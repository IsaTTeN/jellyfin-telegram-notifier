import logging
import os
import json
import requests
import tempfile
import re
import base64
import threading
import time
import markdown
import smtplib
from requests.exceptions import HTTPError
from flask import Flask, request
from dotenv import load_dotenv
from apprise import Apprise
from urllib.parse import quote
from email.message import EmailMessage
from email.utils import formatdate, make_msgid
from logging.handlers import TimedRotatingFileHandler
from datetime import datetime, timedelta, timezone
import sqlite3

load_dotenv()
app = Flask(__name__)

# Set up logging
#log_directory = '/app/log'
log_directory = 'A:/git'
log_filename = os.path.join(log_directory, 'jellyfin_telegram-notifier.log')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Ensure the log directory exists
os.makedirs(log_directory, exist_ok=True)

# Create a handler for rotating log files daily
rotating_handler = TimedRotatingFileHandler(log_filename, when="midnight", interval=1, backupCount=7)
rotating_handler.setLevel(logging.INFO)
rotating_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))

# Add the rotating handler to the logger
logging.getLogger().addHandler(rotating_handler)

# Constants
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "")
GOTIFY_URL = os.environ.get("GOTIFY_URL", "").rstrip("/")
GOTIFY_TOKEN = os.environ.get("GOTIFY_TOKEN", "")
JELLYFIN_BASE_URL = os.environ["JELLYFIN_BASE_URL"].rstrip("/")
JELLYFIN_API_KEY = os.environ["JELLYFIN_API_KEY"]
YOUTUBE_API_KEY = os.environ.get("YOUTUBE_API_KEY", "")
MDBLIST_API_KEY = os.environ.get("MDBLIST_API_KEY", "")
IMGBB_API_KEY = os.environ.get("IMGBB_API_KEY", "")
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL", "")
TMDB_API_KEY = os.environ.get("TMDB_API_KEY")
TMDB_SEARCH_URL = "https://api.themoviedb.org/3/search/tv"
LANGUAGE = os.environ["LANGUAGE"]
EPISODE_PREMIERED_WITHIN_X_DAYS = int(os.environ["EPISODE_PREMIERED_WITHIN_X_DAYS"])
SEASON_ADDED_WITHIN_X_DAYS = int(os.environ["SEASON_ADDED_WITHIN_X_DAYS"])
SIGNAL_URL = os.environ.get("SIGNAL_URL", "").rstrip("/")
SIGNAL_NUMBER = os.environ.get("SIGNAL_NUMBER", "")
SIGNAL_RECIPIENTS = os.environ.get("SIGNAL_RECIPIENTS", "")
WHATSAPP_API_URL = os.environ.get("WHATSAPP_API_URL", "").rstrip("/")
WHATSAPP_NUMBER = os.environ.get("WHATSAPP_NUMBER", "")
WHATSAPP_JID = os.environ.get("WHATSAPP_JID", "")
WHATSAPP_GROUP_JID = os.environ.get("WHATSAPP_GROUP_JID", "")
WHATSAPP_API_USERNAME = os.environ.get("WHATSAPP_API_USERNAME", "")
WHATSAPP_API_PWD = os.environ.get("WHATSAPP_API_PWD", "")
MATRIX_URL = os.environ.get("MATRIX_URL", "").rstrip("/")
MATRIX_ACCESS_TOKEN = os.environ.get("MATRIX_ACCESS_TOKEN", "")
MATRIX_ROOM_ID = os.environ.get("MATRIX_ROOM_ID", "")
SMTP_SUBJECT = "–ù–æ–≤—ã–π —Ä–µ–ª–∏–∑ –≤ Jellyfin"
SMTP_HOST = os.environ.get("SMTP_HOST", "")
SMTP_PORT = int(os.environ.get("SMTP_PORT", "587"))
SMTP_USER = os.environ.get("SMTP_USER", "")
SMTP_PASS = os.environ.get("SMTP_PASS", "")
SMTP_FROM = os.environ.get("SMTP_FROM", "")
SMTP_TO   = os.environ.get("SMTP_TO", "")  # —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é/–ø—Ä–æ–±–µ–ª
SMTP_USE_TLS = os.environ.get("SMTP_USE_TLS", "1") not in ("0", "", "false", "False")   # –¥–ª—è STARTTLS (587)
SMTP_USE_SSL = os.environ.get("SMTP_USE_SSL", "0") in ("1", "true", "True")   # –¥–ª—è SMTPS (465); –µ—Å–ª–∏ 1, —Ç–æ TLS –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
SLACK_BOT_TOKEN = os.environ.get("SLACK_BOT_TOKEN", "")
SLACK_CHANNEL_ID = os.environ.get("SLACK_CHANNEL_ID", "")   # ID –∫–∞–Ω–∞–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä C0123456789
#–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
DISABLE_DEDUP = os.getenv("NOTIFIER_DISABLE_DEDUP", "1").lower() in ("1", "true", "yes")
#–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ñ–∏–ª—å–º–æ–≤
MOVIE_POLL_ENABLED = os.getenv("MOVIE_POLL_ENABLED", "1").lower() in ("1", "true", "yes")
MOVIE_POLL_INTERVAL_SEC = int(os.getenv("MOVIE_POLL_INTERVAL_SEC", "80"))   # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
MOVIE_POLL_GRACE_MIN = int(os.getenv("MOVIE_POLL_GRACE_MIN", "45"))  # –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å —Ñ–∏–ª—å–º—ã, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–∏–Ω—É—Ç
MOVIE_POLL_PAGE_SIZE = int(os.getenv("MOVIE_POLL_PAGE_SIZE", "500"))  # —Å–∫–æ–ª—å–∫–æ –±—Ä–∞—Ç—å –∑–∞ 1 –∑–∞–ø—Ä–æ—Å
MOVIE_POLL_MAX_TOTAL = int(os.getenv("MOVIE_POLL_MAX_TOTAL", "0"))    # 0 = –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –æ–±—â–µ–µ —á–∏—Å–ª–æ
# GC –ë–î –∫–∞—á–µ—Å—Ç–≤–∞
QUALITY_GC_ENABLED = os.getenv("QUALITY_GC_ENABLED", "1").lower() in ("1","true","yes","on")
QUALITY_GC_INTERVAL_HOURS = int(os.getenv("QUALITY_GC_INTERVAL_HOURS", "24"))   # –∫–∞–∫ —á–∞—Å—Ç–æ —á–∏—Å—Ç–∏—Ç—å
QUALITY_GC_GRACE_DAYS = int(os.getenv("QUALITY_GC_GRACE_DAYS", "1"))            # –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –º–æ–ª–æ–∂–µ N –¥–Ω–µ–π
QUALITY_GC_PAGE_SIZE = int(os.getenv("QUALITY_GC_PAGE_SIZE", "500"))            # —Å–∫–æ–ª—å–∫–æ —Ñ–∏–ª—å–º–æ–≤ –∑–∞ —Ä–∞–∑ —Ç—è–Ω—É—Ç—å –∏–∑ Jellyfin
# –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –ë–î –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
FORCE_QUALITY_GC_ON_START = os.getenv("FORCE_QUALITY_GC_ON_START", "0").lower() in ("1","true","yes","on")
# –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ grace-—Å—Ä–æ–∫–∞ –∏–º–µ–Ω–Ω–æ –¥–ª—è —Ñ–æ—Ä—Å-–∑–∞–ø—É—Å–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0 = —É–¥–∞–ª—è—Ç—å —Å—Ä–∞–∑—É)
FORCE_QUALITY_GC_GRACE_DAYS = os.getenv("FORCE_QUALITY_GC_GRACE_DAYS")
# –°–∂–∞—Ç—å –ë–î –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
FORCE_QUALITY_GC_VACUUM = os.getenv("FORCE_QUALITY_GC_VACUUM", "0").lower() in ("1","true","yes","on")
#–≤—ã–∫–ª—é—á–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–≤—É–∫–æ–≤—ã—Ö –¥–æ—Ä–æ–∂–∫–∞—Ö
INCLUDE_AUDIO_TRACKS = os.getenv("INCLUDE_AUDIO_TRACKS", "1").lower() in ("1", "true", "yes", "on")
#–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–µ webhook –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª–¥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN = int(os.getenv("SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN", "60"))  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60 –º–∏–Ω—É—Ç
# –û–ø—Ä–æ—Å —Å–µ—Ä–∏–∞–ª–æ–≤ (–ø–æ –Ω–æ–≤—ã–º/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º —ç–ø–∏–∑–æ–¥–∞–º)
SERIES_POLL_ENABLED = os.getenv("SERIES_POLL_ENABLED", "1").lower() in ("1","true","yes","on")
SERIES_POLL_INTERVAL_SEC = int(os.getenv("SERIES_POLL_INTERVAL_SEC", "80"))  # –ø–µ—Ä–∏–æ–¥, —Å–µ–∫
SERIES_POLL_PAGE_SIZE = int(os.getenv("SERIES_POLL_PAGE_SIZE", "500"))
SERIES_POLL_MAX_TOTAL = int(os.getenv("SERIES_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
SERIES_POLL_GRACE_MIN = int(os.getenv("SERIES_POLL_GRACE_MIN", "0"))  # —Å–≤–µ–∂–∏–µ —ç–ø–∏–∑–æ–¥—ã –æ—Ç–¥–∞—ë–º –Ω–∞ –æ—Ç–∫—É–ø –≤–µ–±—Ö—É–∫—É
# –ü–æ—Å—ã–ª–∞—Ç—å –ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø—Ä–∏ –ü–ï–†–í–û–ú –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Å–µ–∑–æ–Ω–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ—Ç)
SERIES_POLL_INITIAL_ANNOUNCE = os.getenv("SERIES_POLL_INITIAL_ANNOUNCE", "1").lower() in ("1","true","yes","on")
# –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–π–º–µ—Ä—ã –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ –≤—Ä–µ–º—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Jellyfin
NOTIFY_BLOCK_DURING_SCAN = os.getenv("NOTIFY_BLOCK_DURING_SCAN", "1").lower() in ("1","true","yes","on")
SCAN_RECHECK_DELAY_SEC = int(os.getenv("SCAN_RECHECK_DELAY_SEC", "5"))   # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
MAX_SCAN_WAIT_MIN = int(os.getenv("MAX_SCAN_WAIT_MIN", "0"))             # 0 = –∂–¥–∞—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ
# –ö–∞–∫–∏–µ –∏–º–µ–Ω–∞ –∑–∞–¥–∞—á —Å—á–∏—Ç–∞—Ç—å ¬´—Å–∫–∞–Ω–æ–º¬ª (–Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
SCAN_TASK_NAME_MATCH = [s.strip() for s in os.getenv(
    "SCAN_TASK_NAME_MATCH",
    "scan,library,metadata,refresh"
).lower().split(",") if s.strip()]

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
imgbb_upload_done = threading.Event()   # –°–∏–≥–Ω–∞–ª –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏
uploaded_image_url = None               # –ó–¥–µ—Å—å —Ö—Ä–∞–Ω–∏—Ç—Å—è —Å—Å—ã–ª–∫–∞ –ø–æ—Å–ª–µ —É–¥–∞—á–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
# Gotify –±–æ–ª—å—à–µ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ APPRISE_URLS –≤–æ–æ–±—â–µ!
APPRISE_OTHER_URLS = os.environ.get("APPRISE_OTHER_URLS", "")
APPRISE_URLS = APPRISE_OTHER_URLS.strip()

apobj = Apprise()
for url in APPRISE_URLS.split():
    apobj.add(url)

# Path for the JSON file to store notified items
#notified_items_file = '/app/data/notified_items.json'
notified_items_file = 'A:/git/notified_items.json'

# === SQLite –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è Movie –Ω–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ) ===
QUALITY_DB_FILE = os.path.join(os.path.dirname(notified_items_file), "media_quality.db")
os.makedirs(os.path.dirname(QUALITY_DB_FILE), exist_ok=True)

def _init_quality_db():
    conn = sqlite3.connect(QUALITY_DB_FILE)
    try:
        cur = conn.cursor()
        # —Å–Ω–∏–º–æ–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É ItemId (–∏—Å—Ç–æ—Ä–∏—è)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS media_quality (
            item_id TEXT PRIMARY KEY,
            movie_name TEXT,
            year INTEGER,
            video_codec TEXT,
            video_bitrate INTEGER,
            width INTEGER,
            height INTEGER,
            fps REAL,
            bit_depth INTEGER,
            dynamic_range TEXT,
            audio_codec TEXT,
            audio_bitrate INTEGER,
            audio_channels INTEGER,
            container TEXT,
            size_bytes INTEGER,
            duration_sec REAL,
            signature TEXT,
            date_seen TEXT
        )""")
        # "–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è" –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É (tmdb/imdb –∏–ª–∏ name+year)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS content_quality (
            logical_key TEXT PRIMARY KEY,
            last_item_id TEXT,
            movie_name TEXT,
            year INTEGER,
            video_codec TEXT,
            video_bitrate INTEGER,
            width INTEGER,
            height INTEGER,
            fps REAL,
            bit_depth INTEGER,
            dynamic_range TEXT,
            audio_codec TEXT,
            audio_bitrate INTEGER,
            audio_channels INTEGER,
            container TEXT,
            size_bytes INTEGER,
            duration_sec REAL,
            signature TEXT,
            date_seen TEXT
        )""")
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS recent_quality_updates
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        notified_at
                        TEXT,
                        item_id
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS season_progress
                    (
                        season_id
                        TEXT
                        PRIMARY
                        KEY,
                        series_id
                        TEXT,
                        series_name
                        TEXT,
                        season_number
                        INTEGER,
                        release_year
                        INTEGER,
                        present
                        INTEGER
                        DEFAULT
                        0, -- —Å–∫–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –µ—Å—Ç—å —Å–µ—Ä–∏–π –Ω–∞ –¥–∏—Å–∫–µ
                        total
                        INTEGER
                        DEFAULT
                        0, -- —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ —Å–µ—Ä–∏–π (present + missing)
                        last_notified_present
                        INTEGER
                        DEFAULT
                        0, -- –¥–æ –∫–∞–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è —É–∂–µ —Å–æ–æ–±—â–∞–ª–∏
                        updated_at
                        TEXT
                    )
                    """)
        # --- –ú—è–≥–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É image_profiles, –µ—Å–ª–∏ –µ—ë –µ—â—ë –Ω–µ—Ç
        try:
            cur.execute("ALTER TABLE media_quality ADD COLUMN image_profiles TEXT")
        except Exception:
            pass
        try:
            cur.execute("ALTER TABLE content_quality ADD COLUMN image_profiles TEXT")
        except Exception:
            pass
        conn.commit()
    finally:
        conn.close()

_init_quality_db()

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ /app/data —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
os.makedirs(os.path.dirname(notified_items_file), exist_ok=True)

# Function to load notified items from the JSON file
def load_notified_items():
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å ‚Äî —á–∏—Ç–∞–µ–º
    if os.path.exists(notified_items_file):
        with open(notified_items_file, 'r', encoding='utf-8') as file:
            return json.load(file)
    # –ò–Ω–∞—á–µ ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π JSON –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
    with open(notified_items_file, 'w', encoding='utf-8') as file:
        json.dump({}, file, ensure_ascii=False, indent=2)
    return {}

# Function to save notified items to the JSON file
def save_notified_items(notified_items_to_save):
    with open(notified_items_file, 'w', encoding='utf-8') as file:
        json.dump(notified_items_to_save, file, ensure_ascii=False, indent=2)


notified_items = load_notified_items()

# 2. –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–≤–æ–¥–æ–≤
MESSAGES = {
    "en": {
        "new_movie_title": "üçøNew Movie Addedüçø",
        "new_season_title": "üì∫New Season Addedüì∫",
        "new_episode_title": "üì∫New Episode Addedüì∫",
        "new_album_title": "üéµNew Album Addedüéµ",
        "new_runtime": "üïíRuntimeüïí",
        "new_ratings_movie": "‚≠êRatings movie‚≠ê",
        "new_ratings_show": "‚≠êRatings show‚≠ê",
        "new_trailer": "Trailer",
        "new_release_date": "Release Date",
        "new_series": "Series",
        "new_episode_t": "Episode Title",
        "audio_tracks": "Audio tracks",
        "image_profiles": "Image profiles",
        "quality_updated": "üîºQuality updateüîº",
        "season_added_progress": "Added {added} of {total} episodes",
        "season_added_count_only": "Added {added} episodes",
    },
    "ru": {
        "new_movie_title": "üçø–ù–æ–≤—ã–π —Ñ–∏–ª—å–º –¥–æ–±–∞–≤–ª–µ–Ωüçø",
        "new_season_title": "üì∫–ù–æ–≤—ã–π —Å–µ–∑–æ–Ω –¥–æ–±–∞–≤–ª–µ–Ωüì∫",
        "new_episode_title": "üì∫–ù–æ–≤—ã–π —ç–ø–∏–∑–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ωüì∫",
        "new_album_title": "üéµ–ù–æ–≤—ã–π –∞–ª—å–±–æ–º –¥–æ–±–∞–≤–ª–µ–Ωüéµ",
        "new_runtime": "üïí–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—åüïí",
        "new_ratings_movie": "‚≠ê–†–µ–π—Ç–∏–Ω–≥–∏ —Ñ–∏–ª—å–º–∞‚≠ê",
        "new_ratings_show": "‚≠ê–†–µ–π—Ç–∏–Ω–≥–∏ —Å–µ—Ä–∏–∞–ª–∞‚≠ê",
        "new_trailer": "–¢—Ä–µ–π–ª–µ—Ä",
        "new_release_date": "–î–∞—Ç–∞ –≤—ã—Ö–æ–¥–∞",
        "new_series": "–°–µ—Ä–∏–∞–ª",
        "new_episode_t": "–ù–∞–∑–≤–∞–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∞",
        "audio_tracks": "–ê—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏",
        "image_profiles": "–ü—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "quality_updated": "üîº–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞üîº",
        "season_added_progress": "–î–æ–±–∞–≤–ª–µ–Ω–æ {added} –∏–∑ {total} —Å–µ—Ä–∏–π",
        "season_added_count_only": "–î–æ–±–∞–≤–ª–µ–Ω–æ {added} —Å–µ—Ä–∏–π",
    }
}
#–í—ã–±–∏—Ä–∞–µ–º —Ä–∞–±–æ—á–∏–π —è–∑—ã–∫: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–Ω—ã–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ MESSAGES ‚Äî —Å—Ç–∞–≤–∏–º en
LANG = LANGUAGE if LANGUAGE in MESSAGES else "en"

def t(key: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –ø–æ –∫–ª—é—á—É –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —è–∑—ã–∫–∞ LANG.
    –ï—Å–ª–∏ –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø–∞–¥–∞–µ—Ç KeyError, —á—Ç–æ–±—ã –≤—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞.
    """
    return MESSAGES[LANG][key]

#–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
def _task_name_matches(name: str | None) -> bool:
    if not name:
        return False
    n = name.lower()
    return any(seg in n for seg in SCAN_TASK_NAME_MATCH)

def is_jellyfin_scanning() -> tuple[bool, str | None]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ª–∏ —Å–µ–π—á–∞—Å —Å–∫–∞–Ω/—Ä–µ—Ñ—Ä–µ—à –º–µ–¥–∏–∞—Ç–µ–∫–∏/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Jellyfin.
    1) /emby/ScheduledTasks/Running (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
    2) /emby/ScheduledTasks (–∏—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è Running/Executing/IsRunning)
    –í–æ–∑–≤—Ä–∞—Ç: (True/False, –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ)
    """
    headers = {'accept': 'application/json'}
    params = {'api_key': JELLYFIN_API_KEY}

    # 1) —Ç–µ–∫—É—â–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã–µ –∑–∞–¥–∞—á–∏
    try:
        url = f"{JELLYFIN_BASE_URL}/emby/ScheduledTasks/Running"
        r = requests.get(url, headers=headers, params=params, timeout=6)
        if r.status_code == 200:
            data = r.json() or []
            for t in data:
                name = t.get("Name") or t.get("Key") or ""
                state = t.get("State") or ""
                prog = t.get("CurrentProgressPercentage") or t.get("Progress") or t.get("PercentComplete")
                if _task_name_matches(name):
                    desc = f"{name} {prog}%" if prog is not None else name
                    return True, desc
    except Exception:
        pass

    # 2) –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
    try:
        url = f"{JELLYFIN_BASE_URL}/emby/ScheduledTasks"
        r = requests.get(url, headers=headers, params=params, timeout=8)
        if r.status_code == 200:
            data = r.json() or []
            for t in data:
                name = t.get("Name") or t.get("Key") or ""
                state = (t.get("State") or "").lower()
                is_running = bool(t.get("IsRunning")) or state in ("running", "executing", "inprogress")
                if is_running and _task_name_matches(name):
                    prog = t.get("CurrentProgressPercentage") or t.get("Progress") or t.get("PercentComplete")
                    desc = f"{name} {prog}%" if prog is not None else name
                    return True, desc
    except Exception:
        pass

    return False, None

def wait_until_scan_idle(reason: str = ""):
    """
    –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω NOTIFY_BLOCK_DURING_SCAN ‚Äî –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–∫–∞–Ω–∞ Jellyfin.
    MAX_SCAN_WAIT_MIN=0 => –∂–¥—ë–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ.
    """
    if not NOTIFY_BLOCK_DURING_SCAN:
        return
    start = time.time()
    first_log = True
    while True:
        running, detail = is_jellyfin_scanning()
        if not running:
            if not first_log:
                logging.info("Jellyfin scan finished, resume timers.")
            return
        if first_log:
            logging.info(f"Timers paused: Jellyfin is scanning ({detail or 'library task running'})"
                         + (f" [reason: {reason}]" if reason else ""))
            first_log = False
        if MAX_SCAN_WAIT_MIN and (time.time() - start) > MAX_SCAN_WAIT_MIN * 60:
            logging.warning("Max wait for scan reached; resuming timers anyway.")
            return
        time.sleep(max(SCAN_RECHECK_DELAY_SEC, 1))

def _movie_poll_loop():
    while True:
        try:
            wait_until_scan_idle("movie poll")
            poll_recent_movies_once()
        except Exception as ex:
            logging.warning(f"Movie poll loop error: {ex}")
        time.sleep(MOVIE_POLL_INTERVAL_SEC)

def _series_poll_loop():
    while True:
        try:
            wait_until_scan_idle("series poll")
            poll_recent_episodes_once()
        except Exception as ex:
            logging.warning(f"Series poll loop error: {ex}")
        time.sleep(SERIES_POLL_INTERVAL_SEC)

def _wa_get_jid_from_env():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç JID –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≥—Ä—É–ø–ø—É.
    –ò–Ω–∞—á–µ –ª–∏—á–Ω—ã–π —á–∞—Ç –∏–∑ WHATSAPP_JID –∏–ª–∏ WHATSAPP_NUMBER.
    """
    group_jid = WHATSAPP_GROUP_JID.strip()
    if group_jid:
        if not group_jid.endswith("@g.us"):
            # –¥–æ–ø—É—Å—Ç–∏–º, –ø–µ—Ä–µ–¥–∞–ª–∏ —Ç–æ–ª—å–∫–æ id –±–µ–∑ @g.us
            group_jid = re.sub(r"[^\w\-]", "", group_jid) + "@g.us"
        return group_jid

    # –õ–∏—á–Ω—ã–π
    raw = (WHATSAPP_JID or WHATSAPP_NUMBER).strip()
    if not raw:
        return None
    if raw.endswith("@s.whatsapp.net"):
        return raw
    # –æ—á–∏—â–∞–µ–º –¥–æ —Ü–∏—Ñ—Ä –∏ –¥–æ–±–∞–≤–ª—è–µ–º –¥–æ–º–µ–Ω
    local = re.sub(r"\D", "", raw)
    return f"{local}@s.whatsapp.net" if local else None

def jellyfin_get_tmdb_id(item_id: str) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç TMDB ID –¥–ª—è –ª—é–±–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ Jellyfin –ø–æ –µ–≥–æ Id.
    –ß–∏—Ç–∞–µ—Ç Items?Ids=...&Fields=ProviderIds –∏ –±–µ—Ä—ë—Ç –Ω—É–∂–Ω—ã–π –∫–ª—é—á –∏–∑ ProviderIds.
    """
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "Ids": item_id,
            "Fields": "ProviderIds"
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=8)
        r.raise_for_status()
        items = (r.json() or {}).get("Items") or []
        if not items:
            return None
        prov = items[0].get("ProviderIds") or {}
        # —Ä–∞–∑–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä–∞/–≤–µ—Ä—Å–∏–∏ –º–æ–≥—É—Ç –∑–≤–∞—Ç—å –∫–ª—é—á –ø–æ-—Ä–∞–∑–Ω–æ–º—É ‚Äî —É—á—Ç—ë–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
        return prov.get("Tmdb") or prov.get("TmdbId") or prov.get("TMDB") or None
    except Exception as ex:
        logging.warning(f"Failed to read ProviderIds for {item_id}: {ex}")
        return None


def fetch_mdblist_ratings(content_type: str, tmdb_id: str) -> str:
    """
    –ó–∞–ø—Ä–æ—Å –∫ https://api.mdblist.com/tmdb/{type}/{tmdbId}
    –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
      "- IMDb: 7.8\n- Rotten Tomatoes: 84%\n‚Ä¶"
    –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏ –æ—à–∏–±–∫–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    url = f"https://api.mdblist.com/tmdb/{content_type}/{tmdb_id}?apikey={MDBLIST_API_KEY}"
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        ratings = data.get("ratings")
        if not isinstance(ratings, list):
            return ""

        lines = []
        for r in ratings:
            source = r.get("source")
            value = r.get("value")
            if source is None or value is None:
                continue
            lines.append(f"- {source}: {value}")

        return "\n".join(lines)
    except requests.RequestException as e:
        app.logger.warning(f"MDblist API error for {content_type}/{tmdb_id}: {e}")
        return ""

def upload_image_to_imgbb(image_bytes):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ imgbb.com (–¥–æ 3 –ø–æ–ø—ã—Ç–æ–∫) –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏.
    """
    global uploaded_image_url
    uploaded_image_url = None
    imgbb_upload_done.clear()  # –°–±—Ä–æ—Å —Å–æ–±—ã—Ç–∏—è

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞ API
    if not IMGBB_API_KEY:
        logging.debug("IMGBB_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ imgbb.")
        imgbb_upload_done.set()  # –°–∏–≥–Ω–∞–ª –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (–ø—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏)
        return None

    url = "https://api.imgbb.com/1/upload"
    payload = {
        "key": IMGBB_API_KEY,
        "image": base64.b64encode(image_bytes).decode('utf-8')
    }

    for attempt in range(1, 4):
        try:
            logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb #{attempt}")
            response = requests.post(url, data=payload, timeout=20)
            response.raise_for_status()
            data = response.json()
            uploaded_image_url = data['data']['url']
            logging.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞ imgbb: {uploaded_image_url}")
            break
        except Exception as ex:
            logging.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {ex}")
            if attempt < 3:
                time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

    imgbb_upload_done.set()  # –°–∏–≥–Ω–∞–ª, —á—Ç–æ –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—É—Å–ø–µ—à–Ω–æ –∏–ª–∏ –Ω–µ—Ç)
    return uploaded_image_url

def wait_for_imgbb_upload():
    """
    –ë–ª–æ–∫–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    imgbb_upload_done.wait()
    return uploaded_image_url


def get_jellyfin_image_and_upload_imgbb(photo_id):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ–≥–æ –Ω–∞ imgbb, –≤–æ–∑–≤—Ä–∞—â–∞—è –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É.
    """
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    try:
        resp = requests.get(jellyfin_image_url)
        resp.raise_for_status()
        return upload_image_to_imgbb(resp.content)
    except Exception as ex:
        logging.warning(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ Jellyfin: {ex}")
        return None

def send_discord_message(photo_id, message, title="Jellyfin", uploaded_url=None):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Discord —á–µ—Ä–µ–∑ Webhook.
    –ö–∞—Ä—Ç–∏–Ω–∫—É –±–µ—Ä—ë–º –ù–ê–ü–†–Ø–ú–£–Æ –∏–∑ Jellyfin –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª.
    Embed —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –Ω–µ—ë —á–µ—Ä–µ–∑ attachment://filename.
    """
    if not DISCORD_WEBHOOK_URL:
        logging.warning("DISCORD_WEBHOOK_URL not set, skipping Discord notification.")
        return None

    # 1) —Ç—è–Ω–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    image_bytes = None
    filename = "poster.jpg"
    mimetype = "image/jpeg"
    try:
        r = requests.get(jellyfin_image_url, timeout=30)
        r.raise_for_status()
        image_bytes = r.content
        ct = r.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
        if "png" in ct:
            filename, mimetype = "poster.png", "image/png"
        elif "webp" in ct:
            filename, mimetype = "poster.webp", "image/webp"
    except Exception as ex:
        logging.warning(f"Discord: failed to fetch image from Jellyfin: {ex}")

    # 2) –≥–æ—Ç–æ–≤–∏–º payload
    payload = {
        "username": title,
        "content": message
    }

    # –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∞ ‚Äî –¥–æ–±–∞–≤–∏–º embed, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ attachment
    if image_bytes:
        payload["embeds"] = [{
            "image": {"url": f"attachment://{filename}"}
        }]

    try:
        if image_bytes:
            # multipart: payload_json + —Ñ–∞–π–ª
            files = {
                "file": (filename, image_bytes, mimetype)
            }
            resp = requests.post(
                DISCORD_WEBHOOK_URL,
                data={"payload_json": json.dumps(payload, ensure_ascii=False)},
                files=files,
                timeout=30
            )
        else:
            # –±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ–±—ã—á–Ω—ã–π JSON
            resp = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=30)

        resp.raise_for_status()
        logging.info("Discord notification sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Error sending to Discord: {ex}")
        return None

def clean_markdown_for_apprise(text):
    """
    –£–ø—Ä–æ—â–∞–µ—Ç markdown-–ø–æ–¥–æ–±–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è plain text –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç —Å—Å—ã–ª–∫–∏ –∫ –µ–¥–∏–Ω–æ–º—É –≤–∏–¥—É:
    - [—Ç–µ–∫—Å—Ç](url) -> url
    - –£–±–∏—Ä–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ–¥—Ä—è–¥ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ url
    - –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å 'üé• <–ø–µ—Ä–µ–≤–æ–¥ new_trailer>:' –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —Å—Å—ã–ª–∫–æ–π (–±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
    - –û—á–∏—â–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º —Å—Ç—Ä–æ–∫
    """
    if not text:
        return text

    # 0) –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–µ—Ç–∫—É –¥–ª—è "–¢—Ä–µ–π–ª–µ—Ä"
    try:
        trailer_label = t("new_trailer")
    except Exception:
        trailer_label = MESSAGES.get(LANG, {}).get("new_trailer", "Trailer")
    if not trailer_label:
        trailer_label = "Trailer"
    # 1) [—Ç–µ–∫—Å—Ç](url) -> url
    text = re.sub(r'\[([^\]]+)\]\((https?://[^\s)]+)\)', r'\2', text)

    # 2) –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL
    text = re.sub(r'(https?://\S+)(\s*\1)+', r'\1', text)

    # 3) –°–Ω–∞—á–∞–ª–∞ —É–±–∏—Ä–∞–µ–º —É–∂–µ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã,
    #    –∑–∞—Ç–µ–º –¥–æ–±–∞–≤–∏–º –∏—Ö –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ
    prefix_pattern = rf'üé•\s*{re.escape(trailer_label)}[:]?\s*'
    text = re.sub(rf'{prefix_pattern}(https?://\S+)', r'\1', text)

    # 4) –ü—Ä–µ—Ñ–∏–∫—Å—É–µ–º –¢–û–õ–¨–ö–û –Ω–µ-musicbrainz —Å—Å—ã–ª–∫–∏ (—á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫)
    def _prefix_non_mb(m):
        url = m.group(1)
        if re.search(r'https?://(?:[^/\s)]+\.)*musicbrainz\.org(?=[/\s)]|$)', url, re.IGNORECASE):
            return url
        return f'üé• {trailer_label}: {url}'

    text = re.sub(r'(https?://\S+)', _prefix_non_mb, text)
    # 5) –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º —Å—Ç—Ä–æ–∫ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã)
    text = '\n'.join(line.strip() for line in text.split('\n'))

    # –£–±—Ä–∞—Ç—å *–∂–∏—Ä–Ω—ã–π* –∏ _–∫—É—Ä—Å–∏–≤_
    text = re.sub(r'(\*|_){1,3}(.+?)\1{1,3}', r'\2', text)

    return text

def sanitize_whatsapp_text(text: str) -> str:
    if not text:
        return text

    # –ë–µ—Ä—ë–º —è–∑—ã–∫ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    lang = os.environ.get("LANGUAGE", "en")
    trailer_label = MESSAGES.get(lang, {}).get("new_trailer")

    # 1) –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º [–ª—é–±–æ–π —Ç–µ–∫—Å—Ç](https://...) –≤ –ø—Ä–æ—Å—Ç–æ https://...
    text = re.sub(r'\[([^\]]+)\]\((https?://[^\)]+)\)', r'\2', text)

    # 2) –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL
    text = re.sub(r'(https?://\S+)(\s*\1)+', r'\1', text)


    # 3) –°–Ω–æ—Å–∏–º —É–∂–µ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã (–Ω–∞ –≤—Å—è–∫–∏–π)
    prefix_re = rf'üé•\s*{re.escape(trailer_label)}:?[\s]*'
    text = re.sub(rf'{prefix_re}(https?://\S+)', r'\1', text)

    # 4) –ü—Ä–µ—Ñ–∏–∫—Å—É–µ–º –¢–û–õ–¨–ö–û –Ω–µ-musicbrainz —Å—Å—ã–ª–∫–∏ (—á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫)
    def _prefix_non_mb(m):
        url = m.group(1)
        if re.search(r'https?://(?:[^/\s)]+\.)*musicbrainz\.org(?=[/\s)]|$)', url, re.IGNORECASE):
            return url
        return f'üé• {trailer_label} {url}'

    text = re.sub(r'(https?://\S+)', _prefix_non_mb, text)

    # 5) –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'[ \t]+', ' ', text).strip()

    return text

def send_email_with_image_jellyfin(photo_id: str, subject: str, body_markdown: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email —Å:
      - text/plain (plain-–≤–µ—Ä—Å–∏—è —Ç–µ–∫—Å—Ç–∞)
      - text/html (Markdown ‚Üí HTML)
      - inline-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–∑ Jellyfin (—á–µ—Ä–µ–∑ CID)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True/False.
    """
    if not (SMTP_HOST and SMTP_FROM and SMTP_TO):
        logging.debug("Email disabled or misconfigured; skip.")
        return False

    # plain-–≤–µ—Ä—Å–∏—è (–±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å
    body_plain = clean_markdown_for_apprise(body_markdown or "")

    # HTML-–≤–µ—Ä—Å–∏—è ‚Äî —Ä–µ–Ω–¥–µ—Ä–∏–º –∏–∑ Markdown
    # extensions –¥–ª—è –±–æ–ª–µ–µ –ø—Ä–∏—è—Ç–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤/–ø–µ—Ä–µ–Ω–æ—Å–æ–≤
    body_html_rendered = markdown.markdown(
        body_markdown or "",
        extensions=["extra", "sane_lists", "nl2br"]
    )

    # –¢—è–Ω–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ Jellyfin (—Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏)
    img_bytes = None
    img_subtype = "jpeg"
    try:
        img_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        # subtype –ø–æ–¥–±–µ—Ä—ë–º –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ (–µ—Å–ª–∏ –µ—Å—Ç—å headers –≤ —Ä–µ—Ç—Ä–∞–µ ‚Äî –º–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤–º–µ—Å—Ç–µ)
        # –∑–¥–µ—Å—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º jpeg; –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    except Exception as ex:
        logging.warning(f"Email: failed to fetch Jellyfin image: {ex}")

    msg = EmailMessage()
    msg["Subject"] = subject or SMTP_SUBJECT
    msg["From"]    = SMTP_FROM
    recipients = [x.strip() for x in re.split(r"[,\s]+", SMTP_TO) if x.strip()]
    msg["To"]     = ", ".join(recipients)
    msg["Date"]   = formatdate(localtime=True)

    # 1) text/plain
    msg.set_content(body_plain or "")

    # 2) text/html (+ inline image –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏)
    if img_bytes:
        cid = make_msgid()  # –≤–∏–¥–∞ <...@domain>
        html_part = f"""\
<html>
  <body>
    <div>{body_html_rendered}</div>
    <p><img src="cid:{cid[1:-1]}" alt="poster"></p>
  </body>
</html>"""
        msg.add_alternative(html_part, subtype="html")
        try:
            # –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∫ HTML-—á–∞—Å—Ç–∏ –∫–∞–∫ related
            msg.get_payload()[1].add_related(img_bytes, maintype="image", subtype=img_subtype, cid=cid)
        except Exception as ex:
            logging.warning(f"Email: cannot embed inline image (fallback as attachment): {ex}")
            msg.add_attachment(img_bytes, maintype="image", subtype=img_subtype, filename="poster.jpg")
    else:
        # –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ HTML –±–µ–∑ —Ç–µ–≥–∞ <img>
        msg.add_alternative(f"<html><body>{body_html_rendered}</body></html>", subtype="html")

    # –û—Ç–ø—Ä–∞–≤–∫–∞
    try:
        if SMTP_USE_SSL or SMTP_PORT == 465:
            with smtplib.SMTP_SSL(SMTP_HOST, SMTP_PORT, timeout=30) as s:
                if SMTP_USER:
                    s.login(SMTP_USER, SMTP_PASS)
                s.send_message(msg)
        else:
            with smtplib.SMTP(SMTP_HOST, SMTP_PORT, timeout=30) as s:
                if SMTP_USE_TLS:
                    s.starttls()
                if SMTP_USER:
                    s.login(SMTP_USER, SMTP_PASS)
                s.send_message(msg)
        logging.info("Email notification (Markdown->HTML) sent successfully")
        return True
    except Exception as ex:
        logging.warning(f"Email send failed: {ex}")
        return False

def _slack_try_join_channel(channel_id: str) -> bool:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ—Ç–∞ –≤ PUBLIC-–∫–∞–Ω–∞–ª (—Ç—Ä–µ–±—É–µ—Ç scope channels:join).
    –î–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é /invite –≤ Slack.
    """
    if not (SLACK_BOT_TOKEN and channel_id):
        return False
    try:
        resp = requests.post(
            "https://slack.com/api/conversations.join",
            headers={
                "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
                "Content-Type": "application/json; charset=utf-8",
            },
            json={"channel": channel_id},
            timeout=15,
        )
        data = resp.json()
        if not data.get("ok"):
            logging.debug(f"Slack join failed/ignored: {data.get('error')}")
            return False
        return True
    except Exception as ex:
        logging.debug(f"Slack join error: {ex}")
        return False

def send_slack_text_only(message_markdown: str) -> bool:
    """
    –§–æ–ª–ª–±—ç–∫ –Ω–∞ —á–∞—Ç –±–µ–∑ —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç chat.postMessage.
    """
    if not (SLACK_BOT_TOKEN and SLACK_CHANNEL_ID):
        logging.debug("Slack disabled/misconfigured; skip text.")
        return False

    url = "https://slack.com/api/chat.postMessage"
    # Slack –ø–æ–Ω–∏–º–∞–µ—Ç mrkdwn (–Ω–µ —Å–æ–≤—Å–µ–º Markdown). –ú–æ–∂–Ω–æ —Å–ª–µ–≥–∫–∞ ¬´–æ—á–∏—Å—Ç–∏—Ç—å¬ª —Ç–µ–∫—Å—Ç:
    text_plain = sanitize_whatsapp_text(message_markdown) or ""

    headers = {
        "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
        "Content-Type": "application/json; charset=utf-8",
    }
    payload = {
        "channel": SLACK_CHANNEL_ID,
        "text": text_plain,
        "mrkdwn": True,
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        if not data.get("ok"):
            logging.warning(f"Slack chat.postMessage error: {data}")
            return False
        logging.info("Slack text message sent successfully")
        return True
    except Exception as ex:
        logging.warning(f"Slack text send failed: {ex}")
        return False


def send_slack_message_with_image_from_jellyfin(photo_id: str, caption_markdown: str) -> bool:
    """
    Slack: –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ –Ω–æ–≤–æ–º—É –ø–æ—Ç–æ–∫—É:
      1) files.getUploadURLExternal (–ø–æ–ª—É—á–∞–µ–º upload_url –∏ file_id)
      2) POST –±–∞–π—Ç–æ–≤ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞ upload_url
      3) files.completeUploadExternal (channel_id + initial_comment)
    –§–æ–ª–ª–±—ç–∫: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ chat.postMessage.
    """
    if not (SLACK_BOT_TOKEN and SLACK_CHANNEL_ID):
        logging.debug("Slack disabled/misconfigured; skip.")
        return False

    # 1) –¥–æ—Å—Ç–∞—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ Jellyfin
    img_bytes = None
    filename = "poster.jpg"
    mimetype = "image/jpeg"
    try:
        if "_fetch_jellyfin_primary" in globals():
            b, mt, fn = _fetch_jellyfin_primary(photo_id)
            img_bytes, mimetype, filename = b, mt, fn
        else:
            jf_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
            r = requests.get(jf_url, timeout=30)
            r.raise_for_status()
            img_bytes = r.content
            ct = r.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
            if "png" in ct:
                filename, mimetype = "poster.png", "image/png"
            elif "webp" in ct:
                filename, mimetype = "poster.webp", "image/webp"
    except Exception as ex:
        logging.warning(f"Slack: failed to fetch image from Jellyfin: {ex}")

    if not img_bytes:
        # –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º —Ç–µ–∫—Å—Ç
        return send_slack_text_only(caption_markdown)

    # 2) files.getUploadURLExternal
    auth_h = {"Authorization": f"Bearer {SLACK_BOT_TOKEN}"}
    try:
        resp = requests.post(
            "https://slack.com/api/files.getUploadURLExternal",
            headers=auth_h,
            data={"filename": filename, "length": str(len(img_bytes))},
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        if not data.get("ok"):
            logging.warning(f"Slack getUploadURLExternal error: {data}")
            return send_slack_text_only(caption_markdown)
        upload_url = data["upload_url"]
        file_id    = data["file_id"]
    except Exception as ex:
        logging.warning(f"Slack getUploadURLExternal failed: {ex}")
        return send_slack_text_only(caption_markdown)

    # 3) POST —Ñ–∞–π–ª–∞ –Ω–∞ upload_url
    try:
        # –º–æ–∂–Ω–æ —Å—ã—Ä—ã–º–∏ –±–∞–π—Ç–∞–º–∏:
        up_headers = {"Content-Type": mimetype}
        up = requests.post(upload_url, data=img_bytes, headers=up_headers, timeout=60)
        # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ: multipart (–∏–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ –ø—Ä–æ–∫—Å–∏):
        # up = requests.post(upload_url, files={"filename": (filename, img_bytes, mimetype)}, timeout=60)
        if up.status_code != 200:
            logging.warning(f"Slack upload_url returned {up.status_code}: {up.text[:200]}")
            return send_slack_text_only(caption_markdown)
    except Exception as ex:
        logging.warning(f"Slack raw upload failed: {ex}")
        return send_slack_text_only(caption_markdown)

    # 4) files.completeUploadExternal (—à–∞—Ä–∏–º —Ñ–∞–π–ª –≤ –∫–∞–Ω–∞–ª + –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π)
    def _complete_upload():
        comp_payload = {
            "files": [{"id": file_id, "title": filename}],
            "channel_id": SLACK_CHANNEL_ID,
            "initial_comment": sanitize_whatsapp_text(caption_markdown) or "",
        }
        return requests.post(
            "https://slack.com/api/files.completeUploadExternal",
            headers={**auth_h, "Content-Type": "application/json; charset=utf-8"},
            json=comp_payload,
            timeout=30,
        )

    # –ø–æ–ø—ã—Ç–∫–∞ –∑–∞—Ä–∞–Ω–µ–µ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è (–Ω–∞ —Å–ª—É—á–∞–π –ø—É–±–ª–∏—á–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞)
    _slack_try_join_channel(SLACK_CHANNEL_ID)

    try:
        comp = _complete_upload()
        comp.raise_for_status()
        comp_data = comp.json()
        if not comp_data.get("ok"):
            if comp_data.get("error") == "not_in_channel":
                # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑
                if _slack_try_join_channel(SLACK_CHANNEL_ID):
                    comp = _complete_upload()
                    comp.raise_for_status()
                    comp_data = comp.json()
                    if comp_data.get("ok"):
                        logging.info("Slack image sent successfully (after join).")
                        return True
                logging.warning("Slack: bot is not in the channel. Invite the app (/invite @Bot) and retry.")
            else:
                logging.warning(f"Slack completeUploadExternal error: {comp_data}")
            return send_slack_text_only(caption_markdown)

        logging.info("Slack image (external upload flow) sent successfully")
        return True

    except Exception as ex:
        logging.warning(f"Slack completeUploadExternal failed: {ex}")
        return send_slack_text_only(caption_markdown)

def send_notification(photo_id, caption):
    uploaded_url = get_jellyfin_image_and_upload_imgbb(photo_id)
    """
    1. –í—Å–µ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Telegram –Ω–∞–ø—Ä—è–º—É—é (send_telegram_photo).
    2. –ù–µ–∑–∞–≤–∏—Å–∏–º–æ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ Gotify (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω).
    3. –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã ‚Äî —á–µ—Ä–µ–∑ Apprise.
    """
    # –¢–µ–∫—Å—Ç –±–µ–∑ Markdown (–ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è plain-—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞, –≤ —Ç.—á. WhatsApp)
#    caption_plain = clean_markdown_for_apprise(caption)
    if TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID:
        tg_response = send_telegram_photo(photo_id, caption)
        if tg_response and tg_response.ok:
            logging.info("Notification sent via Telegram")
        else:
            logging.warning("Notification failed via Telegram")
#    tg_GOTIFY = send_gotify_message(photo_id, caption)

    # Gotify: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞–Ω—ã
#    gotify_message = clean_markdown_for_apprise(caption)
#    gotify_response = None
    if GOTIFY_URL and GOTIFY_TOKEN:
        gotify_response = send_gotify_message(photo_id, caption, uploaded_url=uploaded_url)
        if gotify_response and gotify_response.ok:
            logging.info("Notification sent via Gotify")
        else:
            logging.warning("Notification failed via Gotify")

    # ======= –î–û–ë–ê–í–õ–ï–ù–û –î–õ–Ø DISCORD =======
    if DISCORD_WEBHOOK_URL:
        discord_response = send_discord_message(photo_id, caption, uploaded_url=uploaded_url)
        if discord_response and discord_response.ok:
            logging.info("Notification sent via Discord")
        else:
            logging.warning("Notification failed via Discord")
    # =====================================
    # ======= SLACK: —Ñ–∞–π–ª-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º =======
    try:
        if SLACK_BOT_TOKEN and SLACK_CHANNEL_ID:
            ok = send_slack_message_with_image_from_jellyfin(photo_id, caption)
            if ok:
                logging.info("Notification sent via Slack")
            else:
                logging.warning("Notification failed via Slack")
        else:
            logging.debug("Slack disabled or not configured; skip.")
    except Exception as sl_ex:
        logging.warning(f"Slack send failed: {sl_ex}")
    # ======================================================
    # ======= MATRIX (REST): –°–ù–ê–ß–ê–õ–ê –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç =======
    try:
        if MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID:
            ok = send_matrix_image_then_text_from_jellyfin(photo_id, caption)
            if ok:
                logging.info("Notification sent via Matrix (REST, image from Jellyfin then text)")
            else:
                logging.warning("Matrix (REST, Jellyfin): image+text flow failed; trying text-only fallback")
                send_matrix_text_rest(caption)
        else:
            logging.debug("Matrix disabled or not configured; skip.")
    except Exception as m_ex:
        logging.warning(f"Matrix send failed: {m_ex}")
    # ========================================================================
    # --- –û–¢–ü–†–ê–í–ö–ê –í SIGNAL ---
    # Plain text –¥–ª—è Signal (–±–µ–∑ Markdown)
    if SIGNAL_URL and SIGNAL_NUMBER:
        signal_resp = send_signal_message_with_image(
            photo_id,
            clean_markdown_for_apprise(caption),
            SIGNAL_NUMBER,
            SIGNAL_RECIPIENTS
        )
        if signal_resp and signal_resp.ok:
            logging.info("Notification sent via Signal")
        else:
            logging.warning("Notification failed via Signal")
    # --------------------------

    # ======= EMAIL: –ø–∏—Å—å–º–æ —Å inline-–∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∏–∑ Jellyfin =======
    try:
        email_ok = send_email_with_image_jellyfin(photo_id, subject=SMTP_SUBJECT, body_markdown=caption)
        if email_ok:
            logging.info("Notification sent via Email")
        else:
            logging.warning("Notification failed via Email")
    except Exception as em_ex:
        logging.warning(f"Email send failed: {em_ex}")

    # ======= WHATSAPP: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –ø–æ–¥–ø–∏—Å—å—é =======
    try:
        wa_jid = _wa_get_jid_from_env()
        if WHATSAPP_API_URL and wa_jid:
            # view_once, compress, duration, is_forwarded –≤–æ–∑—å–º—É—Ç—Å—è –∏–∑ –¥–µ—Ñ–æ–ª—Ç–æ–≤
            send_whatsapp_image_via_rest(
                caption=caption,
                phone_jid=wa_jid,
                image_url=uploaded_url
            )
        else:
            logging.debug("WhatsApp disabled or no JID; skip image send.")
    except Exception as wa_ex:
        logging.warning(f"WhatsApp image send failed: {wa_ex}")

    other_services = [url for url in APPRISE_URLS.split() if url]  # —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    if other_services:
        apprise_obj = Apprise()
        for url in other_services:
            apprise_obj.add(url)

        # –ì–æ—Ç–æ–≤–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ (–µ—Å–ª–∏ —Ñ–æ—Ç–æ –µ—Å—Ç—å)

    base_photo_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    attach_param = None
    try:
        image_response = requests.get(base_photo_url)
        if image_response.ok:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
                tmp.write(image_response.content)
                tmp_path = tmp.name
            attach_param = tmp_path
        else:
            attach_param = None
    except Exception as ex:
        logging.warning(f"Cannot download image: {ex}")
        attach_param = None

    caption_plain = clean_markdown_for_apprise(caption)
    result = apobj.notify(
        body=caption_plain,
        title="",
        attach=attach_param
    )

    if attach_param and os.path.exists(attach_param):
        try:
            os.remove(attach_param)
        except Exception as ex:
            logging.warning(f"Cannot remove temp image: {ex}")

    if result:
        logging.info("Notification sent via Apprise")
    else:
        logging.warning("Notification failed via Apprise")
    return None
def _fetch_jellyfin_image_with_retries(photo_id: str, attempts: int = 3, timeout: int = 10, delay: float = 1.5):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å Primary-–ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes –∏–ª–∏ None.
    """
    url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    last_err = None
    for i in range(1, attempts + 1):
        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ)
            head = requests.head(url, timeout=timeout)
            if head.ok:
                resp = requests.get(url, timeout=timeout)
                resp.raise_for_status()
                return resp.content
            else:
                last_err = f"HTTP {head.status_code}"
        except Exception as ex:
            last_err = ex
        logging.warning(f"Jellyfin image try {i}/{attempts} failed: {last_err}")
        if i < attempts:
            time.sleep(delay)
    return None

def send_telegram_photo(photo_id, caption):
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º caption –¥–æ 1024 —Å–∏–º–≤–æ–ª–æ–≤
    #    if caption and len(caption) > 1024:
    #        caption = caption[:1023] + "..."  # –¥–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–æ–µ—Ç–æ—á–∏–µ, –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∞–µ–º

#        base_photo_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images"
#        primary_photo_url = f"{base_photo_url}/Primary"

        # Download the image from the jellyfin
#        image_response = requests.get(primary_photo_url)

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏
        image_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        if not image_bytes:
            logging.warning("Telegram: Jellyfin image unavailable after retries")
            return None

        # Upload the image to the Telegram bot
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
        data = {
            "chat_id": TELEGRAM_CHAT_ID,
            "caption": caption,
            "parse_mode": "Markdown"
        }

        files = {'photo': ('photo.jpg', image_bytes, 'image/jpeg')}
        response = requests.post(url, data=data, files=files, timeout=30)
        logging.info("Telegram notification sent successfully")
        return response

    except Exception as ex:
        logging.warning(f"Error sending to Telegram: {ex}")
        return None

def send_matrix_text_rest(message_markdown: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤ Matrix —á–µ—Ä–µ–∑ REST (v3).
    1) –ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π PUT –ø–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏.
    2) –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç PUT (405) ‚Äî –¥–µ–ª–∞–µ—Ç POST —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ —Ç–æ—Ç –∂–µ –ø—É—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID):
        logging.debug("Matrix not configured; skip.")
        return None

    try:
        # room_id –≤–∏–¥–∞ "!MNddurK...:example.org" –Ω—É–∂–Ω–æ URL-—ç–Ω–∫–æ–¥–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é
        room_enc = quote(MATRIX_ROOM_ID, safe="")
        base = f"{MATRIX_URL.rstrip('/')}/_matrix/client/v3/rooms/{room_enc}/send/m.room.message"

        headers = {
            "Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}",
            "Content-Type": "application/json",
        }

        # –ß–∏—Å—Ç–∏–º Markdown –¥–ª—è plain-—Ç–µ–∫—Å—Ç–∞ (Matrix –∫–ª–∏–µ–Ω—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–æ–∫–∞–∂—É—Ç)
        body_plain = clean_markdown_for_apprise(message_markdown) or ""
        payload = {"msgtype": "m.text", "body": body_plain}

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π txnId (–≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö)
        txn_id = f"{int(time.time() * 1000)}txt"
        url = f"{base}/{txn_id}"

        # 1) –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å: PUT (—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è)
        try:
            resp = requests.put(url, headers=headers, json=payload, timeout=30)
            resp.raise_for_status()
            logging.info("Matrix text sent successfully via PUT v3")
            return resp
        except requests.exceptions.HTTPError as e:
            status = getattr(e.response, "status_code", None)
            if status == 405:
                # 2) –§–æ–ª–ª–±—ç–∫: POST —Ç–µ–º –∂–µ —É—Ä–ª–æ–º (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ reverse-proxy —Ä–µ–∂—É—Ç PUT)
                logging.warning("Matrix PUT blocked (405). Trying POST fallback‚Ä¶")
                resp2 = requests.post(url, headers=headers, json=payload, timeout=30)
                resp2.raise_for_status()
                logging.info("Matrix text sent successfully via POST fallback")
                return resp2
            else:
                logging.warning(f"Matrix text send failed via PUT: {e}")
                return None

    except Exception as ex:
        logging.warning(f"Matrix text send failed: {ex}")
        return None

def matrix_upload_image_rest(image_bytes: bytes, filename: str, mimetype: str = "image/jpeg") -> str | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ Matrix content repo –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç mxc:// URI.
    –ü—Ä–æ–±—É–µ–º v3, –ø—Ä–∏ 404/405/501 ‚Äî —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ r0.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN):
        logging.debug("Matrix not configured for media upload; skip.")
        return None

    headers = {"Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}", "Content-Type": mimetype}
    base = MATRIX_URL.rstrip("/")
    url_v3 = f"{base}/_matrix/media/v3/upload?filename={quote(filename)}"

    try:
        r = requests.post(url_v3, headers=headers, data=image_bytes, timeout=30)
        r.raise_for_status()
        return r.json().get("content_uri")
    except requests.exceptions.HTTPError as e:
        code = getattr(e.response, "status_code", None)
        if code in (404, 405, 501):
            logging.warning(f"media/v3/upload returned {code}, trying r0‚Ä¶")
            try:
                url_r0 = f"{base}/_matrix/media/r0/upload?filename={quote(filename)}"
                r2 = requests.post(url_r0, headers=headers, data=image_bytes, timeout=30)
                r2.raise_for_status()
                return r2.json().get("content_uri")
            except Exception as ex2:
                logging.warning(f"Matrix r0 upload failed: {ex2}")
                return None
        logging.warning(f"Matrix v3 upload failed: {e}")
        return None
    except Exception as ex:
        logging.warning(f"Matrix upload failed: {ex}")
        return None


def _matrix_send_event_rest(room_id: str, event_type: str, content: dict):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –∫–æ–º–Ω–∞—Ç—É:
      PUT /_matrix/client/v3/rooms/{roomId}/send/{eventType}/{txnId}
    –ü—Ä–∏ 405 ‚Äî POST –Ω–∞ —Ç–æ—Ç –∂–µ –ø—É—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –∏–ª–∏ None.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and room_id):
        return None

    room_enc = quote(room_id, safe="")
    base = f"{MATRIX_URL.rstrip('/')}/_matrix/client/v3/rooms/{room_enc}/send/{event_type}"
    txn_id = f"{int(time.time()*1000)}evt"
    url = f"{base}/{txn_id}"
    headers = {"Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}", "Content-Type": "application/json"}

    try:
        resp = requests.put(url, headers=headers, json=content, timeout=30)
        resp.raise_for_status()
        return resp
    except requests.exceptions.HTTPError as e:
        if getattr(e.response, "status_code", None) == 405:
            logging.warning("PUT blocked (405). Trying POST fallback‚Ä¶")
            try:
                resp2 = requests.post(url, headers=headers, json=content, timeout=30)
                resp2.raise_for_status()
                return resp2
            except Exception as ex2:
                logging.warning(f"Matrix POST fallback failed: {ex2}")
                return None
        logging.warning(f"Matrix send event failed via PUT: {e}")
        return None
    except Exception as ex:
        logging.warning(f"Matrix send event failed: {ex}")
        return None

def _fetch_jellyfin_primary(photo_id: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (bytes, mimetype, filename) –¥–ª—è Primary-–ø–æ—Å—Ç–µ—Ä–∞ –∏–∑ Jellyfin.
    """
    url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    resp = requests.get(url, timeout=30)
    resp.raise_for_status()
    mimetype = resp.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
    ext = ".jpg"
    if "png" in mimetype:
        ext = ".png"
    elif "webp" in mimetype:
        ext = ".webp"
    filename = f"poster{ext}"
    return resp.content, mimetype, filename


def send_matrix_image_then_text_from_jellyfin(photo_id: str, caption_markdown: str) -> bool:
    """
    1) –¢—è–Ω–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin
    2) –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Matrix (media repo) -> mxc://
    3) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º m.image (body = –∏–º—è —Ñ–∞–π–ª–∞)
    4) –û—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç (m.text)
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID):
        logging.debug("Matrix not configured; skip.")
        return False

    # 1) –∫–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ Jellyfin
    try:
        img_bytes, mimetype, filename = _fetch_jellyfin_primary(photo_id)
    except Exception as ex:
        logging.warning(f"Matrix(JF): cannot fetch image from Jellyfin: {ex}")
        # —Ö–æ—Ç—è –±—ã —Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏–º
        resp_txt = send_matrix_text_rest(caption_markdown)
        return bool(resp_txt and resp_txt.ok)

    # 2) upload -> mxc://
    mxc_uri = matrix_upload_image_rest(img_bytes, filename, mimetype)
    if not mxc_uri:
        logging.warning("Matrix(JF): media upload failed; sending text only.")
        resp_txt = send_matrix_text_rest(caption_markdown)
        return bool(resp_txt and resp_txt.ok)

    # 3) m.image (–í–ê–ñ–ù–û: body ‚Äî –∏–º—è —Ñ–∞–π–ª–∞)
    content_img = {
        "msgtype": "m.image",
        "body": filename,
        "url": mxc_uri,
        "info": {
            "mimetype": mimetype,
            "size": len(img_bytes),
        },
    }
    resp_img = _matrix_send_event_rest(MATRIX_ROOM_ID, "m.room.message", content_img)
    img_ok = bool(resp_img and resp_img.ok)

    # 4) –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
    resp_txt = send_matrix_text_rest(caption_markdown)
    txt_ok = bool(resp_txt and resp_txt.ok)

    if img_ok and txt_ok:
        logging.info("Matrix(JF): image then text sent successfully.")
    else:
        logging.warning("Matrix(JF): image+text flow partially/fully failed.")
    return img_ok and txt_ok

def send_gotify_message(photo_id, message, title="Jellyfin", priority=5, uploaded_url=None):
    img_url = wait_for_imgbb_upload()
    if not img_url:
        logging.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –≤ Gotify.")
        return
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞–ø—Ä—è–º—É—é –≤ Gotify.
    """
    if not GOTIFY_URL or not GOTIFY_TOKEN:
        logging.warning("GOTIFY_URL or GOTIFY_TOKEN not set, skipping Gotify notification.")
        return None

    if uploaded_url is None:
        uploaded_url = get_jellyfin_image_and_upload_imgbb(photo_id)
    if uploaded_url:
        message = f"![Poster]({uploaded_url})\n\n{message}"
        big_image_url = uploaded_url
    else:
        big_image_url = None

    gotify_url = GOTIFY_URL.rstrip('/')
    url = f"{gotify_url}/message?token={GOTIFY_TOKEN}"

    data = {
        "title": title,
        "message": message,
        "priority": priority,
        "extras": {
            "client::display": {"contentType": "text/markdown"}
        }
    }
    if big_image_url:
        data["extras"]["client::notification"] = {"bigImageUrl": big_image_url}
    headers = {"X-Gotify-Format": "markdown"}

    try:
        response = requests.post(url, json=data, headers=headers)
        response.raise_for_status()
        logging.info("Gotify notification sent successfully")
        return response
    except Exception as ex:
        logging.warning(f"Error sending to Gotify: {ex}")
        return None

def send_signal_message_with_image(photo_id, message, SIGNAL_NUMBER, SIGNAL_RECIPIENTS, api_url=SIGNAL_URL):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin –≤ Signal —á–µ—Ä–µ–∑ base64_attachments.
    """
    # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    try:
        image_resp = requests.get(jellyfin_image_url)
        image_resp.raise_for_status()
        image_bytes = image_resp.content
        # –ö–æ–¥–∏—Ä—É–µ–º –≤ base64
        image_b64 = base64.b64encode(image_bytes).decode("utf-8")

        data = {
            "message": message,
            "number": SIGNAL_NUMBER,
            "recipients": SIGNAL_RECIPIENTS if isinstance(SIGNAL_RECIPIENTS, list) else [SIGNAL_RECIPIENTS],
            "base64_attachments": [image_b64],
        }

        resp = requests.post(api_url, json=data)
        resp.raise_for_status()
        logging.info("Signal image message sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Error sending Signal image message: {ex}")
        return None


def send_whatsapp_image_via_rest(
    caption: str,
    phone_jid: str = None,
    image_url: str = None,
#    photo_id: str = None,   # —Ç–µ–ø–µ—Ä—å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π
    view_once: bool = False,
    compress: bool = False,
    duration: int = 0,
    is_forwarded: bool = False,
):
    img_url = wait_for_imgbb_upload()
    if not img_url:
        logging.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –≤ WhatsApp.")
        return
    if not WHATSAPP_API_URL:
        logging.warning("WHATSAPP_API_URL not set, skipping WhatsApp image.")
        return None

    phone_jid = phone_jid or _wa_get_jid_from_env()
    if not phone_jid:
        logging.warning("WhatsApp JID is empty, skip sending image.")
        return None

    url = f"{WHATSAPP_API_URL.rstrip('/')}/send/image"
    auth = (WHATSAPP_API_USERNAME, WHATSAPP_API_PWD)

    form = {
        "phone": phone_jid,
        "caption": sanitize_whatsapp_text(caption or ""),
        "view_once": str(bool(view_once)).lower(),
        "compress": str(bool(compress)).lower(),
        "duration": str(int(duration)),
        "is_forwarded": str(bool(is_forwarded)).lower(),
    }

    files = None
    jellyfin_used = False

    if image_url:
        form["image_url"] = image_url
    else:
        logging.warning("WhatsApp image: image_url –Ω–µ –∑–∞–¥–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return None

    try:
        resp = requests.post(url, data=form, files=files, auth=auth, timeout=30)
        resp.raise_for_status()
        logging.info("WhatsApp image sent successfully")
        return resp
    except requests.exceptions.RequestException as e:
        logging.warning(f"Error sending WhatsApp image: {e}")
        return None


def get_item_details(item_id):
    headers = {'accept': 'application/json', }
    params = {'api_key': JELLYFIN_API_KEY, }
    url = f"{JELLYFIN_BASE_URL}/emby/Items?Recursive=true&Fields=DateCreated, Overview&Ids={item_id}"
    response = requests.get(url, headers=headers, params=params)
    response.raise_for_status()  # Check if request was successful
    return response.json()


def is_within_last_x_days(date_str, x):
    days_ago = datetime.now() - timedelta(days=x)
    return date_str >= days_ago.isoformat()


def is_not_within_last_x_days(date_str, x):
    days_ago = datetime.now() - timedelta(days=x)
    return date_str < days_ago.isoformat()


def get_youtube_trailer_url(query):
    base_search_url = "https://www.googleapis.com/youtube/v3/search"
    if not YOUTUBE_API_KEY:
        return None
    api_key = YOUTUBE_API_KEY

    params = {
        'part': 'snippet',
        'q': query,
        'type': 'video',
        'key': api_key
    }

    response = requests.get(base_search_url, params=params)
    response.raise_for_status()  # Check for HTTP errors before processing the data
    response_data = response.json()
    video_id = response_data.get("items", [{}])[0].get('id', {}).get('videoId')

    return f"https://www.youtube.com/watch?v={video_id}" if video_id else "Video not found!"


def item_already_notified(item_type, item_name, release_year):
    # –í —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –≤—Å–µ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –µ—â—ë –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏
    if DISABLE_DEDUP:
        logging.debug("Dedup is disabled: treating as NOT notified.")
        return False

    key = f"{item_type}:{item_name}:{release_year}"
    return notified_items.get(key) is True


def mark_item_as_notified(item_type, item_name, release_year, max_items=100):
    # –í —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∏—à–µ–º –≤ —Ñ–∞–π–ª
    if DISABLE_DEDUP:
        logging.debug("Dedup is disabled: NOT recording notified key.")
        return

    key = f"{item_type}:{item_name}:{release_year}"
    notified_items[key] = True

    # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä ¬´–ø–∞–º—è—Ç–∏¬ª
    if len(notified_items) > max_items:
        # –µ—Å–ª–∏ —É–∂–µ —Ö—Ä–∞–Ω–∏—Ç–µ timestamp ‚Äî —É–¥–∞–ª—è–π—Ç–µ —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π; –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ pop –ø–µ—Ä–≤–æ–≥–æ
        notified_items.pop(next(iter(notified_items)))
    save_notified_items(notified_items)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –≤–∏–¥–µ–æ

def _get_item_media_info_movie(item_id: str) -> dict:
    """
    –¢—è–Ω–µ–º MediaSources/MediaStreams –¥–ª—è —Ñ–∏–ª—å–º–∞ –∏ —É–ø–ª–æ—â–∞–µ–º –≤ dict.
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º:
      - —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫: audio_tracks + –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
      - –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: image_profiles (['DV','HDR10',...]) –∏ image_profile_str ("DV, HDR10")
    """
    try:
        headers = {'accept': 'application/json'}
        params = {'api_key': JELLYFIN_API_KEY}
        url = f"{JELLYFIN_BASE_URL}/emby/Items?Ids={item_id}&Fields=MediaSources,RunTimeTicks"
        r = requests.get(url, headers=headers, params=params, timeout=12)
        r.raise_for_status()
        data = r.json()
        item = (data.get("Items") or [{}])[0]
        sources = item.get("MediaSources") or []
        if not sources:
            return {}
        src = sources[0]

        container = src.get("Container")
        overall_bitrate = src.get("Bitrate")
        size_bytes = src.get("Size")
        duration_ticks = src.get("RunTimeTicks") or item.get("RunTimeTicks")
        duration_sec = duration_ticks / 10_000_000 if duration_ticks else None

        vcodec = None; vbitrate = None; width = None; height = None; dyn = None; vdepth = None; fps = None
        acodec = None; abitrate = None; channels = None

        audio_tracks = []
        image_profiles = None  # NEW

        for s in (src.get("MediaStreams") or []):
            stype = s.get("Type")
            if stype == "Video" and vcodec is None:
                # ... –≤–∞—à –∫–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π ...
                try:
                    image_profiles = _detect_image_profiles_from_fields(s)
                except Exception:
                    image_profiles = None
                # >>> –§–û–õ–ë–≠–ö
                if not image_profiles:
                    image_profiles = ["SDR"]
                # <<<
                vcodec = s.get("Codec")
                vbitrate = s.get("BitRate") or s.get("bitrate") or overall_bitrate
                width = s.get("Width"); height = s.get("Height")
                fps = s.get("AverageFrameRate") or s.get("RealFrameRate")
                vdepth = s.get("BitDepth") or s.get("VideoBitDepth")
                dyn = s.get("ColorTransfer") or s.get("VideoRange") or s.get("ColorPrimaries")
                if isinstance(dyn, str):
                    u = dyn.upper()
                    dyn = "HDR" if ("PQ" in u or "HLG" in u or "HDR" in u or "BT2020" in u) else "SDR"

                # NEW: –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (DV / HDR10+ / HDR10 / HLG / HDR / SDR)
                try:
                    image_profiles = _detect_image_profiles_from_fields(s)
                except Exception:
                    image_profiles = None

            elif stype == "Audio":
                # –æ—Å–Ω–æ–≤–Ω–æ–π –∞—É–¥–∏–æ-—Å–Ω–∏–º–æ–∫ (–¥–ª—è —Å–≤–æ–¥–∫–∏)
                if acodec is None:
                    acodec = s.get("Codec")
                    abitrate = s.get("BitRate") or s.get("bitrate")
                    channels = s.get("Channels")
                # —á–∏—Ç–∞–µ–º ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ¬ª –∏–º—è –¥–æ—Ä–æ–∂–∫–∏
                label = s.get("DisplayTitle") or s.get("Title")
                if not label:
                    lang = s.get("Language")
                    codec = s.get("Codec")
                    ch = s.get("Channels")
                    layout = s.get("ChannelLayout")
                    parts = []
                    if lang:   parts.append(str(lang).upper())
                    if codec:  parts.append(str(codec).upper())
                    if ch:     parts.append(f"{ch}ch")
                    if layout: parts.append(layout)
                    label = " ".join(parts) or "Audio"
                audio_tracks.append(label)

        approx_kbps = None
        if (not vbitrate) and size_bytes and duration_sec and duration_sec > 0:
            approx_kbps = int((size_bytes * 8) / duration_sec / 1000)

        return {
            "video_codec": vcodec,
            "video_bitrate": vbitrate,
            "approx_video_kbps": approx_kbps,
            "width": width,
            "height": height,
            "fps": fps,
            "bit_depth": vdepth,
            "dynamic_range": dyn or "SDR",
            "audio_codec": acodec,
            "audio_bitrate": abitrate,
            "audio_channels": channels,
            "container": container,
            "size_bytes": size_bytes,
            "duration_sec": duration_sec,
            # –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏
            "audio_tracks": audio_tracks,
            "audio_track_count": len(audio_tracks),
            # NEW: –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ñ–æ–ª–±—ç–∫–æ–º
            "image_profiles": image_profiles or ["SDR"],
            "image_profile_str": ", ".join(image_profiles or ["SDR"]),
        }
    except Exception as ex:
        logging.warning(f"Media info fetch failed for movie {item_id}: {ex}")
        return {}

def build_audio_tracks_block(q: dict) -> str:
    tracks = (q or {}).get("audio_tracks") or []
    if not tracks:
        return ""
    header = t("audio_tracks")
    lines = "\n".join(f"- {name}" for name in tracks)
    return f"\n\n*{header} ({len(tracks)})*\n{lines}"

def _quality_signature(q: dict) -> str:
    """
    –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–ª—é—á –∫–∞—á–µ—Å—Ç–≤–∞: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–µ–∞–ª—å–Ω–æ–π –∑–∞–º–µ–Ω–µ —Ñ–∞–π–ª–∞.
    """
    def part(x): return "-" if x in (None, "", 0) else str(x)
    vbr = q.get("video_bitrate") or q.get("approx_video_kbps")
    return "|".join([
        part(q.get("video_codec")),
        f"{part(q.get('width'))}x{part(q.get('height'))}",
        part(vbr),
        part(q.get("dynamic_range")),
        part(q.get("bit_depth")),
        part(q.get("fps")),
        part(q.get("audio_codec")),
        part(q.get("audio_channels")),
        part(q.get("audio_bitrate")),
        part(q.get("container")),
        part(q.get("size_bytes")),
    ])

def _quality_is_substantial(q: dict | None) -> bool:
    """False, –µ—Å–ª–∏ ¬´–ø—É—Å—Ç–æ–π¬ª —Å–Ω–∏–º–æ–∫ (Jellyfin –µ—â—ë –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª –ø–æ—Ç–æ–∫–∏)."""
    if not q: return False
    return any([
        q.get("video_codec"),
        (q.get("width") and q.get("height")),
        q.get("audio_codec"),
        q.get("container"),
        q.get("size_bytes"),
    ])

def _fmt_mbps(q: dict) -> str:
    vbr = q.get("video_bitrate")
    if vbr:
        try: return f"{int(vbr)/1000:.1f} Mbps"
        except: return f"{vbr} kbps"
    kbps = q.get("approx_video_kbps")
    return f"{kbps/1000:.1f} Mbps (‚âà)" if kbps else "-"

def _movie_logical_key(*, tmdb_id: str | None, imdb_id: str | None, name: str, year: int | None) -> str:
    if tmdb_id: return f"movie:tmdb:{tmdb_id}"
    if imdb_id: return f"movie:imdb:{imdb_id}"
    # —Ñ–æ–ª–±—ç–∫: name+year –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    key_name = re.sub(r"\s+", " ", (name or "").strip().lower())
    return f"movie:nameyear:{key_name}:{year or ''}"

def store_quality_snapshot_movie(*, item_id: str, name: str, year: int | None,
                                 tmdb_id: str | None, imdb_id: str | None) -> dict:
    """
    1) –¢—è–Ω–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑ Jellyfin
    2) Upsert –≤ media_quality (–ø–æ ItemId)
    3) –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ upsert –≤ content_quality (–ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É)
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–ª–∞–≥–∏: logical_inserted, logical_changed, old_quality, new_quality
    """
    q = _get_item_media_info_movie(item_id)
    sig = _quality_signature(q)
    now = datetime.now().isoformat(timespec='seconds')

    profiles_str = (q.get("image_profile_str") or
                    ",".join(_profiles_from_q(q)))  # "DV,HDR10" –∏–ª–∏ "SDR"

    result = {
        "logical_inserted": False,
        "logical_changed": False,
        "old_quality": None,
        "new_quality": q,
        "old_signature": None,
        "new_signature": sig,
        "logical_key": None
    }

    logical_key = _movie_logical_key(tmdb_id=tmdb_id, imdb_id=imdb_id, name=name, year=year)
    result["logical_key"] = logical_key

    conn = sqlite3.connect(QUALITY_DB_FILE)
    try:
        cur = conn.cursor()
        # --- media_quality –ø–æ ItemId
        cur.execute("SELECT signature FROM media_quality WHERE item_id=?", (item_id,))
        if cur.fetchone() is None:
            cur.execute("""INSERT INTO media_quality
                           (item_id, movie_name, year, video_codec, video_bitrate, width, height, fps, bit_depth,
                            dynamic_range,
                            audio_codec, audio_bitrate, audio_channels, container, size_bytes, duration_sec, signature,
                            date_seen, image_profiles)
                           VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                        (item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                         q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                         q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                         q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now, profiles_str)
                        )
        else:
            cur.execute("""UPDATE media_quality
                           SET movie_name=?,
                               year=?,
                               video_codec=?,
                               video_bitrate=?,
                               width=?,
                               height=?,
                               fps=?,
                               bit_depth=?,
                               dynamic_range=?,
                               audio_codec=?,
                               audio_bitrate=?,
                               audio_channels=?,
                               container=?,
                               size_bytes=?,
                               duration_sec=?,
                               signature=?,
                               date_seen=?,
                               image_profiles=?
                           WHERE item_id = ?""",
                        (name, year, q.get("video_codec"), q.get("video_bitrate"),
                         q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                         q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                         q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now, profiles_str,
                         item_id)
                        )

        # --- content_quality –ø–æ logical_key
        cur.execute("""SELECT signature,
                              last_item_id,
                              video_codec,
                              video_bitrate,
                              width,
                              height,
                              fps,
                              bit_depth,
                              dynamic_range,
                              image_profiles,
                              audio_codec,
                              audio_bitrate,
                              audio_channels,
                              container,
                              size_bytes,
                              duration_sec
                       FROM content_quality
                       WHERE logical_key = ?""", (logical_key,))
        row = cur.fetchone()
        if row is None:
            if _quality_is_substantial(q):
                cur.execute("""INSERT INTO content_quality
                               (logical_key, last_item_id, movie_name, year, video_codec, video_bitrate, width, height,
                                fps, bit_depth,
                                dynamic_range, image_profiles, audio_codec, audio_bitrate, audio_channels, container,
                                size_bytes, duration_sec, signature, date_seen)
                               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                            (logical_key, item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                             q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                             profiles_str, q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                             q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now)
                            )
                result["logical_inserted"] = True
        else:
            old_sig, old_item_id = row[0], row[1]
            old_q = {
                "video_codec": row[2], "video_bitrate": row[3], "width": row[4], "height": row[5],
                "fps": row[6], "bit_depth": row[7], "dynamic_range": row[8],
                "image_profiles": ([p.strip() for p in row[9].split(",")] if row[9] else None),
                "audio_codec": row[10], "audio_bitrate": row[11], "audio_channels": row[12],
                "container": row[13], "size_bytes": row[14], "duration_sec": row[15]
            }
            result["old_signature"] = old_sig
            result["old_quality"] = old_q

            if old_sig != sig and _quality_is_substantial(old_q) and _quality_is_substantial(q):
                result["logical_changed"] = True
                cur.execute("""UPDATE content_quality
                               SET last_item_id=?,
                                   movie_name=?,
                                   year=?,
                                   video_codec=?,
                                   video_bitrate=?,
                                   width=?,
                                   height=?,
                                   fps=?,
                                   bit_depth=?,
                                   dynamic_range=?,
                                   image_profiles=?,
                                   audio_codec=?,
                                   audio_bitrate=?,
                                   audio_channels=?,
                                   container=?,
                                   size_bytes=?,
                                   duration_sec=?,
                                   signature=?,
                                   date_seen=?
                               WHERE logical_key = ?""",
                            (item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                             q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                             profiles_str, q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                             q.get("container"), q.get("size_bytes"), q.get("duration_sec"),
                             sig, now, logical_key)
                            )
        conn.commit()
    finally:
        conn.close()
    return result

def _labels():
    if LANG == "ru":
        return {
            "changes": "–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞",
            "resolution": "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ",
            "video_codec": "–í–∏–¥–µ–æ-–∫–æ–¥–µ–∫",
            "bitrate": "–ë–∏—Ç—Ä–µ–π—Ç (–≤–∏–¥–µ–æ)",
            "dynamic_range": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω",
            "audio": "–ê—É–¥–∏–æ",
            "container": "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä",
            "fps": "–ö–∞–¥—Ä–æ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞",
            "bit_depth": "–ë–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞",
        }
    return {
        "changes": "Quality changes",
        "resolution": "Resolution",
        "video_codec": "Video codec",
        "bitrate": "Bitrate (video)",
        "dynamic_range": "Dynamic range",
        "audio": "Audio",
        "container": "Container",
        "fps": "Frame rate",
        "bit_depth": "Bit depth",
    }

def build_quality_changes_block(old_q: dict, new_q: dict) -> str:
    L = _labels()
    lines = []

    def arrow(a, b):
        return f"{a} ‚Üí {b}"

    # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    # --- Resolution (—Å —è—Ä–ª—ã–∫–∞–º–∏) ---
    res_old = _res_display_from_q(old_q)
    res_new = _res_display_from_q(new_q)
    if res_old != res_new:
        lines.append(f"- {L['resolution']}: {arrow(res_old, res_new)}")

    # –í–∏–¥–µ–æ-–∫–æ–¥–µ–∫
    vc_old = (old_q.get("video_codec") or "-").upper()
    vc_new = (new_q.get("video_codec") or "-").upper()
    if vc_old != vc_new:
        lines.append(f"- {L['video_codec']}: {arrow(vc_old, vc_new)}")

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω (SDR/HDR –∏ —Ç.–ø.)
    dr_old = old_q.get("dynamic_range") or "-"
    dr_new = new_q.get("dynamic_range") or "-"
    if dr_old != dr_new:
        lines.append(f"- {L['dynamic_range']}: {arrow(dr_old, dr_new)}")

    # –ü—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (SDR/HDR/HDR10/HDR10+/DV/HLG)
    old_profiles = ", ".join(_profiles_from_q(old_q))
    new_profiles = ", ".join(_profiles_from_q(new_q))
    if old_profiles != new_profiles:
        lines.append(f"- {t('image_profiles')}: {old_profiles} ‚Üí {new_profiles}")
    logging.debug(f"Quality delta profiles: old='{old_profiles}' new='{new_profiles}'")
    if not lines:
        return ""
    return f"\n\n*{L['changes']}*\n" + "\n".join(lines)

def build_initial_quality_changes_block(new_q: dict) -> str:
    """
    –ë–ª–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –ù–û–í–û–ì–û —Ñ–∏–ª—å–º–∞ –±–µ–∑ —Å—Ç—Ä–µ–ª–æ–∫ –∏ –±–µ–∑ 'Dynamic range'.
    –ü–æ–∫–∞–∑—ã–≤–∞–µ–º: Resolution, Video codec, Image profiles.
    """
    L = _labels()
    lines = []

    # Resolution
    # Resolution -> —è—Ä–ª—ã–∫ (–∏–ª–∏ WxH –ø—Ä–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º)
    res_new = _res_display_from_q(new_q)
    if res_new != "-":
        lines.append(f"- {L['resolution']}: {res_new}")

    # Video codec
    vc_new = (new_q.get("video_codec") or "-").upper()
    if vc_new != "-":
        lines.append(f"- {L['video_codec']}: {vc_new}")

    # Image profiles (SDR/HDR/HDR10/HDR10+/DV/HLG)
    profiles = ", ".join(_profiles_from_q(new_q))
    lines.append(f"- {t('image_profiles')}: {profiles}")

    if not lines:
        return ""
    return f"\n\n*{L['changes']}*\n" + "\n".join(lines)



def maybe_notify_movie_quality_change(*, item_id: str, movie_name_cleaned: str, release_year: int | None,
                                      tmdb_id: str | None, imdb_id: str | None,
                                      overview: str | None, runtime: str | None) -> bool:
    """
    –ï—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å–º–∞ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å (–ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É) ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    —Ç–µ–º –∂–µ —à–∞–±–ª–æ–Ω–æ–º, —á—Ç–æ –∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞, + –±–ª–æ–∫ '–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ (–æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ 'New Movie' —Å–ª–∞—Ç—å –Ω–µ –Ω–∞–¥–æ).
    """
    res = store_quality_snapshot_movie(
        item_id=item_id, name=movie_name_cleaned, year=release_year,
        tmdb_id=tmdb_id, imdb_id=imdb_id
    )
    if not res.get("logical_changed"):
        return False

    old_q = res.get("old_quality")
    new_q = res.get("new_quality")
    # –ï—Å–ª–∏ —Å—Ç–∞—Ä—ã–π —Å–Ω–∏–º–æ–∫ ¬´–ø—É—Å—Ç–æ–π¬ª ‚Äî —ç—Ç–æ –ø–µ—Ä–≤—ã–π –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å –Ω–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞; —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ –ù–ï –∞–ø–≥—Ä–µ–π–¥.
    if not _quality_is_substantial(old_q):
        logging.info("(Movie guard) Old quality is empty -> treat as NEW content, not a quality update.")
        return False

    # –°–æ–±–∏—Ä–∞–µ–º ¬´–∫–∞–∫ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏¬ª
    notification_message = (
        f"*{t('quality_updated')}*\n\n*{movie_name_cleaned}* *({release_year})*\n\n{overview or ''}\n\n"
        f"*{t('new_runtime')}*\n{runtime or ''}"
    )

    # —Ä–µ–π—Ç–∏–Ω–≥–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å tmdb_id)
    if tmdb_id:
        ratings_text = fetch_mdblist_ratings("movie", tmdb_id)
        if ratings_text:
            notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"

    # —Ç—Ä–µ–π–ª–µ—Ä
    trailer_url = get_youtube_trailer_url(f"{movie_name_cleaned} Trailer {release_year}")
    if trailer_url:
        notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

    # –¥–æ–±–∞–≤–∏–º –±–ª–æ–∫ ¬´—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å¬ª
    # –¥–æ–±–∞–≤–∏–º –±–ª–æ–∫ ¬´—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å¬ª
    delta = build_quality_changes_block(old_q, new_q)
    if delta:
        notification_message += delta

    # –î–û–ë–ê–í–¨ –£–°–õ–û–í–ò–ï:
    if INCLUDE_AUDIO_TRACKS:
        tracks_block = build_audio_tracks_block(new_q)
        if tracks_block:
            notification_message += tracks_block

    send_notification(item_id, notification_message)
    touch_quality_update_marker(res.get("logical_key") or _movie_logical_key(
        tmdb_id=tmdb_id, imdb_id=imdb_id, name=movie_name_cleaned, year=release_year
    ), item_id=item_id)
    logging.info(f"(Movie) Quality update sent for {movie_name_cleaned} ({release_year}); logical_key={res.get('logical_key')}")
    return True

def _format_runtime_from_ticks(runtime_ticks) -> str:
    if not runtime_ticks:
        return ""
    try:
        total_sec = int(runtime_ticks) // 10_000_000
        h = total_sec // 3600
        m = (total_sec % 3600) // 60
        if h > 0:
            return f"{h}h {m}m"
        return f"{m}m"
    except Exception:
        return ""
def poll_recent_movies_once():
    """
    –ü–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ç—è–Ω–µ–º —Ñ–∏–ª—å–º—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞–ø–≥—Ä–µ–π–¥—ã –∫–∞—á–µ—Å—Ç–≤–∞.
    –ù–æ–≤—ã–µ (–æ—á–µ–Ω—å —Å–≤–µ–∂–∏–µ) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –∏—Ö –æ–±—ä—è–≤–∏—Ç –≤–µ–±—Ö—É–∫.
    """
    page_size = MOVIE_POLL_PAGE_SIZE
    # —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Å—Ç–∞—Ä—ã–π MOVIE_POLL_LIMIT –∏ MAX_TOTAL == 0, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –ø—Ä–µ–¥–µ–ª
    max_total = MOVIE_POLL_MAX_TOTAL  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    while True:
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        current_limit = page_size
        if max_total and (max_total - fetched) < page_size:
            current_limit = max_total - fetched
            if current_limit <= 0:
                break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                # DateCreated –Ω—É–∂–µ–Ω –¥–ª—è –≥—Ä–µ–π—Å-—Ñ–∏–ª—å—Ç—Ä–∞ (—á—Ç–æ–±—ã –≤–µ–±—Ö—É–∫ –æ–±—ä—è–≤–ª—è–ª ¬´–Ω–æ–≤—ã–µ¬ª)
                "Fields": "MediaSources,RunTimeTicks,ProviderIds,ProductionYear,Overview,DateCreated"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Movie poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            try:
                # --- –≥—Ä–µ–π—Å: —Å–≤–µ–∂–∏–µ –Ω–æ–≤–∏–Ω–∫–∏ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º (–ø—É—Å—Ç—å –≤–µ–±—Ö—É–∫ –ø–æ—à–ª—ë—Ç 'New Movie Added')
                created_iso = it.get("DateCreated")
                created_dt = _parse_iso_utc(created_iso)
                if created_dt and (now_utc - created_dt) < timedelta(minutes=MOVIE_POLL_GRACE_MIN):
                    logging.debug(f"Movie poll: skip fresh item (created {created_dt.isoformat()}): {it.get('Name')}")
                    continue
                # -------------------------------------------------------------

                item_id = it.get("Id")
                name = it.get("Name") or ""
                year = it.get("ProductionYear")
                prov = it.get("ProviderIds") or {}
                tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
                imdb_id = prov.get("Imdb") or prov.get("ImdbId")

                # –ò–º—è –±–µ–∑ –≥–æ–¥–∞ –≤ —Å–∫–æ–±–∫–∞—Ö (–∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ)
                name_clean = name.replace(f" ({year})", "").strip()

                # Overview/Runtime –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                overview = it.get("Overview") or ""
                runtime_str = _format_runtime_from_ticks(it.get("RunTimeTicks"))

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –∞–ø–¥–µ–π—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–Ω–µ ¬´–Ω–æ–≤—ã–π —Ñ–∏–ª—å–º¬ª)
                sent = maybe_notify_movie_quality_change(
                    item_id=item_id,
                    movie_name_cleaned=name_clean,
                    release_year=year,
                    tmdb_id=tmdb_id,
                    imdb_id=imdb_id,
                    overview=overview,
                    runtime=runtime_str
                )
                if sent:
                    # –∑–∞–ø–∏—Å—å –≤ –ë–î —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞; –ø–æ–≤—Ç–æ—Ä–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –ø—Ä–æ—Ö–æ–¥–µ –Ω–µ –±—É–¥–µ—Ç
                    continue
            except Exception as ex:
                logging.warning(f"Movie poll: item {it.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        logging.debug(f"Movie poll: page fetched {n} items (total {fetched})")

        # –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ–ø–æ–ª–Ω–∞—è ‚Äî –¥–∞–ª—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç
        if n < current_limit:
            break

        # –º—è–≥–∫–æ–µ –¥—ã—Ö–∞–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        time.sleep(0.1)

def _detect_image_profiles_from_fields(s: dict) -> list[str]:
    """
    –î–µ—Ç–µ–∫—Ç DV / HDR10+ / HDR10 / HLG / HDR / SDR –ø–æ –ø–æ–ª—è–º –≤–∏–¥–µ–æ-–ø–æ—Ç–æ–∫–∞.
    –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º ['SDR'].
    """
    txt_parts = []
    for k in ("ColorTransfer","VideoRange","VideoRangeType","ColorPrimaries","ColorSpace",
              "Profile","Hdr","Hdr10Plus","DolbyVision","DoVi","VideoDoViProfile"):
        v = s.get(k)
        if isinstance(v, bool):
            v = "1" if v else "0"
        if v is not None:
            txt_parts.append(str(v))
    txt = " ".join(txt_parts).upper()

    prof = []
    def add(tag):
        if tag not in prof:
            prof.append(tag)

    if "DOLBY VISION" in txt or "DOVI" in txt or "VIDEO DOVIPROFILE" in txt or re.search(r"\bDV\b", txt or ""):
        add("DV")
    if "HDR10+" in txt or "HDR10PLUS" in txt or "HDR10 PLUS" in txt:
        add("HDR10+")
    if "HDR10" in txt:
        add("HDR10")
    if "HLG" in txt:
        add("HLG")
    if ("HDR" in txt or "PQ" in txt or "BT2020" in txt) and not any(p in prof for p in ("DV","HDR10+","HDR10","HLG")):
        add("HDR")
    if not prof:
        add("SDR")

    order = {"DV":0,"HDR10+":1,"HDR10":2,"HLG":3,"HDR":4,"SDR":5}
    prof.sort(key=lambda x: order.get(x, 99))
    return prof

def _profiles_from_q(q: dict | None) -> list[str]:
    order = {"DV": 0, "HDR10+": 1, "HDR10": 2, "HLG": 3, "HDR": 4, "SDR": 5}
    if not q:
        return ["SDR"]

    profs = (q.get("image_profiles") or [])
    if not profs:
        dr = (q.get("dynamic_range") or "").upper()
        if "DV" in dr or "DOLBY" in dr:
            profs = ["DV"]
        elif "HDR10+" in dr:
            profs = ["HDR10+"]
        elif "HDR10" in dr:
            profs = ["HDR10"]
        elif "HLG" in dr:
            profs = ["HLG"]
        elif "HDR" in dr:
            profs = ["HDR"]
        else:
            profs = ["SDR"]

    # ‚Üê –≤–æ—Ç —ç—Ç–∏ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ:
    profs = [str(p).strip().upper() for p in profs if str(p).strip()]
    profs = list(dict.fromkeys(profs))

    profs.sort(key=lambda p: order.get(p, 99))
    return profs

def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')

def _iso_to_dt(s: str | None) -> datetime | None:
    if not s: return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00'))
    except Exception:
        return None

def touch_quality_update_marker(logical_key: str, item_id: str | None = None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""INSERT INTO recent_quality_updates (logical_key, notified_at, item_id)
                       VALUES (?, ?, ?)
                       ON CONFLICT(logical_key) DO UPDATE SET
                         notified_at=excluded.notified_at,
                         item_id=excluded.item_id
                    """, (logical_key, _now_utc_iso(), item_id))
        conn.commit()
    except Exception as ex:
        logging.warning(f"touch_quality_update_marker failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def was_quality_update_recent(logical_key: str) -> bool:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT notified_at FROM recent_quality_updates WHERE logical_key=?", (logical_key,))
        row = cur.fetchone()
    except Exception as ex:
        logging.warning(f"was_quality_update_recent check failed: {ex}")
        return False
    finally:
        try: conn.close()
        except: pass

    if not row:
        return False
    ts = _iso_to_dt(row[0])
    if not ts:
        return False
    return (datetime.now(timezone.utc) - ts) < timedelta(minutes=SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN)

def _parse_iso_utc(s: str | None):
    if not s:
        return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00')).astimezone(timezone.utc)
    except Exception:
        return None


def _movie_poll_loop():
    while True:
        try:
            poll_recent_movies_once()
        except Exception as ex:
            logging.warning(f"Movie poll loop error: {ex}")
        time.sleep(MOVIE_POLL_INTERVAL_SEC)

if MOVIE_POLL_ENABLED:
    threading.Thread(target=_movie_poll_loop, name="movie-poll", daemon=True).start()
    logging.info(f"Movie quality polling enabled every {MOVIE_POLL_INTERVAL_SEC}s (limit={MOVIE_POLL_MAX_TOTAL})")

def _resolution_label(width: int | None, height: int | None) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —è—Ä–ª—ã–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è (8K, 5K, 4K (UltraHD), 1440p, 1080p, 720p, 576p, 480p, 360p, 240p).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã—Å–æ—Ç—É –∫–∞–¥—Ä–∞ —Å –¥–æ–ø—É—Å–∫–æ–º (~8%) –Ω–∞ ¬´–Ω–µ–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ¬ª –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2026 ‚âà 2160).
    –ï—Å–ª–∏ –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –Ω–∏ –≤ –æ–¥–∏–Ω –¥–∏–∞–ø–∞–∑–æ–Ω ‚Äî –≤–µ—Ä–Ω—ë—Ç None.
    """
    if not height:
        return None

    # (target_height, label)
    targets = [
        (4320, "8K"),
        (2880, "5K"),
        (2160, "4K (UltraHD)"),
        (1440, "1440p"),
        (1080, "1080p"),
        (720,  "720p"),
        (576,  "576p"),
        (480,  "480p"),
        (360,  "360p"),
        (240,  "240p"),
    ]
    for h, label in targets:
        tol = max(int(h * 0.08), 12)  # ~8% –∏–ª–∏ –º–∏–Ω–∏–º—É–º 12px
        if abs(height - h) <= tol:
            return label
    return None

def _res_display_from_q(q: dict | None) -> str:
    """
    –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:
    - –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —è—Ä–ª—ã–∫ 8K/4K/... -> –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ
    - –∏–Ω–∞—á–µ –≤–µ—Ä–Ω—É—Ç—å 'WxH'
    - –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç -> '-'
    """
    if not q:
        return "-"
    w, h = q.get("width"), q.get("height")
    if not (w and h):
        return "-"
    label = _resolution_label(w, h)
    return label or f"{w}x{h}"

#–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace("+00:00", "Z")

def _iso_to_dt(s: str | None) -> datetime | None:
    if not s: return None
    try: return datetime.fromisoformat(s.replace("Z","+00:00")).astimezone(timezone.utc)
    except Exception: return None

def _collect_current_movie_keys_and_ids() -> tuple[set[str], set[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (set –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–π, set ItemId) –¥–ª—è –í–°–ï–• —Ñ–∏–ª—å–º–æ–≤ –≤ Jellyfin.
    –ö–ª—é—á —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ _movie_logical_key(...) –ø–æ ProviderIds/Tmdb/Imdb -> name+year.
    """
    current_keys: set[str] = set()
    current_ids: set[str] = set()

    start = 0
    page_size = QUALITY_GC_PAGE_SIZE

    while True:
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateCreated",
                "SortOrder": "Descending",
                "Limit": str(page_size),
                "StartIndex": str(start),
                "Fields": "ProviderIds,ProductionYear"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Quality GC: failed to list movies page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            item_id = it.get("Id")
            name = it.get("Name") or ""
            year = it.get("ProductionYear")
            prov = it.get("ProviderIds") or {}
            tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
            imdb_id = prov.get("Imdb") or prov.get("ImdbId")
            # –∏–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ "(year)"
            name_clean = name.replace(f" ({year})", "").strip()

            key = _movie_logical_key(
                tmdb_id=tmdb_id,
                imdb_id=imdb_id,
                name=name_clean,
                year=year
            )
            current_keys.add(key)
            if item_id:
                current_ids.add(item_id)

        n = len(items)
        start += n
        if n < page_size:
            break

    return current_keys, current_ids

def _collect_current_movie_keys_and_ids() -> tuple[set[str], set[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (set –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–π, set ItemId) –¥–ª—è –í–°–ï–• —Ñ–∏–ª—å–º–æ–≤ –≤ Jellyfin.
    –ö–ª—é—á —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ _movie_logical_key(...) –ø–æ ProviderIds/Tmdb/Imdb -> name+year.
    """
    current_keys: set[str] = set()
    current_ids: set[str] = set()

    start = 0
    page_size = QUALITY_GC_PAGE_SIZE

    while True:
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateCreated",
                "SortOrder": "Descending",
                "Limit": str(page_size),
                "StartIndex": str(start),
                "Fields": "ProviderIds,ProductionYear"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Quality GC: failed to list movies page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            item_id = it.get("Id")
            name = it.get("Name") or ""
            year = it.get("ProductionYear")
            prov = it.get("ProviderIds") or {}
            tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
            imdb_id = prov.get("Imdb") or prov.get("ImdbId")
            # –∏–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ "(year)"
            name_clean = name.replace(f" ({year})", "").strip()

            key = _movie_logical_key(
                tmdb_id=tmdb_id,
                imdb_id=imdb_id,
                name=name_clean,
                year=year
            )
            current_keys.add(key)
            if item_id:
                current_ids.add(item_id)

        n = len(items)
        start += n
        if n < page_size:
            break

    return current_keys, current_ids

def gc_quality_db_once():
    """
    –£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏:
      - content_quality: –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ last seen —Å—Ç–∞—Ä—à–µ GRACE
      - media_quality: item_id, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ last seen —Å—Ç–∞—Ä—à–µ GRACE
      - recent_quality_updates: –º–∞—Ä–∫–µ—Ä—ã –ø–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º –∫–ª—é—á–∞–º
    """
    try:
        current_keys, current_ids = _collect_current_movie_keys_and_ids()
        cutoff = datetime.now(timezone.utc) - timedelta(days=QUALITY_GC_GRACE_DAYS)

        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()

        # --- content_quality
        cur.execute("SELECT logical_key, date_seen FROM content_quality")
        rows = cur.fetchall()
        to_del_keys = []
        for logical_key, date_seen in rows:
            if logical_key in current_keys:
                continue
            dt = _iso_to_dt(date_seen)
            if (dt is None) or (dt < cutoff):
                to_del_keys.append(logical_key)

        if to_del_keys:
            for key in to_del_keys:
                cur.execute("DELETE FROM content_quality WHERE logical_key=?", (key,))
            logging.info(f"Quality GC: removed {len(to_del_keys)} content_quality rows")

        # --- media_quality
        cur.execute("SELECT item_id, date_seen FROM media_quality")
        rows = cur.fetchall()
        to_del_ids = []
        for item_id, date_seen in rows:
            if item_id in current_ids:
                continue
            dt = _iso_to_dt(date_seen)
            if (dt is None) or (dt < cutoff):
                to_del_ids.append(item_id)

        if to_del_ids:
            for iid in to_del_ids:
                cur.execute("DELETE FROM media_quality WHERE item_id=?", (iid,))
            logging.info(f"Quality GC: removed {len(to_del_ids)} media_quality rows")

        # --- recent_quality_updates (–º–∞—Ä–∫–µ—Ä—ã –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –≤–µ–±—Ö—É–∫–∞)
        if to_del_keys:
            for key in to_del_keys:
                cur.execute("DELETE FROM recent_quality_updates WHERE logical_key=?", (key,))

        conn.commit()

        # –ø–æ –∂–µ–ª–∞–Ω–∏—é –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –¥–µ–ª–∞—Ç—å VACUUM (—Ä–µ–¥–∫–æ)
        # cur.execute("VACUUM")  # –µ—Å–ª–∏ –±–∞–∑–∞ –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–∞

    except Exception as ex:
        logging.warning(f"Quality GC error: {ex}")
    finally:
        try:
            conn.close()
        except Exception:
            pass

_init_quality_db()

# --- –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ) ---
if FORCE_QUALITY_GC_ON_START:
    old_grace = QUALITY_GC_GRACE_DAYS
    try:
        # –ï—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ —è–≤–Ω–æ ‚Äî —á–∏—Å—Ç–∏–º –±–µ–∑ ¬´–≥—Ä–µ–π—Å–∞¬ª (—Å—Ä–∞–∑—É)
        QUALITY_GC_GRACE_DAYS = int(FORCE_QUALITY_GC_GRACE_DAYS) if FORCE_QUALITY_GC_GRACE_DAYS is not None else 0
    except Exception:
        logging.warning(f"FORCE_QUALITY_GC_GRACE_DAYS is not an int: {FORCE_QUALITY_GC_GRACE_DAYS}")
        QUALITY_GC_GRACE_DAYS = 0

    logging.info(f"Quality DB GC (startup forced): grace={QUALITY_GC_GRACE_DAYS}d, vacuum={FORCE_QUALITY_GC_VACUUM}")
    try:
        gc_quality_db_once()  # —É–¥–∞–ª–∏—Ç –∑–∞–ø–∏—Å–∏ –ø–æ —Ñ–∏–ª—å–º–∞–º, –∫–æ—Ç–æ—Ä—ã—Ö —É–∂–µ –Ω–µ—Ç –≤ Jellyfin
        if FORCE_QUALITY_GC_VACUUM:
            try:
                conn = sqlite3.connect(QUALITY_DB_FILE)
                conn.execute("VACUUM")
                conn.close()
                logging.info("Quality DB GC (startup) VACUUM done.")
            except Exception as ex:
                logging.warning(f"Quality DB GC (startup) VACUUM failed: {ex}")
    finally:
        # –≤–µ—Ä–Ω—ë–º –æ–±—ã—á–Ω—ã–π grace –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–∏
        QUALITY_GC_GRACE_DAYS = old_grace

#–†–∞–±–æ—Ç–∞ —Å —Å–µ–∑–æ–Ω–Ω—ã–º–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏
def jellyfin_count_present_episodes_in_season(season_id: str) -> int | None:
    """–¢–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ø–∏–∑–æ–¥—ã (–µ—Å—Ç—å —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π —Ñ–∞–π–ª)."""
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ParentId": season_id,
            "IncludeItemTypes": "Episode",
            "Recursive": "false",
            # –∫–ª—é—á: —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã –Ω–∞ –¥–∏—Å–∫–µ
            "LocationTypes": "FileSystem",
            # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∏—Å–∫–ª—é—á–∏–º —è–≤–Ω–æ ¬´–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ¬ª
            "IsMissing": "false",
            "Limit": "1",  # TotalRecordCount —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä—ã
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json() or {}
        cnt = data.get("TotalRecordCount")
        return int(cnt) if isinstance(cnt, int) else len(data.get("Items") or [])
    except Exception as ex:
        logging.warning(f"Failed to count PRESENT episodes for season {season_id}: {ex}")
        return None

def jellyfin_count_missing_episodes_in_season(season_id: str) -> int | None:
    """–≠–ø–∏–∑–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–µ–∑–æ–Ω–∞, –Ω–æ —Ñ–∞–π–ª–∞ –Ω–µ—Ç (–∏—Å–∫–ª—é—á–∞–µ–º –Ω–µ –≤—ã—à–µ–¥—à–∏–µ)."""
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ParentId": season_id,
            "IncludeItemTypes": "Episode",
            "Recursive": "false",
            # –∫–ª—é—á: –ø—Ä–æ—Å–∏–º ¬´–ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ¬ª (–≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ) —ç–ø–∏–∑–æ–¥—ã
            "IsMissing": "true",
            "IsUnaired": "false",
            "IsVirtualUnaired": "false",
            # –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏
            "LocationTypes": "Virtual",
            "Limit": "1",
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json() or {}
        cnt = data.get("TotalRecordCount")
        return int(cnt) if isinstance(cnt, int) else len(data.get("Items") or [])
    except Exception as ex:
        logging.warning(f"Failed to count MISSING episodes for season {season_id}: {ex}")
        return None

def jellyfin_get_season_counts_resilient(season_id: str) -> tuple[int, int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (present, total) c –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –ø–æ–≤—Ç–æ—Ä–∞–º–∏.
    total = present + missing. –ï—Å–ª–∏ missing –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî total=present.
    """
    attempts = max(int(os.getenv("SEASON_EP_COUNT_RETRY_ATTEMPTS", "5")), 1)
    delay = max(int(os.getenv("SEASON_EP_COUNT_RETRY_DELAY_SEC", "3")), 0)

    present, total = 0, 0
    for i in range(1, attempts + 1):
        p = jellyfin_count_present_episodes_in_season(season_id)
        m = jellyfin_count_missing_episodes_in_season(season_id)
        present = int(p) if isinstance(p, int) else present
        total = present + (int(m) if isinstance(m, int) else 0)

        if total > 0 and (present > 0 or i == attempts):
            if i > 1:
                logging.debug(f"Season counts after {i} attempts: present={present}, total={total}")
            break
        time.sleep(delay)
    return present, total

def poll_recent_episodes_once():
    """
    –ò—â–µ–º —Å–≤–µ–∂–∏–µ —ç–ø–∏–∑–æ–¥—ã –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ, –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–µ–∑–æ–Ω—É –∏ —à–ª—ë–º –û–î–ù–û —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ ¬´–ù–æ–≤—ã–π —Å–µ–∑–æ–Ω: –¥–æ–±–∞–≤–ª–µ–Ω–æ N –∏–∑ M¬ª.
    –°–≤–µ–∂–∏–µ (–º–æ–ª–æ–∂–µ SERIES_POLL_GRACE_MIN) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –ø—É—Å—Ç—å –∏—Ö –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –≤–µ–±—Ö—É–∫.
    """
    page_size = SERIES_POLL_PAGE_SIZE
    max_total = SERIES_POLL_MAX_TOTAL or 0  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    processed_seasons: set[str] = set()

    while True:
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø—Ä–∏ max_total
        current_limit = page_size if (not max_total or (max_total - fetched) >= page_size) else (max_total - fetched)
        if current_limit <= 0:
            break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Episode",
                "Recursive": "true",
                "SortBy": "DateCreated,DateModified",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                "Fields": "ParentId,SeriesId,SeasonName,DateCreated,ProductionYear,Overview"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Series poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        # —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º —ç–ø–∏–∑–æ–¥—ã –ø–æ —Å–µ–∑–æ–Ω—É
        for ep in items:
            try:
                season_id = ep.get("ParentId") or ep.get("SeasonId")
                if not season_id or season_id in processed_seasons:
                    continue

                # –≥—Ä–µ–π—Å: –µ—Å–ª–∏ —ç–ø–∏–∑–æ–¥ —Å–æ–≤—Å–µ–º —Å–≤–µ–∂–∏–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–∑–æ–Ω, –ø—É—Å—Ç—å –≤–µ–±—Ö—É–∫ –æ–±—ä—è–≤–∏—Ç
                created_iso = ep.get("DateCreated")
                created_dt = _parse_iso_utc(created_iso) if ' _parse_iso_utc' in globals() else None
                if created_dt and (now_utc - created_dt) < timedelta(minutes=SERIES_POLL_GRACE_MIN):
                    logging.debug(f"Series poll: skip fresh season (ep created {created_dt.isoformat()}) season={season_id}")
                    continue

                # –ø–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ —Å–µ–∑–æ–Ω–∞/—Å–µ—Ä–∏–∞–ª–∞
                season_details = get_item_details(season_id)
                s_item = (season_details.get("Items") or [{}])[0]
                series_id = s_item.get("SeriesId")
                season_name = s_item.get("Name") or ep.get("SeasonName") or "Season"
                release_year = s_item.get("ProductionYear") or ep.get("ProductionYear")

                series_details = get_item_details(series_id) if series_id else {"Items": [{}]}
                series_item = (series_details.get("Items") or [{}])[0]
                series_name = series_item.get("Name") or ""
                overview_to_use = s_item.get("Overview") or series_item.get("Overview") or ""

                # –∞–Ω—Ç–∏—Å–ø–∞–º-–∫–ª—é—á, –∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ
                series_name_cleaned = series_name.replace(f" ({release_year})", "").strip()
                key_name = f"{series_name_cleaned} {season_name}".strip()

                if item_already_notified("Season", key_name, release_year):
                    processed_seasons.add(season_id)
                    continue

                # —Ä–µ–π—Ç–∏–Ω–≥–∏/—Ç—Ä–µ–π–ª–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                tmdb_id = jellyfin_get_tmdb_id(series_id) if 'jellyfin_get_tmdb_id' in globals() else None
                trailer_url = get_youtube_trailer_url(f"{series_name_cleaned} Trailer {release_year}")

                # —Å—á–∏—Ç–∞–µ–º ¬´—Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å / —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ¬ª –ø–æ —Å–µ–∑–æ–Ω—É (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ–π resilient-—Ö–µ–ª–ø–µ—Ä)
                # –≤ poll_recent_episodes_once(), –ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ –ø–æ–¥—Å—á—ë—Ç–æ–º present/total:
                wait_until_scan_idle("season counts build")
                present, total = jellyfin_get_season_counts_resilient(season_id)

                # 1) —Å–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ¬ª (–±–µ–∑ mark_notified) ‚Äî —á—Ç–æ–±—ã –∏–º–µ—Ç—å –±–∞–∑—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–∞
                _sp_upsert(
                    season_id,
                    present=present, total=total,
                    series_id=series_id,
                    season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                    series_name=series_name_cleaned,
                    release_year=release_year,
                    mark_notified=False
                )

                # 2) —Ä–µ—à–∞–µ–º, –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ present –≤—ã—Ä–æ—Å —Å–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–æ—à–ª–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                if not _sp_should_notify(season_id, present):
                    processed_seasons.add(season_id)
                    continue

                # 3) —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                notification_message = (
                    f"*{t('new_season_title')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n"
                    f"*{season_name}*"
                )
                if total >= present and total > 0:
                    notification_message += f"\n\n{t('season_added_progress').format(added=present, total=total)}"
                elif present > 0:
                    notification_message += f"\n\n{t('season_added_count_only').format(added=present)}"
                if overview_to_use:
                    notification_message += f"\n\n{overview_to_use}"
                if tmdb_id:
                    ratings_text = fetch_mdblist_ratings("show", tmdb_id)
                    if ratings_text:
                        notification_message += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"
                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # 4) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ–º ¬´–¥–æ –∫—É–¥–∞ —Å–æ–æ–±—â–∏–ª–∏¬ª
                if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                    send_notification(season_id, notification_message)
                else:
                    send_notification(series_id, notification_message)
                    logging.warning(
                        f"(Series poll) {series_name_cleaned} {season_name} image missing; using series image")

                # –ø–æ–º–µ—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å: —Ç–µ–ø–µ—Ä—å last_notified_present = present
                _sp_upsert(
                    season_id,
                    present=present, total=total,
                    series_id=series_id,
                    season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                    series_name=series_name_cleaned,
                    release_year=release_year,
                    mark_notified=True
                )

                logging.info(
                    f"(Series poll) Season announced: {series_name_cleaned} {season_name} ‚Äî {present} / {total}")
                processed_seasons.add(season_id)

            except Exception as ex:
                logging.warning(f"Series poll: season from ep {ep.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        logging.debug(f"Series poll: page fetched {n} episodes (total {fetched})")
        if n < current_limit:
            break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

def _series_poll_loop():
    while True:
        try:
            poll_recent_episodes_once()
        except Exception as ex:
            logging.warning(f"Series poll loop error: {ex}")
        time.sleep(SERIES_POLL_INTERVAL_SEC)

if SERIES_POLL_ENABLED:
    threading.Thread(target=_series_poll_loop, name="series-poll", daemon=True).start()
    logging.info(f"Series polling enabled every {SERIES_POLL_INTERVAL_SEC}s "
                 f"(page={SERIES_POLL_PAGE_SIZE}, max_total={SERIES_POLL_MAX_TOTAL}, grace={SERIES_POLL_GRACE_MIN}m)")

def _sp_get(season_id: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""
            SELECT season_id, series_id, series_name, season_number, release_year,
                   present, total, last_notified_present, updated_at
            FROM season_progress WHERE season_id=?""", (season_id,))
        row = cur.fetchone()
        if not row:
            return None
        return {
            "season_id": row[0], "series_id": row[1], "series_name": row[2],
            "season_number": row[3], "release_year": row[4],
            "present": row[5], "total": row[6],
            "last_notified_present": row[7], "updated_at": row[8],
        }
    except Exception as ex:
        logging.warning(f"_sp_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _sp_upsert(season_id: str, *, present: int, total: int,
               series_id: str | None = None, season_number: int | None = None,
               series_name: str | None = None, release_year: int | None = None,
               mark_notified: bool = False):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
        if mark_notified:
            cur.execute("""
                INSERT INTO season_progress (season_id, series_id, series_name, season_number, release_year,
                                             present, total, last_notified_present, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(season_id) DO UPDATE SET
                    series_id=excluded.series_id,
                    series_name=excluded.series_name,
                    season_number=excluded.season_number,
                    release_year=excluded.release_year,
                    present=excluded.present,
                    total=excluded.total,
                    last_notified_present=excluded.last_notified_present,
                    updated_at=excluded.updated_at
            """, (season_id, series_id, series_name, season_number, release_year,
                  int(present), int(total), int(present), nowz))
        else:
            cur.execute("""
                INSERT INTO season_progress (season_id, series_id, series_name, season_number, release_year,
                                             present, total, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ON CONFLICT(season_id) DO UPDATE SET
                    series_id=excluded.series_id,
                    series_name=excluded.series_name,
                    season_number=excluded.season_number,
                    release_year=excluded.release_year,
                    present=excluded.present,
                    total=excluded.total,
                    updated_at=excluded.updated_at
            """, (season_id, series_id, series_name, season_number, release_year,
                  int(present), int(total), nowz))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sp_upsert failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _sp_should_notify(season_id: str, present_now: int) -> bool:
    row = _sp_get(season_id)
    if row is None:
        # –≤–ø–µ—Ä–≤—ã–µ –≤–∏–¥–∏–º —Å–µ–∑–æ–Ω: —Å–ª–∞—Ç—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –∏ –µ—Å—Ç—å —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ
        return SERIES_POLL_INITIAL_ANNOUNCE and present_now > 0
    last = int(row.get("last_notified_present") or 0)
    return present_now > last




@app.route("/webhook", methods=["POST"])
def announce_new_releases_from_jellyfin():
    try:
        payload = json.loads(request.data)
        item_type = payload.get("ItemType")
        tmdb_id = payload.get("Provider_tmdb")
        item_name = payload.get("Name")
        release_year = payload.get("Year")
        series_name = payload.get("SeriesName")
        season_epi = payload.get("EpisodeNumber00")
        season_num = payload.get("SeasonNumber00")

        if item_type == "Movie":
            movie_id = payload.get("ItemId")
            overview = payload.get("Overview")
            runtime = payload.get("RunTime")

            movie_name = item_name
            movie_name_cleaned = movie_name.replace(f" ({release_year})", "").strip()

            tmdb_id_payload = payload.get("Provider_tmdb") or payload.get("TmdbId")
            imdb_id_payload = payload.get("Provider_imdb") or payload.get("ImdbId")

            # --- –ù–û–í–û–ï: –µ—Å–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ quality-update –ø–æ —Å–∫–∞–Ω–µ—Ä—É/–≥–≤–∞—Ä–¥—É ‚Äî –≥–ª—É—à–∏–º –≤–µ–±—Ö—É–∫
            logical_key = _movie_logical_key(tmdb_id=tmdb_id_payload, imdb_id=imdb_id_payload,
                                             name=movie_name_cleaned, year=release_year)
            if was_quality_update_recent(logical_key):
                logging.info(
                    f"(Webhook/Movie) Suppressed 'new movie' due to recent quality update (logical_key={logical_key})")
                return "Suppressed: recent quality update"

            # 1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º –∞–ø–≥—Ä–µ–π–¥ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äî —ç—Ç–æ –¥–æ–ª–∂–Ω–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–∏–ª—å–º —É–∂–µ ¬´–±—ã–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω¬ª
            if maybe_notify_movie_quality_change(
                    item_id=movie_id,
                    movie_name_cleaned=movie_name_cleaned,
                    release_year=release_year,
                    tmdb_id=tmdb_id_payload,
                    imdb_id=imdb_id_payload,
                    overview=overview,
                    runtime=runtime
            ):
                return "Movie quality update sent"

            # 2) –ò–Ω–∞—á–µ ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–º —Ñ–∏–ª—å–º–µ (–∫–∞–∫ –±—ã–ª–æ)
            if not item_already_notified(item_type, item_name, release_year):
                trailer_url = get_youtube_trailer_url(f"{movie_name_cleaned} Trailer {release_year}")

                notification_message = (
                    f"*{t('new_movie_title')}*\n\n*{movie_name_cleaned}* *({release_year})*\n\n{overview}\n\n"
                    f"*{t('new_runtime')}*\n{runtime}"
                )

                if tmdb_id:
                    mdblist_type = item_type.lower()
                    ratings_text = fetch_mdblist_ratings(mdblist_type, tmdb_id)
                    if ratings_text:
                        notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"

                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # --- Quality changes –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ –ù–û–í–û–ú —Ñ–∏–ª—å–º–µ ---
                try:
                    # —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                    new_q = _get_item_media_info_movie(movie_id)

                    # –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ä—ã–π —Å–ª–µ–ø–æ–∫ –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É (–µ—Å–ª–∏ —Ñ–∏–ª—å–º –∫–æ–≥–¥–∞-—Ç–æ –±—ã–ª)
                    logical_key = _movie_logical_key(
                        tmdb_id=tmdb_id_payload,
                        imdb_id=imdb_id_payload,
                        name=movie_name_cleaned,
                        year=release_year
                    )
                    old_q = None
                    try:
                        conn = sqlite3.connect(QUALITY_DB_FILE)
                        cur = conn.cursor()
                        cur.execute("""SELECT video_codec,
                                              video_bitrate,
                                              width,
                                              height,
                                              fps,
                                              bit_depth,
                                              dynamic_range,
                                              image_profiles,
                                              audio_codec,
                                              audio_bitrate,
                                              audio_channels,
                                              container,
                                              size_bytes,
                                              duration_sec
                                       FROM content_quality
                                       WHERE logical_key = ?""", (logical_key,))
                        row = cur.fetchone()
                        if row:
                            old_q = {
                                "video_codec": row[0], "video_bitrate": row[1], "width": row[2], "height": row[3],
                                "fps": row[4], "bit_depth": row[5], "dynamic_range": row[6],
                                "image_profiles": ([p.strip() for p in row[7].split(",")] if row[7] else None),
                                "audio_codec": row[8], "audio_bitrate": row[9], "audio_channels": row[10],
                                "container": row[11], "size_bytes": row[12], "duration_sec": row[13],
                            }
                    except Exception as ex:
                        logging.warning(f"Quality (new movie) old snapshot read failed: {ex}")
                    finally:
                        try:
                            conn.close()
                        except Exception:
                            pass

                    # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –±–ª–æ–∫:
                    delta_block = build_quality_changes_block(old_q,
                                                              new_q) if old_q else build_initial_quality_changes_block(
                        new_q)
                    if not delta_block:
                        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –µ—Å–ª–∏ –ø–æ—á–µ–º—É-—Ç–æ –±–ª–æ–∫ –ø—É—Å—Ç, –ø–æ–∫–∞–∂–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π
                        delta_block = build_initial_quality_changes_block(new_q)
                    notification_message += delta_block

                    # (–ø–æ –∂–µ–ª–∞–Ω–∏—é) —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫, –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à—ë–Ω —Ñ–ª–∞–≥–æ–º
                    if INCLUDE_AUDIO_TRACKS:
                        tracks_block = build_audio_tracks_block(new_q)
                        if tracks_block:
                            notification_message += tracks_block

                except Exception as ex:
                    logging.warning(f"Quality (new movie) block build failed: {ex}")
                # --- /Quality changes ---

                send_notification(movie_id, notification_message)
                mark_item_as_notified(item_type, item_name, release_year)
                logging.info(f"(Movie) {movie_name} {release_year} notification was sent.")
                return "Movie notification was sent"

        if item_type == "Season":
            # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–ª—é—á –¥–ª—è –∞–Ω—Ç–∏—Å–ø–∞–º–∞
            season = item_name  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "–°–µ–∑–æ–Ω 1"
            series_title_for_key = (series_name or "").strip()
            key_name = f"{series_title_for_key} {season}".strip()

            if not item_already_notified(item_type, key_name, release_year):
                season_id = payload.get("ItemId")
                season = item_name
                season_details = get_item_details(season_id)
                series_id = season_details["Items"][0].get("SeriesId")
                series_details = get_item_details(series_id)
                # Remove release_year from series_name if present
                series_name_cleaned = series_name.replace(f" ({release_year})", "").strip()

                trailer_url = get_youtube_trailer_url(f"{series_name_cleaned} Trailer {release_year}")

                # Get TMDb ID via external API
                tmdb_id = jellyfin_get_tmdb_id(series_id)

                # **–ù–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏**: –ø–æ–ª—É—á–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∞
                ratings_text = fetch_mdblist_ratings("show", tmdb_id)
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–π—Ç–∏–Ω–≥–∏ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –Ω–∏—Ö
                ratings_section = f"{ratings_text}\n\n" if ratings_text else ""

                # Get series overview if season overview is empty
                overview_to_use = payload.get("Overview") if payload.get("Overview") else series_details["Items"][0].get(
                    "Overview")

                # —Å—á–∏—Ç–∞–µ–º ¬´—Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å / —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ¬ª –ø–æ —Å–µ–∑–æ–Ω—É (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ–π resilient-—Ö–µ–ª–ø–µ—Ä)
                present, total = jellyfin_get_season_counts_resilient(season_id)

                if total >= present and total > 0:
                    episodes_segment = f"\n\n{t('season_added_progress').format(added=present, total=total)}"
                elif present > 0:
                    episodes_segment = f"\n\n{t('season_added_count_only').format(added=present)}"
                else:
                    episodes_segment = ""

                notification_message = (
                    f"*{t('new_season_title')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n"
                    f"*{season}*{episodes_segment}\n\n{overview_to_use}")

                if ratings_text:
                    notification_message += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"

                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞ ‚Äî –µ—Å–ª–∏ –Ω–µ—Ç, —à–ª—ë–º —Å –ø–æ—Å—Ç–µ—Ä–æ–º —Å–µ—Ä–∏–∞–ª–∞
                if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                    send_notification(season_id, notification_message)
                else:
                    send_notification(series_id, notification_message)
                    logging.warning(
                        f"{series_name_cleaned} {season} image does not exist, falling back to series image")

                mark_item_as_notified(item_type, key_name, release_year)
                logging.info(f"(Season) {series_name_cleaned} {season} notification was sent")
                return "Season notification was sent"

        if item_type == "Episode":
            if not item_already_notified(item_type, item_name, release_year):
                item_id = payload.get("ItemId")
                file_details = get_item_details(item_id)
                season_id = file_details["Items"][0].get("SeasonId")
                episode_premiere_date = file_details["Items"][0].get("PremiereDate", "0000-00-00T").split("T")[0]
                season_details = get_item_details(season_id)
                series_id = season_details["Items"][0].get("SeriesId")
                season_date_created = season_details["Items"][0].get("DateCreated", "0000-00-00T").split("T")[0]
                epi_name = item_name
                overview = payload.get("Overview")

#                if not DEBUG_DISABLE_DATE_CHECKS:
                if not is_not_within_last_x_days(season_date_created, SEASON_ADDED_WITHIN_X_DAYS):
                    logging.info(f"(Episode) {series_name} Season {season_num} "
                                 f"was added within the last {SEASON_ADDED_WITHIN_X_DAYS} "
                                 f"days. Not sending notification.")
                    return (f"Season was added within the last {SEASON_ADDED_WITHIN_X_DAYS} "
                            f"days. Not sending notification.")

                if episode_premiere_date and is_within_last_x_days(episode_premiere_date,
                                                                   EPISODE_PREMIERED_WITHIN_X_DAYS):

                    notification_message = (
                        f"*{t('new_episode_title')}*\n\n*{t('new_release_date')}*: {episode_premiere_date}\n\n*{t('new_series')}*: {series_name} *S*"
                        f"{season_num}*E*{season_epi}\n*{t('new_episode_t')}*: {epi_name}\n\n{overview}\n\n"
                    )
                    # –ü–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞ –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –ø—Ä–æ–≤–µ—Ä–∏–º –∑–∞—Ä–∞–Ω–µ–µ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–π–¥—ë–º –Ω–∞ –ø–æ—Å—Ç–µ—Ä —Å–µ—Ä–∏–∞–ª–∞
                    if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                        send_notification(season_id, notification_message)
                    else:
                        send_notification(series_id, notification_message)
                        logging.warning(
                            f"(Episode) {series_name} season image does not exist, falling back to series image")

                    mark_item_as_notified(item_type, item_name, release_year)
                    logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} notification sent!")
                    return "Notification sent!"

                else:
                    logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} "
                                 f"was premiered more than {EPISODE_PREMIERED_WITHIN_X_DAYS} "
                                 f"days ago. Not sending notification.")
                    return (f"Episode was added more than {EPISODE_PREMIERED_WITHIN_X_DAYS} "
                            f"days ago. Not sending notification.")

        if item_type == "MusicAlbum":
            # —á–∏—Ç–∞–µ–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è/–∞–ª—å–±–æ–º –∑–∞—Ä–∞–Ω–µ–µ, —á—Ç–æ–±—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á
            album_name = payload.get("Name")
            artist = payload.get("Artist")
            key_name = f"{artist} ‚Äì {album_name}".strip()

            if not item_already_notified(item_type, key_name, release_year):
                album_id = payload.get("ItemId")
                album_name = payload.get("Name")
                artist = payload.get("Artist")
                year = payload.get("Year")
                overview = payload.get("Overview")
                runtime = payload.get("RunTime")
                musicbrainzalbum_id = payload.get("Provider_musicbrainzalbum")

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ MusicBrainz, –µ—Å–ª–∏ –µ—Å—Ç—å ID
                mb_link = f"https://musicbrainz.org/release/{musicbrainzalbum_id}" if musicbrainzalbum_id else ""

                # –®–∞–±–ª–æ–Ω —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                notification_message = (
                    f"*{t('new_album_title')}*\n\n"
                    f"*{artist}*\n\n"
                    f"*{album_name} ({year})*\n\n"
                    f"{overview and overview + '\n\n' or ''}"
                    f"*{t('new_runtime')}*\n{runtime}\n\n"
                    f"{f'[MusicBrainz]({mb_link})' if mb_link else ''}\n"
                )

                send_notification(album_id, notification_message)
                mark_item_as_notified(item_type, key_name, release_year)
                logging.info(f"(Album) {artist} ‚Äì {album_name} ({year}) notification sent.")
                return "Album notification was sent to telegram"

        if item_type == "Movie":
            logging.info(f"(Movie) {item_name} Notification Was Already Sent")
        elif item_type == "Season":
            logging.info(f"(Season) {series_name} {item_name} Notification Was Already Sent")
        elif item_type == "Episode":
            logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} Notification Was Already Sent")
        else:
            logging.error('Item type not supported')
        return "Item type not supported."

    # Handle specific HTTP errors
    except HTTPError as http_err:
        logging.error(f"HTTP error occurred: {http_err}")
        return str(http_err)

    # Handle generic exceptions
    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return f"Error: {str(e)}"


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
