import logging
import os
import json
import requests
import tempfile
import re
import base64
import threading
import time
import markdown
import smtplib
from requests.exceptions import HTTPError
from flask import Flask, request
from dotenv import load_dotenv
#from apprise import Apprise
from urllib.parse import quote
from email.message import EmailMessage
from email.utils import formatdate, make_msgid
from logging.handlers import TimedRotatingFileHandler
from datetime import datetime, timedelta, timezone
from collections import Counter, OrderedDict
import sqlite3
import hashlib
from urllib.parse import urlparse
import ipaddress

load_dotenv()
app = Flask(__name__)

# Set up logging
#log_directory = '/app/log'
log_directory = 'A:/git/log'
log_filename = os.path.join(log_directory, 'jellyfin_telegram-notifier.log')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –¥–µ—Ä–∂–∞—Ç—å —Ä–æ—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5), –º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ ENV
LOG_RETENTION_DAYS = int(os.getenv("LOG_RETENTION_DAYS", "3"))

def _cleanup_rotated_logs(base_log_path: str, retain_days: int = LOG_RETENTION_DAYS) -> None:
    """
    –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã –≤–∏–¥–∞ 'jellyfin_telegram-notifier.log.YYYY-MM-DD' —Å—Ç–∞—Ä—à–µ retain_days.
    –ù–µ —Ç—Ä–æ–≥–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª '...log'.
    """
    try:
        dirpath = os.path.dirname(base_log_path) or "."
        basename = os.path.basename(base_log_path)  # jellyfin_telegram-notifier.log
        # –ú–∞—Ç—á–∏–º —Ç–æ–ª—å–∫–æ —Å—É—Ñ—Ñ–∏–∫—Å .YYYY-MM-DD
        pattern = re.compile(rf"^{re.escape(basename)}\.(\d{{4}}-\d{{2}}-\d{{2}})$")
        cutoff = (datetime.now().date() - timedelta(days=max(0, int(retain_days))))

        for name in os.listdir(dirpath):
            m = pattern.match(name)
            if not m:
                continue
            date_str = m.group(1)
            try:
                d = datetime.strptime(date_str, "%Y-%m-%d").date()
            except ValueError:
                continue
            if d < cutoff:
                full = os.path.join(dirpath, name)
                try:
                    os.remove(full)
                    logging.info(f"Log cleanup: removed old rotation {name}")
                except Exception as ex:
                    logging.warning(f"Log cleanup: failed to remove {name}: {ex}")
    except Exception as ex:
        logging.warning(f"Log cleanup failed: {ex}")

# Ensure the log directory exists
os.makedirs(log_directory, exist_ok=True)

# Create a handler for rotating log files daily
rotating_handler = TimedRotatingFileHandler(log_filename, when="midnight", interval=1, backupCount=7)
rotating_handler.setLevel(logging.INFO)
rotating_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))

# Add the rotating handler to the logger
logging.getLogger().addHandler(rotating_handler)

# –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ä–æ—Ç–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç–∞—Ä—à–µ 5 –¥–Ω–µ–π)
_cleanup_rotated_logs(log_filename, retain_days=LOG_RETENTION_DAYS)

# Constants
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "")
GOTIFY_URL = os.environ.get("GOTIFY_URL", "").rstrip("/")
GOTIFY_TOKEN = os.environ.get("GOTIFY_TOKEN", "")
JELLYFIN_BASE_URL = os.environ["JELLYFIN_BASE_URL"].rstrip("/")
JELLYFIN_API_KEY = os.environ["JELLYFIN_API_KEY"]
YOUTUBE_API_KEY = os.environ.get("YOUTUBE_API_KEY", "")
MDBLIST_API_KEY = os.environ.get("MDBLIST_API_KEY", "")
IMGBB_API_KEY = os.environ.get("IMGBB_API_KEY", "")
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL", "")
TMDB_API_KEY = os.environ.get("TMDB_API_KEY")
TMDB_LANGUAGE = os.getenv("TMDB_LANGUAGE", "en-US")  # –Ω–∞–ø—Ä. "ru-RU"
TMDB_SEARCH_URL = "https://api.themoviedb.org/3/search/tv"
TMDB_BASE = "https://api.themoviedb.org/3"
LANGUAGE = os.environ["LANGUAGE"]
EPISODE_PREMIERED_WITHIN_X_DAYS = int(os.environ["EPISODE_PREMIERED_WITHIN_X_DAYS"])
SEASON_ADDED_WITHIN_X_DAYS = int(os.environ["SEASON_ADDED_WITHIN_X_DAYS"])
SIGNAL_URL = os.environ.get("SIGNAL_URL", "").rstrip("/")
SIGNAL_NUMBER = os.environ.get("SIGNAL_NUMBER", "")
SIGNAL_RECIPIENTS = os.environ.get("SIGNAL_RECIPIENTS", "")
WHATSAPP_API_URL = os.environ.get("WHATSAPP_API_URL", "").rstrip("/")
WHATSAPP_NUMBER = os.environ.get("WHATSAPP_NUMBER", "")
WHATSAPP_JID = os.environ.get("WHATSAPP_JID", "")
WHATSAPP_GROUP_JID = os.environ.get("WHATSAPP_GROUP_JID", "")
WHATSAPP_API_USERNAME = os.environ.get("WHATSAPP_API_USERNAME", "")
WHATSAPP_API_PWD = os.environ.get("WHATSAPP_API_PWD", "")
MATRIX_URL = os.environ.get("MATRIX_URL", "").rstrip("/")
MATRIX_ACCESS_TOKEN = os.environ.get("MATRIX_ACCESS_TOKEN", "")
MATRIX_ROOM_ID = os.environ.get("MATRIX_ROOM_ID", "")
SMTP_SUBJECT = "–ù–æ–≤—ã–π —Ä–µ–ª–∏–∑ –≤ Jellyfin"
SMTP_HOST = os.environ.get("SMTP_HOST", "")
SMTP_PORT = int(os.environ.get("SMTP_PORT", "587"))
SMTP_USER = os.environ.get("SMTP_USER", "")
SMTP_PASS = os.environ.get("SMTP_PASS", "")
SMTP_FROM = os.environ.get("SMTP_FROM", "")
SMTP_TO   = os.environ.get("SMTP_TO", "")  # —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é/–ø—Ä–æ–±–µ–ª
SMTP_USE_TLS = os.environ.get("SMTP_USE_TLS", "1") not in ("0", "", "false", "False")   # –¥–ª—è STARTTLS (587)
SMTP_USE_SSL = os.environ.get("SMTP_USE_SSL", "0") in ("1", "true", "True")   # –¥–ª—è SMTPS (465); –µ—Å–ª–∏ 1, —Ç–æ TLS –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
SLACK_BOT_TOKEN = os.environ.get("SLACK_BOT_TOKEN", "")
SLACK_CHANNEL_ID = os.environ.get("SLACK_CHANNEL_ID", "")   # ID –∫–∞–Ω–∞–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä C0123456789
# --- Home Assistant notifications ---
HA_BASE_URL = os.getenv("HA_BASE_URL", "").rstrip("/")          # –Ω–∞–ø—Ä–∏–º–µ—Ä: http://192.168.1.10:8123
HA_TOKEN    = os.getenv("HA_TOKEN", "")                         # Long-Lived Access Token –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è HA
HA_VERIFY_SSL = os.getenv("HA_VERIFY_SSL", "1").lower() in ("1","true","yes","on")
# --- Pushover ---
PUSHOVER_USER_KEY = os.getenv("PUSHOVER_USER_KEY", "")  # –≤–∞—à user/group key
PUSHOVER_TOKEN    = os.getenv("PUSHOVER_TOKEN", "")     # –≤–∞—à app token
PUSHOVER_SOUND    = os.getenv("PUSHOVER_SOUND", "")     # –æ–ø—Ü.: –∏–º—è –∑–≤—É–∫–∞ (—Å–º. API sounds)
PUSHOVER_DEVICE   = os.getenv("PUSHOVER_DEVICE", "")    # –æ–ø—Ü.: –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
PUSHOVER_PRIORITY = int(os.getenv("PUSHOVER_PRIORITY", "0"))  # -2..2
PUSHOVER_HTML     = os.getenv("PUSHOVER_HTML", "0").lower() in ("1","true","yes","on")

# –µ—Å–ª–∏ –±—É–¥–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç–∫—Å—Ç—Ä–µ–Ω–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç (2)
PUSHOVER_EMERGENCY_RETRY  = int(os.getenv("PUSHOVER_EMERGENCY_RETRY",  "60"))   # >= 30 —Å–µ–∫
PUSHOVER_EMERGENCY_EXPIRE = int(os.getenv("PUSHOVER_EMERGENCY_EXPIRE", "600"))  # —Å–µ–∫
# --- Pushover retry/timing ---
PUSHOVER_TIMEOUT_SEC        = float(os.getenv("PUSHOVER_TIMEOUT_SEC", "10"))   # —Ç–∞–π–º–∞—É—Ç –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
PUSHOVER_RETRIES            = int(os.getenv("PUSHOVER_RETRIES", "3"))          # —Å–∫–æ–ª—å–∫–æ –ø–æ–ø—ã—Ç–æ–∫ –≤—Å–µ–≥–æ
PUSHOVER_RETRY_BASE_DELAY   = float(os.getenv("PUSHOVER_RETRY_BASE_DELAY", "0.7"))  # —Å—Ç–∞—Ä—Ç–æ–≤–∞—è –ø–∞—É–∑–∞, —Å–µ–∫
PUSHOVER_RETRY_BACKOFF      = float(os.getenv("PUSHOVER_RETRY_BACKOFF", "1.8"))     # –º–Ω–æ–∂–∏—Ç–µ–ª—å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ç—ã

# –ö—É–¥–∞ —Å–ª–∞—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é:
# –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —É–∫–∞–∑—ã–≤–∞–π—Ç–µ notify/<–∏–º—è_—Å–µ—Ä–≤–∏—Å–∞>, –Ω–∞–ø—Ä. "notify/mobile_app_m2007j20cg"
# –¥–ª—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π ¬´–ø–æ—Å—Ç–æ—è–Ω–Ω–æ–π¬ª –Ω–æ—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —É–∫–∞–∂–∏—Ç–µ "persistent_notification/create"
HA_DEFAULT_SERVICE = os.getenv("HA_DEFAULT_SERVICE", "persistent_notification/create")
# –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Å—Ç–µ—Ä –≤ persistent_notification
HA_PN_IMAGE_LINK = os.getenv("HA_PN_IMAGE_LINK", "1").lower() in ("1","true","yes","on")
HA_PN_IMAGE_LABEL = os.getenv("HA_PN_IMAGE_LABEL", "Poster")  # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –ø–µ—Ä–µ–¥ —Å—Å—ã–ª–∫–æ–π
# --- Jellyfin: In-App —Å–æ–æ–±—â–µ–Ω–∏—è (–≤ –∫–ª–∏–µ–Ω—Ç) ---
JELLYFIN_INAPP_ENABLED = os.getenv("JELLYFIN_INAPP_ENABLED", "1") == "1"
JELLYFIN_INAPP_TIMEOUT_MS = int(os.getenv("JELLYFIN_INAPP_TIMEOUT_MS", "800"))      # —Å–∫–æ–ª—å–∫–æ –≤–∏—Å–∏—Ç –ø–æ–ø-–∞–ø
JELLYFIN_INAPP_ACTIVE_WITHIN_SEC = int(os.getenv("JELLYFIN_INAPP_ACTIVE_WITHIN_SEC", "900"))  # ¬´–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å¬ª —Å–µ—Å—Å–∏–∏
JELLYFIN_INAPP_TITLE = os.getenv("JELLYFIN_INAPP_TITLE", "Jellyfin")
JELLYFIN_INAPP_FORCE_MODAL = os.getenv("JELLYFIN_INAPP_FORCE_MODAL", "1").lower() in ("1","true","yes","on")
# --- Reddit ---
REDDIT_ENABLED     = os.getenv("REDDIT_ENABLED", "1").lower() in ("1","true","yes","on")
REDDIT_APP_ID      = os.getenv("REDDIT_APP_ID", "")
REDDIT_APP_SECRET  = os.getenv("REDDIT_APP_SECRET", "")
REDDIT_USERNAME    = os.getenv("REDDIT_USERNAME", "")
REDDIT_PASSWORD    = os.getenv("REDDIT_PASSWORD", "")
REDDIT_SUBREDDIT   = os.getenv("REDDIT_SUBREDDIT", "MySubJellynotify")     # –±–µ–∑ /r/
REDDIT_USER_AGENT  = os.getenv("REDDIT_USER_AGENT", "jellyfin-bot/1.0 (by u/your_username)")
# –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
REDDIT_SEND_REPLIES = os.getenv("REDDIT_SEND_REPLIES", "1").lower() in ("1","true","yes","on")
REDDIT_SPOILER      = os.getenv("REDDIT_SPOILER", "0").lower() in ("1","true","yes","on")
REDDIT_NSFW         = os.getenv("REDDIT_NSFW", "0").lower() in ("1","true","yes","on")
# --- Reddit post mode ---
# 1 = –∫–∞–∫ —Å–µ–π—á–∞—Å: –ø–æ—Å—Ç-—Å—Å—ã–ª–∫–∞ (–∫–∞—Ä—Ç–∏–Ω–∫–∞), –∞ –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º
# 0 = —Å—Ç–∞—Ä—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: self-post, —Å–≤–µ—Ä—Ö—É —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç–µ—Ä, –Ω–∏–∂–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤ —Ç–æ–º –∂–µ –ø–æ—Å—Ç–µ
REDDIT_SPLIT_TO_COMMENT = os.getenv("REDDIT_SPLIT_TO_COMMENT", "1").lower() in ("1","true","yes","on")
# --- Synology Chat ---
SYNOCHAT_ENABLED       = os.getenv("SYNOCHAT_ENABLED", "1").lower() in ("1","true","yes","on")
SYNOCHAT_WEBHOOK_URL   = os.getenv("SYNOCHAT_WEBHOOK_URL", "https://vaultwardendr.duckdns.org/webapi/entry.cgi?api=SYNO.Chat.External&method=incoming&version=2&token=%22rSfkUhV6XtEe87OQFai9IUH0C07KvLBZnctQO8COHiNLoLzSPhwCmUp2rN3pVuIz%22").strip()   # –ø–æ–ª–Ω—ã–π URL –∏–∑ Incoming Webhook
SYNOCHAT_TIMEOUT_SEC   = float(os.getenv("SYNOCHAT_TIMEOUT_SEC", "8"))
SYNOCHAT_VERIFY_SSL    = os.getenv("SYNOCHAT_VERIFY_SSL", "1").lower() in ("1","true","yes","on")
SYNOCHAT_INCLUDE_POSTER = os.getenv("SYNOCHAT_INCLUDE_POSTER", "1").lower() in ("1","true","yes","on")
SYNOCHAT_CA_BUNDLE = os.getenv("SYNOCHAT_CA_BUNDLE", "").strip()  # –ø—É—Ç—å –∫ .pem (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
SYNOCHAT_RETRIES = int(os.getenv("SYNOCHAT_RETRIES", "3"))
SYNOCHAT_RETRY_BASE_DELAY = float(os.getenv("SYNOCHAT_RETRY_BASE_DELAY", "0.8"))
SYNOCHAT_RETRY_BACKOFF = float(os.getenv("SYNOCHAT_RETRY_BACKOFF", "1.7"))
#–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
DISABLE_DEDUP = os.getenv("NOTIFIER_DISABLE_DEDUP", "0").lower() in ("1", "true", "yes")
#–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ñ–∏–ª—å–º–æ–≤
MOVIE_POLL_ENABLED = os.getenv("MOVIE_POLL_ENABLED", "1").lower() in ("1", "true", "yes")
MOVIE_POLL_INTERVAL_SEC = int(os.getenv("MOVIE_POLL_INTERVAL_SEC", "600"))   # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
MOVIE_POLL_GRACE_MIN = int(os.getenv("MOVIE_POLL_GRACE_MIN", "45"))  # –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å —Ñ–∏–ª—å–º—ã, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–∏–Ω—É—Ç
MOVIE_POLL_PAGE_SIZE = int(os.getenv("MOVIE_POLL_PAGE_SIZE", "500"))  # —Å–∫–æ–ª—å–∫–æ –±—Ä–∞—Ç—å –∑–∞ 1 –∑–∞–ø—Ä–æ—Å
MOVIE_POLL_MAX_TOTAL = int(os.getenv("MOVIE_POLL_MAX_TOTAL", "0"))    # 0 = –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –æ–±—â–µ–µ —á–∏—Å–ª–æ
# GC –ë–î –∫–∞—á–µ—Å—Ç–≤–∞
QUALITY_GC_ENABLED = os.getenv("QUALITY_GC_ENABLED", "1").lower() in ("1","true","yes","on")
QUALITY_GC_INTERVAL_HOURS = int(os.getenv("QUALITY_GC_INTERVAL_HOURS", "24"))   # –∫–∞–∫ —á–∞—Å—Ç–æ —á–∏—Å—Ç–∏—Ç—å
QUALITY_GC_GRACE_DAYS = int(os.getenv("QUALITY_GC_GRACE_DAYS", "1"))            # –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –º–æ–ª–æ–∂–µ N –¥–Ω–µ–π
QUALITY_GC_PAGE_SIZE = int(os.getenv("QUALITY_GC_PAGE_SIZE", "500"))            # —Å–∫–æ–ª—å–∫–æ —Ñ–∏–ª—å–º–æ–≤ –∑–∞ —Ä–∞–∑ —Ç—è–Ω—É—Ç—å –∏–∑ Jellyfin
# –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –ë–î –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
FORCE_QUALITY_GC_ON_START = os.getenv("FORCE_QUALITY_GC_ON_START", "0").lower() in ("1","true","yes","on")
# –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ grace-—Å—Ä–æ–∫–∞ –∏–º–µ–Ω–Ω–æ –¥–ª—è —Ñ–æ—Ä—Å-–∑–∞–ø—É—Å–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0 = —É–¥–∞–ª—è—Ç—å —Å—Ä–∞–∑—É)
FORCE_QUALITY_GC_GRACE_DAYS = os.getenv("FORCE_QUALITY_GC_GRACE_DAYS")
# –°–∂–∞—Ç—å –ë–î –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
FORCE_QUALITY_GC_VACUUM = os.getenv("FORCE_QUALITY_GC_VACUUM", "0").lower() in ("1","true","yes","on")
#–≤—ã–∫–ª—é—á–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–≤—É–∫–æ–≤—ã—Ö –¥–æ—Ä–æ–∂–∫–∞—Ö
INCLUDE_AUDIO_TRACKS = os.getenv("INCLUDE_AUDIO_TRACKS", "1").lower() in ("1", "true", "yes", "on")
#–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–µ webhook –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª–¥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN = int(os.getenv("SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN", "60"))  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60 –º–∏–Ω—É—Ç
# –û–ø—Ä–æ—Å —Å–µ—Ä–∏–∞–ª–æ–≤ (–ø–æ –Ω–æ–≤—ã–º/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º —ç–ø–∏–∑–æ–¥–∞–º)
SERIES_POLL_ENABLED = os.getenv("SERIES_POLL_ENABLED", "1").lower() in ("1","true","yes","on")
SERIES_POLL_INTERVAL_SEC = int(os.getenv("SERIES_POLL_INTERVAL_SEC", "300"))  # –ø–µ—Ä–∏–æ–¥, —Å–µ–∫
SERIES_POLL_PAGE_SIZE = int(os.getenv("SERIES_POLL_PAGE_SIZE", "500"))
SERIES_POLL_MAX_TOTAL = int(os.getenv("SERIES_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
SERIES_POLL_GRACE_MIN = int(os.getenv("SERIES_POLL_GRACE_MIN", "0"))  # —Å–≤–µ–∂–∏–µ —ç–ø–∏–∑–æ–¥—ã –æ—Ç–¥–∞—ë–º –Ω–∞ –æ—Ç–∫—É–ø –≤–µ–±—Ö—É–∫—É
# –ü–æ—Å—ã–ª–∞—Ç—å –ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø—Ä–∏ –ü–ï–†–í–û–ú –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Å–µ–∑–æ–Ω–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ—Ç)
SERIES_POLL_INITIAL_ANNOUNCE = os.getenv("SERIES_POLL_INITIAL_ANNOUNCE", "0").lower() in ("1","true","yes","on")
# –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–π–º–µ—Ä—ã –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ –≤—Ä–µ–º—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Jellyfin
NOTIFY_BLOCK_DURING_SCAN = os.getenv("NOTIFY_BLOCK_DURING_SCAN", "1").lower() in ("1","true","yes","on")
SCAN_RECHECK_DELAY_SEC = int(os.getenv("SCAN_RECHECK_DELAY_SEC", "5"))   # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
MAX_SCAN_WAIT_MIN = int(os.getenv("MAX_SCAN_WAIT_MIN", "0"))             # 0 = –∂–¥–∞—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ
# –ö–∞–∫–∏–µ –∏–º–µ–Ω–∞ –∑–∞–¥–∞—á —Å—á–∏—Ç–∞—Ç—å ¬´—Å–∫–∞–Ω–æ–º¬ª (–Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
SCAN_TASK_NAME_MATCH = [s.strip() for s in os.getenv(
    "SCAN_TASK_NAME_MATCH",
    "scan,library,metadata,refresh"
).lower().split(",") if s.strip()]
EXTERNAL_CACHE_ENABLED = os.getenv("EXTERNAL_CACHE_ENABLED", "1").lower() in ("1","true","yes","on")
TRAILER_CACHE_TTL_DAYS = int(os.getenv("TRAILER_CACHE_TTL_DAYS", "30"))
RATINGS_CACHE_TTL_DAYS = int(os.getenv("RATINGS_CACHE_TTL_DAYS", "14"))
# –ü—Ä–µ–¥–µ–ª—ã –¥–ª—è –±–ª–æ–∫–∞ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫ —É —Å–µ–∑–æ–Ω–æ–≤
SEASON_AUDIO_TRACKS_MAX = int(os.getenv("SEASON_AUDIO_TRACKS_MAX", "12"))   # –º–∞–∫—Å–∏–º—É–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ—Ä–æ–∂–µ–∫
SEASON_AUDIO_SCAN_LIMIT = int(os.getenv("SEASON_AUDIO_SCAN_LIMIT", "50"))   # –º–∞–∫—Å–∏–º—É–º —Å–µ—Ä–∏–π –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (present)
#–î–ª—è whatsapp –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
WHATSAPP_IMAGE_RETRY_ATTEMPTS = int(os.getenv("WHATSAPP_IMAGE_RETRY_ATTEMPTS", "3"))
WHATSAPP_IMAGE_RETRY_DELAY_SEC = int(os.getenv("WHATSAPP_IMAGE_RETRY_DELAY_SEC", "2"))
# --- Episode/Season quality polling (–ø–æ —Å–µ—Ä–∏—è–º -> —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–∞ —Å–µ–∑–æ–Ω) ---
EP_QUALITY_POLL_ENABLED = (os.getenv("EP_QUALITY_POLL_ENABLED", "1").lower() in ("1","true","yes","on"))
EP_QUALITY_POLL_INTERVAL_SEC = int(os.getenv("EP_QUALITY_POLL_INTERVAL_SEC", "300"))
EP_QUALITY_POLL_PAGE_SIZE = int(os.getenv("EP_QUALITY_POLL_PAGE_SIZE", "500"))
EP_QUALITY_POLL_MAX_TOTAL = int(os.getenv("EP_QUALITY_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
# –î–ª—è "—Å–≤–µ–∂–∏—Ö" —ç–ø–∏–∑–æ–¥–æ–≤ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SERIES_POLL_GRACE_MIN
# –û–ø—Ä–æ—Å –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –∞–ª—å–±–æ–º–æ–≤ (–ø–æ –Ω–æ–≤—ã–º/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º –∞–ª—å–±–æ–º–∞–º)
ALBUM_POLL_ENABLED = os.getenv("ALBUM_POLL_ENABLED", "1").lower() in ("1","true","yes","on")
ALBUM_POLL_INTERVAL_SEC = int(os.getenv("ALBUM_POLL_INTERVAL_SEC", "300"))  # –ø–µ—Ä–∏–æ–¥, —Å–µ–∫
ALBUM_POLL_PAGE_SIZE = int(os.getenv("ALBUM_POLL_PAGE_SIZE", "500"))
ALBUM_POLL_MAX_TOTAL = int(os.getenv("ALBUM_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
ALBUM_POLL_GRACE_MIN = int(os.getenv("ALBUM_POLL_GRACE_MIN", "0"))  # —Å–≤–µ–∂–∏–µ –∞–ª—å–±–æ–º—ã –æ—Ç–¥–∞—ë–º –≤–µ–±—Ö—É–∫—É (—É –Ω–∞—Å –µ–≥–æ –Ω–µ—Ç) -> 0
# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥ —Å–ø–∏—Å–∫–∞ —Ç—Ä–µ–∫–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –ø—Ä–æ –Ω–æ–≤—ã–π –∞–ª—å–±–æ–º
ALBUM_TRACKLIST_ENABLED = os.getenv("ALBUM_TRACKLIST_ENABLED", "1").lower() in ("1","true","yes","on")
ALBUM_TRACKLIST_LIMIT = int(os.getenv("ALBUM_TRACKLIST_LIMIT", "5"))  # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫
ALBUM_TRACKLIST_SHOW_DURATION = os.getenv("ALBUM_TRACKLIST_SHOW_DURATION", "1").lower() in ("1","true","yes","on")
# --- Books poll ---
BOOK_POLL_ENABLED = os.getenv("BOOK_POLL_ENABLED", "1").lower() in ("1","true","yes","on")
BOOK_POLL_INTERVAL_SEC = int(os.getenv("BOOK_POLL_INTERVAL_SEC", "300"))
BOOK_POLL_PAGE_SIZE = int(os.getenv("BOOK_POLL_PAGE_SIZE", "500"))
BOOK_POLL_MAX_TOTAL = int(os.getenv("BOOK_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
BOOK_POLL_GRACE_MIN = int(os.getenv("BOOK_POLL_GRACE_MIN", "0"))  # 0 ‚Äî —Å—Ä–∞–∑—É –æ–ø–æ–≤–µ—â–∞–µ–º –∫–æ–¥–æ–º
# --- MusicVideo (–∫–ª–∏–ø—ã) poll ---
MVID_POLL_ENABLED = os.getenv("MVID_POLL_ENABLED", "1").lower() in ("1","true","yes","on")
MVID_POLL_INTERVAL_SEC = int(os.getenv("MVID_POLL_INTERVAL_SEC", "300"))
MVID_POLL_PAGE_SIZE = int(os.getenv("MVID_POLL_PAGE_SIZE", "500"))
MVID_POLL_MAX_TOTAL = int(os.getenv("MVID_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
MVID_POLL_GRACE_MIN = int(os.getenv("MVID_POLL_GRACE_MIN", "0"))  # 0 ‚Äî –æ–ø–æ–≤–µ—â–∞–µ–º —Å—Ä–∞–∑—É –∫–æ–¥–æ–º
# --- Outbound proxy for notifications ---
# –ü—Ä–∏–º–µ—Ä: http://user:pass@1.2.3.4:8080  –∏–ª–∏  socks5h://user:pass@127.0.0.1:1080 –∏–ª–∏ http://192.168.1.34:2088
NOTIFY_PROXY_URL = os.getenv("NOTIFY_PROXY_URL", "").strip()

# –°–ø–∏—Å–æ–∫ —Ö–æ—Å—Ç–æ–≤/–º–∞—Å–æ–∫, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–æ–∫—Å–∏ –ù–ï –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é).
# –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤: exact, *.domain.tld, localhost.
NOTIFY_PROXY_NO = [h.strip() for h in os.getenv("NOTIFY_PROXY_NO", "192.168.1.*").split(",") if h.strip()]

# –ü—Ä–æ–≥–æ–Ω—è—Ç—å –ª–∏ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ –ª–æ–∫–∞–ª—å–Ω—ã–µ/–ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –∞–¥—Ä–µ—Å–∞ (RFC1918, localhost)
NOTIFY_PROXY_FOR_INTERNAL = os.getenv("NOTIFY_PROXY_FOR_INTERNAL", "0").lower() in ("1","true","yes","on")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
imgbb_upload_done = threading.Event()   # –°–∏–≥–Ω–∞–ª –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏
uploaded_image_url = None               # –ó–¥–µ—Å—å —Ö—Ä–∞–Ω–∏—Ç—Å—è —Å—Å—ã–ª–∫–∞ –ø–æ—Å–ª–µ —É–¥–∞—á–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
# Gotify –±–æ–ª—å—à–µ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ APPRISE_URLS –≤–æ–æ–±—â–µ!
#APPRISE_OTHER_URLS = os.environ.get("APPRISE_OTHER_URLS", "")
#APPRISE_URLS = APPRISE_OTHER_URLS.strip()

#apobj = Apprise()
#for url in APPRISE_URLS.split():
#    apobj.add(url)

# Path for the JSON file to store notified items
#notified_items_file = '/app/data/notified_items.json'
notified_items_file = 'A:/git/notified_items.json'

# === SQLite –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è Movie –Ω–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ) ===
QUALITY_DB_FILE = os.path.join(os.path.dirname(notified_items_file), "media_quality.db")
os.makedirs(os.path.dirname(QUALITY_DB_FILE), exist_ok=True)

def _utcnow_iso() -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç –≤ UTC –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO 8601 c 'Z' –Ω–∞ –∫–æ–Ω—Ü–µ,
    –±–µ–∑ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2025-08-31T19:45:00Z).
    """
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')

def _init_quality_db():
    conn = sqlite3.connect(QUALITY_DB_FILE)
    try:
        cur = conn.cursor()
        # —Å–Ω–∏–º–æ–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É ItemId (–∏—Å—Ç–æ—Ä–∏—è)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS media_quality (
            item_id TEXT PRIMARY KEY,
            movie_name TEXT,
            year INTEGER,
            video_codec TEXT,
            video_bitrate INTEGER,
            width INTEGER,
            height INTEGER,
            fps REAL,
            bit_depth INTEGER,
            dynamic_range TEXT,
            audio_codec TEXT,
            audio_bitrate INTEGER,
            audio_channels INTEGER,
            container TEXT,
            size_bytes INTEGER,
            duration_sec REAL,
            signature TEXT,
            date_seen TEXT
        )""")
        # "–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è" –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É (tmdb/imdb –∏–ª–∏ name+year)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS content_quality (
            logical_key TEXT PRIMARY KEY,
            last_item_id TEXT,
            movie_name TEXT,
            year INTEGER,
            video_codec TEXT,
            video_bitrate INTEGER,
            width INTEGER,
            height INTEGER,
            fps REAL,
            bit_depth INTEGER,
            dynamic_range TEXT,
            audio_codec TEXT,
            audio_bitrate INTEGER,
            audio_channels INTEGER,
            container TEXT,
            size_bytes INTEGER,
            duration_sec REAL,
            signature TEXT,
            date_seen TEXT
        )""")
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS recent_quality_updates
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        notified_at
                        TEXT,
                        item_id
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS season_progress
                    (
                        season_id
                        TEXT
                        PRIMARY
                        KEY,
                        series_id
                        TEXT,
                        series_name
                        TEXT,
                        season_number
                        INTEGER,
                        release_year
                        INTEGER,
                        present
                        INTEGER
                        DEFAULT
                        0, -- —Å–∫–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –µ—Å—Ç—å —Å–µ—Ä–∏–π –Ω–∞ –¥–∏—Å–∫–µ
                        total
                        INTEGER
                        DEFAULT
                        0, -- —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ —Å–µ—Ä–∏–π (present + missing)
                        last_notified_present
                        INTEGER
                        DEFAULT
                        0, -- –¥–æ –∫–∞–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è —É–∂–µ —Å–æ–æ–±—â–∞–ª–∏
                        updated_at
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS external_cache
                    (
                        cache_key
                        TEXT
                        PRIMARY
                        KEY,  -- —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á (—Å–º. –Ω–∏–∂–µ)
                        kind
                        TEXT
                        NOT
                        NULL, -- 'trailer' | 'ratings'
                        subkind
                        TEXT, -- 'movie' | 'show' (–¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤/—Ç—Ä–µ–π–ª–µ—Ä–æ–≤)
                        value
                        TEXT, -- –¥–ª—è —Ç—Ä–µ–π–ª–µ—Ä–∞: URL; –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤: –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
                        updated_at
                        TEXT  -- ISO8601 UTC, –∫–æ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–ª–∏
                    )
                    """)
        # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è/–ë–î
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS app_meta
                    (
                        key
                        TEXT
                        PRIMARY
                        KEY,
                        value
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS season_quality
                    (
                        season_id
                        TEXT
                        PRIMARY
                        KEY,
                        series_id
                        TEXT,
                        series_name
                        TEXT,
                        season_number
                        INTEGER,
                        release_year
                        INTEGER,
                        signature
                        TEXT, -- –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–Ω–∏–º–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º —ç–ø–∏–∑–æ–¥–∞–º
                        updated_at
                        TEXT  -- ISO
                    )""")
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS album_announced
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        announced_at
                        TEXT,
                        item_id
                        TEXT,
                        album_name
                        TEXT,
                        artist_name
                        TEXT,
                        year
                        INTEGER
                    )
                    """)
        # --- NEW: —Ñ–∏–ª—å–º—ã, —É–∂–µ ¬´–æ–±—ä—è–≤–ª–µ–Ω–Ω—ã–µ¬ª (–¥–µ–¥—É–ø –≤ –ë–î) ---
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS movie_announced
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        announced_at
                        TEXT,
                        item_id
                        TEXT,
                        movie_name
                        TEXT,
                        year
                        INTEGER
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS book_announced
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        announced_at
                        TEXT,
                        item_id
                        TEXT,
                        title
                        TEXT,
                        authors
                        TEXT,
                        year
                        INTEGER
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS musicvideo_announced
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        announced_at
                        TEXT,
                        item_id
                        TEXT,
                        title
                        TEXT,
                        artist
                        TEXT,
                        year
                        INTEGER
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS app_meta
                    (
                        key
                        TEXT
                        PRIMARY
                        KEY,
                        value
                        TEXT
                    )
                    """)
        # –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏ –ë–î –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ñ–ª–∞–≥ ¬´–Ω–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ¬ª
        cur.execute("""
                    INSERT INTO app_meta(key, value)
                    VALUES ('congrats_sent', '0') ON CONFLICT(key) DO NOTHING
                    """)
        # –ú–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–∏–º episode_count, –µ—Å–ª–∏ —Å—Ç–æ–ª–±—Ü–∞ –Ω–µ—Ç
        cur.execute("PRAGMA table_info(season_quality)")
        cols = {r[1] for r in cur.fetchall()}
        if "episode_count" not in cols:
            cur.execute("ALTER TABLE season_quality ADD COLUMN episode_count INTEGER")
        # –µ—Å–ª–∏ –Ω–µ—Ç —à—Ç–∞–º–ø–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î ‚Äî –ø—Ä–æ—Å—Ç–∞–≤–∏–º —Å–µ–π—á–∞—Å
        cur.execute("SELECT value FROM app_meta WHERE key='db_created_at'")
        row = cur.fetchone()
        if not row:
            cur.execute("INSERT INTO app_meta(key,value) VALUES('db_created_at', ?)", (_utcnow_iso(),))
        # --- –ú—è–≥–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É image_profiles, –µ—Å–ª–∏ –µ—ë –µ—â—ë –Ω–µ—Ç
        try:
            cur.execute("ALTER TABLE media_quality ADD COLUMN image_profiles TEXT")
        except Exception:
            pass
        try:
            cur.execute("ALTER TABLE content_quality ADD COLUMN image_profiles TEXT")
        except Exception:
            pass
        conn.commit()
    finally:
        conn.close()

_init_quality_db()

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ /app/data —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
os.makedirs(os.path.dirname(notified_items_file), exist_ok=True)

# Function to load notified items from the JSON file
def load_notified_items():
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å ‚Äî —á–∏—Ç–∞–µ–º, –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º {}
    try:
        if os.path.exists(notified_items_file):
            with open(notified_items_file, 'r', encoding='utf-8') as file:
                return json.load(file) or {}
    except Exception as ex:
        logging.debug(f"notified_items.json read skipped: {ex}")
    return {}

# Function to save notified items to the JSON file
def save_notified_items(notified_items_to_save):
    # –§–∞–π–ª –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
    return


notified_items = load_notified_items()

# 2. –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–≤–æ–¥–æ–≤
MESSAGES = {
    "en": {
        "new_movie_title": "üçøNew Movie Addedüçø",
        "new_season_title": "üì∫New Season Addedüì∫",
        "new_episode_title": "üì∫New Episode Addedüì∫",
        "new_album_title": "üéµNew Album Addedüéµ",
        "new_runtime": "üïíRuntimeüïí",
        "new_ratings_movie": "‚≠êRatings movie‚≠ê",
        "new_ratings_show": "‚≠êRatings show‚≠ê",
        "new_trailer": "Trailer",
        "new_release_date": "Release Date",
        "new_series": "Series",
        "new_episode_t": "Episode Title",
        "audio_tracks": "Audio tracks",
        "image_profiles": "Image profiles",
        "quality_updated": "üîºQuality updateüîº",
        "season_added_progress": "Added {added} of {total} episodes",
        "season_added_count_only": "Added {added} episodes",
        "new_track_count": "Tracks",
        "album_tracklist": "Tracklist",
        "album_tracklist_more": "‚Ä¶and {n} more",
        "new_book_title": "üìñNew book Addedüìñ",
        "new_authors": "Author(s)",
        "new_isbn": "ISBN",
        "new_book_header": "üìñNew book Addedüìñ",
        "new_audiobook_header": "üíøNew audiobook addedüíø",
        "new_musicvideo_header": "üé∂New music video addedüé∂",
        "new_musicvideo_artist": "Artist",
        "new_musicvideo_album": "Album",
        "onboarding_congrats": "üéâ Congratulations! The app is ready to use.",
    },
    "ru": {
        "new_movie_title": "üçø–ù–æ–≤—ã–π —Ñ–∏–ª—å–º –¥–æ–±–∞–≤–ª–µ–Ωüçø",
        "new_season_title": "üì∫–ù–æ–≤—ã–π —Å–µ–∑–æ–Ω –¥–æ–±–∞–≤–ª–µ–Ωüì∫",
        "new_episode_title": "üì∫–ù–æ–≤—ã–π —ç–ø–∏–∑–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ωüì∫",
        "new_album_title": "üéµ–ù–æ–≤—ã–π –∞–ª—å–±–æ–º –¥–æ–±–∞–≤–ª–µ–Ωüéµ",
        "new_runtime": "üïí–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—åüïí",
        "new_ratings_movie": "‚≠ê–†–µ–π—Ç–∏–Ω–≥–∏ —Ñ–∏–ª—å–º–∞‚≠ê",
        "new_ratings_show": "‚≠ê–†–µ–π—Ç–∏–Ω–≥–∏ —Å–µ—Ä–∏–∞–ª–∞‚≠ê",
        "new_trailer": "–¢—Ä–µ–π–ª–µ—Ä",
        "new_release_date": "–î–∞—Ç–∞ –≤—ã—Ö–æ–¥–∞",
        "new_series": "–°–µ—Ä–∏–∞–ª",
        "new_episode_t": "–ù–∞–∑–≤–∞–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∞",
        "audio_tracks": "–ê—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏",
        "image_profiles": "–ü—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "quality_updated": "üîº–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞üîº",
        "season_added_progress": "–î–æ–±–∞–≤–ª–µ–Ω–æ {added} –∏–∑ {total} —Å–µ—Ä–∏–π",
        "season_added_count_only": "–î–æ–±–∞–≤–ª–µ–Ω–æ {added} —Å–µ—Ä–∏–π",
        "new_track_count": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–∫–æ–≤",
        "album_tracklist": "–°–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤",
        "album_tracklist_more": "‚Ä¶–∏ –µ—â—ë {n}",
        "new_book_title": "üìñ–ù–æ–≤–∞—è –∫–Ω–∏–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞üìñ",
        "new_authors": "–ê–≤—Ç–æ—Ä(—ã)",
        "new_isbn": "ISBN",
        "new_book_header": "üìñ–ù–æ–≤–∞—è –∫–Ω–∏–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞üìñ",
        "new_audiobook_header": "üíø–ù–æ–≤–∞—è –∞—É–¥–∏–æ–∫–Ω–∏–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞üíø",
        "new_musicvideo_header": "üé∂–ù–æ–≤—ã–π –∫–ª–∏–ø –¥–æ–±–∞–≤–ª–µ–Ωüé∂",
        "new_musicvideo_artist": "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å",
        "new_musicvideo_album": "–ê–ª—å–±–æ–º",
        "onboarding_congrats": "üéâ –ü–æ–∑–¥—Ä–∞–≤–ª—è—é! –ü—Ä–æ–≥—Ä–∞–º–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ.",
    }
}
#–í—ã–±–∏—Ä–∞–µ–º —Ä–∞–±–æ—á–∏–π —è–∑—ã–∫: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–Ω—ã–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ MESSAGES ‚Äî —Å—Ç–∞–≤–∏–º en
LANG = LANGUAGE if LANGUAGE in MESSAGES else "en"

def t(key: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –ø–æ –∫–ª—é—á—É –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —è–∑—ã–∫–∞ LANG.
    –ï—Å–ª–∏ –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø–∞–¥–∞–µ—Ç KeyError, —á—Ç–æ–±—ã –≤—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞.
    """
    return MESSAGES[LANG][key]

#–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
def _task_name_matches(name: str | None) -> bool:
    if not name:
        return False
    n = name.lower()
    return any(seg in n for seg in SCAN_TASK_NAME_MATCH)

def is_jellyfin_scanning() -> tuple[bool, str | None]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ª–∏ —Å–µ–π—á–∞—Å —Å–∫–∞–Ω/—Ä–µ—Ñ—Ä–µ—à –º–µ–¥–∏–∞—Ç–µ–∫–∏/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Jellyfin.
    1) /emby/ScheduledTasks/Running (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
    2) /emby/ScheduledTasks (–∏—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è Running/Executing/IsRunning)
    –í–æ–∑–≤—Ä–∞—Ç: (True/False, –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ)
    """
    headers = {'accept': 'application/json'}
    params = {'api_key': JELLYFIN_API_KEY}

    # 1) —Ç–µ–∫—É—â–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã–µ –∑–∞–¥–∞—á–∏
    try:
        url = f"{JELLYFIN_BASE_URL}/emby/ScheduledTasks/Running"
        r = requests.get(url, headers=headers, params=params, timeout=6)
        if r.status_code == 200:
            data = r.json() or []
            for t in data:
                name = t.get("Name") or t.get("Key") or ""
                state = t.get("State") or ""
                prog = t.get("CurrentProgressPercentage") or t.get("Progress") or t.get("PercentComplete")
                if _task_name_matches(name):
                    desc = f"{name} {prog}%" if prog is not None else name
                    return True, desc
    except Exception:
        pass

    # 2) –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
    try:
        url = f"{JELLYFIN_BASE_URL}/emby/ScheduledTasks"
        r = requests.get(url, headers=headers, params=params, timeout=8)
        if r.status_code == 200:
            data = r.json() or []
            for t in data:
                name = t.get("Name") or t.get("Key") or ""
                state = (t.get("State") or "").lower()
                is_running = bool(t.get("IsRunning")) or state in ("running", "executing", "inprogress")
                if is_running and _task_name_matches(name):
                    prog = t.get("CurrentProgressPercentage") or t.get("Progress") or t.get("PercentComplete")
                    desc = f"{name} {prog}%" if prog is not None else name
                    return True, desc
    except Exception:
        pass

    return False, None

def wait_until_scan_idle(reason: str = ""):
    """
    –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω NOTIFY_BLOCK_DURING_SCAN ‚Äî –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–∫–∞–Ω–∞ Jellyfin.
    MAX_SCAN_WAIT_MIN=0 => –∂–¥—ë–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ.
    """
    if not NOTIFY_BLOCK_DURING_SCAN:
        return
    start = time.time()
    first_log = True
    while True:
        running, detail = is_jellyfin_scanning()
        if not running:
            if not first_log:
                logging.info("Jellyfin scan finished, resume timers.")
            return
        if first_log:
            logging.info(f"Timers paused: Jellyfin is scanning ({detail or 'library task running'})"
                         + (f" [reason: {reason}]" if reason else ""))
            first_log = False
        if MAX_SCAN_WAIT_MIN and (time.time() - start) > MAX_SCAN_WAIT_MIN * 60:
            logging.warning("Max wait for scan reached; resuming timers anyway.")
            return
        time.sleep(max(SCAN_RECHECK_DELAY_SEC, 1))

def _movie_poll_loop():
    while True:
        try:
            wait_until_scan_idle("movie poll")
            poll_recent_movies_once()
        except Exception as ex:
            logging.warning(f"Movie poll loop error: {ex}")
        time.sleep(MOVIE_POLL_INTERVAL_SEC)

def _series_poll_loop():
    while True:
        try:
            wait_until_scan_idle("series poll")
            poll_recent_episodes_once()
        except Exception as ex:
            logging.warning(f"Series poll loop error: {ex}")
        time.sleep(SERIES_POLL_INTERVAL_SEC)

def _wa_get_jid_from_env():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç JID –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≥—Ä—É–ø–ø—É.
    –ò–Ω–∞—á–µ –ª–∏—á–Ω—ã–π —á–∞—Ç –∏–∑ WHATSAPP_JID –∏–ª–∏ WHATSAPP_NUMBER.
    """
    group_jid = WHATSAPP_GROUP_JID.strip()
    if group_jid:
        if not group_jid.endswith("@g.us"):
            # –¥–æ–ø—É—Å—Ç–∏–º, –ø–µ—Ä–µ–¥–∞–ª–∏ —Ç–æ–ª—å–∫–æ id –±–µ–∑ @g.us
            group_jid = re.sub(r"[^\w\-]", "", group_jid) + "@g.us"
        return group_jid

    # –õ–∏—á–Ω—ã–π
    raw = (WHATSAPP_JID or WHATSAPP_NUMBER).strip()
    if not raw:
        return None
    if raw.endswith("@s.whatsapp.net"):
        return raw
    # –æ—á–∏—â–∞–µ–º –¥–æ —Ü–∏—Ñ—Ä –∏ –¥–æ–±–∞–≤–ª—è–µ–º –¥–æ–º–µ–Ω
    local = re.sub(r"\D", "", raw)
    return f"{local}@s.whatsapp.net" if local else None

def jellyfin_get_tmdb_id(item_id: str) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç TMDB ID –¥–ª—è –ª—é–±–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ Jellyfin –ø–æ –µ–≥–æ Id.
    –ß–∏—Ç–∞–µ—Ç Items?Ids=...&Fields=ProviderIds –∏ –±–µ—Ä—ë—Ç –Ω—É–∂–Ω—ã–π –∫–ª—é—á –∏–∑ ProviderIds.
    """
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "Ids": item_id,
            "Fields": "ProviderIds"
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=8)
        r.raise_for_status()
        items = (r.json() or {}).get("Items") or []
        if not items:
            return None
        prov = items[0].get("ProviderIds") or {}
        # —Ä–∞–∑–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä–∞/–≤–µ—Ä—Å–∏–∏ –º–æ–≥—É—Ç –∑–≤–∞—Ç—å –∫–ª—é—á –ø–æ-—Ä–∞–∑–Ω–æ–º—É ‚Äî —É—á—Ç—ë–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
        return prov.get("Tmdb") or prov.get("TmdbId") or prov.get("TMDB") or None
    except Exception as ex:
        logging.warning(f"Failed to read ProviderIds for {item_id}: {ex}")
        return None


def fetch_mdblist_ratings(content_type: str, tmdb_id: str) -> str:
    """
    –ó–∞–ø—Ä–æ—Å –∫ https://api.mdblist.com/tmdb/{type}/{tmdbId}
    –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
      "- IMDb: 7.8\n- Rotten Tomatoes: 84%\n‚Ä¶"
    –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏ –æ—à–∏–±–∫–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    url = f"https://api.mdblist.com/tmdb/{content_type}/{tmdb_id}?apikey={MDBLIST_API_KEY}"
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        ratings = data.get("ratings")
        if not isinstance(ratings, list):
            return ""

        lines = []
        for r in ratings:
            source = r.get("source")
            value = r.get("value")
            if source is None or value is None:
                continue
            lines.append(f"- {source}: {value}")

        return "\n".join(lines)
    except requests.RequestException as e:
        app.logger.warning(f"MDblist API error for {content_type}/{tmdb_id}: {e}")
        return ""

def upload_image_to_imgbb(image_bytes):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ imgbb.com (–¥–æ 3 –ø–æ–ø—ã—Ç–æ–∫) –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏.
    """
    global uploaded_image_url
    uploaded_image_url = None
    imgbb_upload_done.clear()  # –°–±—Ä–æ—Å —Å–æ–±—ã—Ç–∏—è

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞ API
    if not IMGBB_API_KEY:
        logging.debug("IMGBB_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ imgbb.")
        imgbb_upload_done.set()  # –°–∏–≥–Ω–∞–ª –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (–ø—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏)
        return None

    url = "https://api.imgbb.com/1/upload"
    payload = {
        "key": IMGBB_API_KEY,
        "image": base64.b64encode(image_bytes).decode('utf-8')
    }

    for attempt in range(1, 4):
        try:
            logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb #{attempt}")
            response = requests.post(url, data=payload, timeout=20)
            response.raise_for_status()
            data = response.json()
            uploaded_image_url = data['data']['url']
            logging.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞ imgbb: {uploaded_image_url}")
            break
        except Exception as ex:
            logging.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {ex}")
            if attempt < 3:
                time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

    imgbb_upload_done.set()  # –°–∏–≥–Ω–∞–ª, —á—Ç–æ –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—É—Å–ø–µ—à–Ω–æ –∏–ª–∏ –Ω–µ—Ç)
    return uploaded_image_url

def wait_for_imgbb_upload(timeout: float | None = 10.0):
    """
    –ñ–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç URL –∏–ª–∏ None –ø–æ —Ç–∞–π–º–∞—É—Ç—É/–æ—à–∏–±–∫–µ.
    """
    signaled = imgbb_upload_done.wait(timeout=timeout if timeout is not None else None)
    if not signaled:
        logging.warning("IMGBB wait timed out; continue without image.")
    return uploaded_image_url


def get_jellyfin_image_and_upload_imgbb(photo_id):
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    try:
        resp = requests.get(jellyfin_image_url, timeout=10)
        resp.raise_for_status()
        return upload_image_to_imgbb(resp.content)
    except Exception as ex:
        logging.warning(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ Jellyfin: {ex}")
        # –í–ê–ñ–ù–û: —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –æ–∂–∏–¥–∞—Ç–µ–ª–µ–π imgbb
        try:
            imgbb_upload_done.set()
        except Exception:
            pass
        return None

def send_discord_message(photo_id, message, title="Jellyfin", uploaded_url=None):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Discord —á–µ—Ä–µ–∑ Webhook.
    –ö–∞—Ä—Ç–∏–Ω–∫—É –±–µ—Ä—ë–º –ù–ê–ü–†–Ø–ú–£–Æ –∏–∑ Jellyfin –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª.
    Embed —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –Ω–µ—ë —á–µ—Ä–µ–∑ attachment://filename.
    """
    if not DISCORD_WEBHOOK_URL:
        logging.warning("DISCORD_WEBHOOK_URL not set, skipping Discord notification.")
        return None

    # 1) —Ç—è–Ω–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    image_bytes = None
    filename = "poster.jpg"
    mimetype = "image/jpeg"
    try:
        r = requests.get(jellyfin_image_url, timeout=30)
        r.raise_for_status()
        image_bytes = r.content
        ct = r.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
        if "png" in ct:
            filename, mimetype = "poster.png", "image/png"
        elif "webp" in ct:
            filename, mimetype = "poster.webp", "image/webp"
    except Exception as ex:
        logging.warning(f"Discord: failed to fetch image from Jellyfin: {ex}")

    # 2) –≥–æ—Ç–æ–≤–∏–º payload
    payload = {
        "username": title,
        "content": message
    }

    # –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∞ ‚Äî –¥–æ–±–∞–≤–∏–º embed, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ attachment
    if image_bytes:
        payload["embeds"] = [{
            "image": {"url": f"attachment://{filename}"}
        }]

    try:
        if image_bytes:
            # multipart: payload_json + —Ñ–∞–π–ª
            files = {
                "file": (filename, image_bytes, mimetype)
            }
            resp = requests.post(
                DISCORD_WEBHOOK_URL,
                data={"payload_json": json.dumps(payload, ensure_ascii=False)},
                files=files,
                timeout=30
            )
        else:
            # –±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ–±—ã—á–Ω—ã–π JSON
            resp = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=30)

        resp.raise_for_status()
        logging.info("Discord notification sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Error sending to Discord: {ex}")
        return None

def clean_markdown_for_apprise(text):
    """
    –£–ø—Ä–æ—â–∞–µ—Ç markdown-–ø–æ–¥–æ–±–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è plain text –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç —Å—Å—ã–ª–∫–∏ –∫ –µ–¥–∏–Ω–æ–º—É –≤–∏–¥—É:
    - [—Ç–µ–∫—Å—Ç](url) -> url
    - –£–±–∏—Ä–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ–¥—Ä—è–¥ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ url
    - –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å 'üé• <–ø–µ—Ä–µ–≤–æ–¥ new_trailer>:' –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —Å—Å—ã–ª–∫–æ–π (–±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
    - –û—á–∏—â–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º —Å—Ç—Ä–æ–∫
    """
    if not text:
        return text

    # 0) –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–µ—Ç–∫—É –¥–ª—è "–¢—Ä–µ–π–ª–µ—Ä"
    try:
        trailer_label = t("new_trailer")
    except Exception:
        trailer_label = MESSAGES.get(LANG, {}).get("new_trailer", "Trailer")
    if not trailer_label:
        trailer_label = "Trailer"
    # 1) [—Ç–µ–∫—Å—Ç](url) -> url
    text = re.sub(r'\[([^\]]+)\]\((https?://[^\s)]+)\)', r'\2', text)

    # 2) –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL
    text = re.sub(r'(https?://\S+)(\s*\1)+', r'\1', text)

    # 3) –°–Ω–∞—á–∞–ª–∞ —É–±–∏—Ä–∞–µ–º —É–∂–µ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã,
    #    –∑–∞—Ç–µ–º –¥–æ–±–∞–≤–∏–º –∏—Ö –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ
    prefix_pattern = rf'üé•\s*{re.escape(trailer_label)}[:]?\s*'
    text = re.sub(rf'{prefix_pattern}(https?://\S+)', r'\1', text)

    # 4) –ü—Ä–µ—Ñ–∏–∫—Å—É–µ–º –¢–û–õ–¨–ö–û –Ω–µ-musicbrainz —Å—Å—ã–ª–∫–∏ (—á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫)
    def _prefix_non_mb(m):
        url = m.group(1)
        if re.search(r'https?://(?:[^/\s)]+\.)*musicbrainz\.org(?=[/\s)]|$)', url, re.IGNORECASE):
            return url
        return f'üé• {trailer_label}: {url}'

    text = re.sub(r'(https?://\S+)', _prefix_non_mb, text)
    # 5) –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º —Å—Ç—Ä–æ–∫ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã)
    text = '\n'.join(line.strip() for line in text.split('\n'))

    # –£–±—Ä–∞—Ç—å *–∂–∏—Ä–Ω—ã–π* –∏ _–∫—É—Ä—Å–∏–≤_
    text = re.sub(r'(\*|_){1,3}(.+?)\1{1,3}', r'\2', text)

    return text

def _extract_bold_line(line: str) -> str | None:
    m = re.fullmatch(r"\*\s*(.+?)\s*\*", (line or "").strip())
    return m.group(1).strip() if m else None

def make_jf_inapp_payload_from_caption(caption: str) -> tuple[str, str]:
    """
    –ò–∑ Markdown-—Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–±–∏—Ä–∞–µ—Ç:
      header -> –ø–µ—Ä–≤–∞—è –∂–∏—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (*...*)
      title  -> –≤—Ç–æ—Ä–∞—è –∂–∏—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (*...*)
      overview -> –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ title –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –∂–∏—Ä–Ω–æ–π —Å–µ–∫—Ü–∏–∏/–∫–æ–Ω—Ü–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (header, text) –≥–¥–µ text = "title\\n\\noverview" (–±–µ–∑ Markdown).
    –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç ‚Äî gracefully –¥–µ–≥—Ä–∞–¥–∏—Ä—É–µ–º.
    """
    caption = caption or ""
    lines = caption.replace("\r\n", "\n").replace("\r", "\n").split("\n")

    # 1) –Ω–∞–π—Ç–∏ header
    i = 0
    while i < len(lines) and not lines[i].strip():
        i += 1
    header = _extract_bold_line(lines[i]) if i < len(lines) else None
    if header is None:
        # –Ω–µ—Ç –∂–∏—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî –±–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π –Ω–µ–ø—É—Å—Ç–æ–π –∫–∞–∫ "title", –∞ header ‚Äî –¥–µ—Ñ–æ–ª—Ç
        first_non_empty = next((ln for ln in lines if ln.strip()), "")
        title_plain = clean_markdown_for_apprise(first_non_empty)
        header_plain = "Jellyfin"
        return header_plain, title_plain

    i += 1
    while i < len(lines) and not lines[i].strip():
        i += 1

    # 2) –Ω–∞–π—Ç–∏ title (–≤—Ç–æ—Ä–∞—è –∂–∏—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞)
    title_md = _extract_bold_line(lines[i]) if i < len(lines) else None
    i += 1 if title_md is not None else 0

    # 3) —Å–æ–±—Ä–∞—Ç—å overview –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –∂–∏—Ä–Ω–æ–π —Å–µ–∫—Ü–∏–∏
    overview_parts = []
    while i < len(lines):
        ln = lines[i]
        if _extract_bold_line(ln) is not None:
            break  # –Ω–∞—á–∞–ª–∞—Å—å —Å–ª–µ–¥—É—é—â–∞—è —Å–µ–∫—Ü–∏—è (*...*)
        overview_parts.append(ln)
        i += 1

    # 4) –æ—á–∏—Å—Ç–∏—Ç—å Markdown ‚Üí plain
    header_plain = clean_markdown_for_apprise(header)
    title_plain  = clean_markdown_for_apprise(title_md) if title_md else ""
    overview_plain = clean_markdown_for_apprise("\n".join(overview_parts)).strip()

    # –ò—Ç–æ–≥–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è Jellyfin: —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ
    text = title_plain if title_plain else ""
    if overview_plain:
        text = (text + ("\n\n" if text else "")) + overview_plain

    # Fallback, –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –≤—Å—ë –ø—É—Å—Ç–æ
    if not text:
        text = clean_markdown_for_apprise(caption)[:500]

    return header_plain or "Jellyfin", text

def _split_caption_for_reddit(caption: str) -> tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (title, body_md) –¥–ª—è Reddit:
      - title: –ø–µ—Ä–≤–∞—è –∂–∏—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ (*...*) ‚Äî ¬´—à–∞–ø–∫–∞¬ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, New Movie Added)
      - body_md: caption –ë–ï–ó ¬´—à–∞–ø–∫–∏¬ª. –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –≤—Ç–æ—Ä–æ–π –∂–∏—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–∑–≤–∞–Ω–∏–µ), –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç.
    –ï—Å–ª–∏ ¬´—à–∞–ø–∫–∏¬ª –Ω–µ—Ç ‚Äî title='Jellyfin', body=–∏—Å—Ö–æ–¥–Ω—ã–π caption.
    """
    import re
    caption = (caption or "").replace("\r\n", "\n").replace("\r", "\n")
    lines = caption.split("\n")

    # –Ω–∞–π—Ç–∏ –ø–µ—Ä–≤—É—é –∂–∏—Ä–Ω—É—é —Å—Ç—Ä–æ–∫—É (*...*)
    header = None
    hdr_idx = None
    for i, ln in enumerate(lines):
        m = re.fullmatch(r"\*\s*(.+?)\s*\*", ln.strip())
        if m:
            header = m.group(1).strip()
            hdr_idx = i
            break

    if header is None:
        return "Jellyfin", caption

    # —Ç–µ–ª–æ = –≤—Å—ë, –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–π –∂–∏—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ (—à–∞–ø–∫–∏)
    body = "\n".join(lines[:hdr_idx] + lines[hdr_idx+1:])
    # –ø–æ–¥—á–∏—Å—Ç–∏–º –≤–µ–¥—É—â–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    while body.startswith("\n"):
        body = body[1:]
    while body.startswith("\n\n"):
        body = body[2:]
    return header or "Jellyfin", body.strip()



def sanitize_whatsapp_text(text: str) -> str:
    if not text:
        return text

    # –ë–µ—Ä—ë–º —è–∑—ã–∫ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    lang = os.environ.get("LANGUAGE", "en")
    trailer_label = MESSAGES.get(lang, {}).get("new_trailer")

    # 1) –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º [–ª—é–±–æ–π —Ç–µ–∫—Å—Ç](https://...) –≤ –ø—Ä–æ—Å—Ç–æ https://...
    text = re.sub(r'\[([^\]]+)\]\((https?://[^\)]+)\)', r'\2', text)

    # 2) –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL
    text = re.sub(r'(https?://\S+)(\s*\1)+', r'\1', text)


    # 3) –°–Ω–æ—Å–∏–º —É–∂–µ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã (–Ω–∞ –≤—Å—è–∫–∏–π)
    prefix_re = rf'üé•\s*{re.escape(trailer_label)}:?[\s]*'
    text = re.sub(rf'{prefix_re}(https?://\S+)', r'\1', text)

    # 4) –ü—Ä–µ—Ñ–∏–∫—Å—É–µ–º –¢–û–õ–¨–ö–û –Ω–µ-musicbrainz —Å—Å—ã–ª–∫–∏ (—á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫)
    def _prefix_non_mb(m):
        url = m.group(1)
        if re.search(r'https?://(?:[^/\s)]+\.)*musicbrainz\.org(?=[/\s)]|$)', url, re.IGNORECASE):
            return url
        return f'üé• {trailer_label} {url}'

    text = re.sub(r'(https?://\S+)', _prefix_non_mb, text)

    # 5) –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'[ \t]+', ' ', text).strip()

    return text

def markdown_to_pushover_html(text: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç ¬´—É–ø—Ä–æ—â—ë–Ω–Ω—ã–π Markdown¬ª –≤–∞—à–∏—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –≤ HTML,
    —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å Pushover (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: <b>, <i>, <u>, <a>).
    - –°—Å—ã–ª–∫–∏ [—Ç–µ–∫—Å—Ç](url) -> <a href="url">—Ç–µ–∫—Å—Ç</a>
    - –ñ–∏—Ä–Ω—ã–π: **‚Ä¶** –∏ —Å—Ç—Ä–æ–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ *‚Ä¶* –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ -> <b>‚Ä¶</b>
    - –ö—É—Ä—Å–∏–≤: *‚Ä¶* –∏ _‚Ä¶_ -> <i>‚Ä¶</i>
    - –ó–∞–≥–æ–ª–æ–≤–∫–∏ '# ' –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ -> <b>‚Ä¶</b>
    - –ú–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤ "- " / "* " -> "‚Ä¢ "
    - –ë—ç–∫—Ç–∏–∫–∏ `‚Ä¶` ‚Äî —É–±–∏—Ä–∞—é—Ç—Å—è (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, —É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ)
    - –ü–µ—Ä–µ—Ö–æ–¥—ã —Å—Ç—Ä–æ–∫: \n (—Ç–µ–≥–∏ <br> Pushover –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)
    –í–µ—Å—å –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç HTML-—ç–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç—Å—è.
    """
    if not text:
        return ""

    s = text.replace("\r\n", "\n").replace("\r", "\n")

    def _esc(t: str) -> str:
        return (t.replace("&", "&amp;")
                 .replace("<", "&lt;")
                 .replace(">", "&gt;")
                 .replace('"', "&quot;"))

    # 0) –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤—Å—ë (—á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å HTML), –¥–∞–ª—å—à–µ –≤—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –Ω–∞—à–∏ —Ç–µ–≥–∏
    s = _esc(s)

    import re

    # 1) –°—Å—ã–ª–∫–∏: [text](https://url)
    def _link_repl(m: re.Match) -> str:
        txt = m.group(1)
        url = m.group(2)
        # —ç—Å–∫–µ–π–ø –¥–ª—è href
        url = url.replace("&", "&amp;").replace('"', "&quot;").strip()
        return f'<a href="{url}">{txt}</a>'
    s = re.sub(r"\[([^\]]+)\]\((https?://[^\s)]+)\)", _link_repl, s)

    # 2) –ñ–∏—Ä–Ω—ã–π: **‚Ä¶**
    s = re.sub(r"\*\*(.+?)\*\*", lambda m: f"<b>{m.group(1)}</b>", s)

    # 3) –ñ–∏—Ä–Ω–∞—è ¬´—Ü–µ–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞¬ª –≤ —Å—Ç–∏–ª–µ –≤–∞—à–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: *‚Ä¶* –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
    s = re.sub(r"(?m)^\*\s*(.+?)\s*\*$", lambda m: f"<b>{m.group(1)}</b>", s)

    # 4) –ñ–∏—Ä–Ω—ã–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π: __‚Ä¶__
    s = re.sub(r"__(.+?)__", lambda m: f"<b>{m.group(1)}</b>", s)

    # 5) –ö—É—Ä—Å–∏–≤: *‚Ä¶* (–≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏) ‚Äî –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ¬´—Ü–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–∏¬ª
    s = re.sub(r"\*(.+?)\*", lambda m: f"<i>{m.group(1)}</i>", s)

    # 6) –ö—É—Ä—Å–∏–≤: _‚Ä¶_
    s = re.sub(r"_(.+?)_", lambda m: f"<i>{m.group(1)}</i>", s)

    # 7) –ó–∞–≥–æ–ª–æ–≤–∫–∏: '# ' –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ -> <b>‚Ä¶</b>
    s = re.sub(r"(?m)^#\s+(.*)$", lambda m: f"<b>{m.group(1)}</b>", s)

    # 8) –ú–∞—Ä–∫–µ—Ä—ã —Å–ø–∏—Å–∫–æ–≤ -> –±—É–ª–ª–µ—Ç
    s = re.sub(r"(?m)^\s*[-*]\s+", "‚Ä¢ ", s)

    # 9) –£–±—Ä–∞—Ç—å –∏–Ω–ª–∞–π–Ω-–∫–æ–¥–æ–≤—ã–µ –±—ç–∫—Ç–∏–∫–∏ (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —É–∂–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ –Ω–∞ —à–∞–≥–µ 0)
    s = re.sub(r"`(.+?)`", r"\1", s)

    # 10) –°—Ö–ª–æ–ø—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ —Ç—Ä–æ–π–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã –≤ –¥–≤–æ–π–Ω—ã–µ (–∞–∫–∫—É—Ä–∞—Ç–Ω–µ–µ –≤—ã–≥–ª—è–¥–∏—Ç)
    s = re.sub(r"\n{3,}", "\n\n", s)

    return s


def send_email_with_image_jellyfin(photo_id: str, subject: str, body_markdown: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email —Å:
      - text/plain (plain-–≤–µ—Ä—Å–∏—è —Ç–µ–∫—Å—Ç–∞)
      - text/html (Markdown ‚Üí HTML)
      - inline-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–∑ Jellyfin (—á–µ—Ä–µ–∑ CID)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True/False.
    """
    if not (SMTP_HOST and SMTP_FROM and SMTP_TO):
        logging.debug("Email disabled or misconfigured; skip.")
        return False

    # plain-–≤–µ—Ä—Å–∏—è (–±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å
    body_plain = clean_markdown_for_apprise(body_markdown or "")

    # HTML-–≤–µ—Ä—Å–∏—è ‚Äî —Ä–µ–Ω–¥–µ—Ä–∏–º –∏–∑ Markdown
    # extensions –¥–ª—è –±–æ–ª–µ–µ –ø—Ä–∏—è—Ç–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤/–ø–µ—Ä–µ–Ω–æ—Å–æ–≤
    body_html_rendered = markdown.markdown(
        body_markdown or "",
        extensions=["extra", "sane_lists", "nl2br"]
    )

    # –¢—è–Ω–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ Jellyfin (—Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏)
    img_bytes = None
    img_subtype = "jpeg"
    try:
        img_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        # subtype –ø–æ–¥–±–µ—Ä—ë–º –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ (–µ—Å–ª–∏ –µ—Å—Ç—å headers –≤ —Ä–µ—Ç—Ä–∞–µ ‚Äî –º–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤–º–µ—Å—Ç–µ)
        # –∑–¥–µ—Å—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º jpeg; –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    except Exception as ex:
        logging.warning(f"Email: failed to fetch Jellyfin image: {ex}")

    msg = EmailMessage()
    msg["Subject"] = subject or SMTP_SUBJECT
    msg["From"]    = SMTP_FROM
    recipients = [x.strip() for x in re.split(r"[,\s]+", SMTP_TO) if x.strip()]
    msg["To"]     = ", ".join(recipients)
    msg["Date"]   = formatdate(localtime=True)

    # 1) text/plain
    msg.set_content(body_plain or "")

    # 2) text/html (+ inline image –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏)
    if img_bytes:
        cid = make_msgid()  # –≤–∏–¥–∞ <...@domain>
        html_part = f"""\
<html>
  <body>
    <div>{body_html_rendered}</div>
    <p><img src="cid:{cid[1:-1]}" alt="poster"></p>
  </body>
</html>"""
        msg.add_alternative(html_part, subtype="html")
        try:
            # –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∫ HTML-—á–∞—Å—Ç–∏ –∫–∞–∫ related
            msg.get_payload()[1].add_related(img_bytes, maintype="image", subtype=img_subtype, cid=cid)
        except Exception as ex:
            logging.warning(f"Email: cannot embed inline image (fallback as attachment): {ex}")
            msg.add_attachment(img_bytes, maintype="image", subtype=img_subtype, filename="poster.jpg")
    else:
        # –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ HTML –±–µ–∑ —Ç–µ–≥–∞ <img>
        msg.add_alternative(f"<html><body>{body_html_rendered}</body></html>", subtype="html")

    # –û—Ç–ø—Ä–∞–≤–∫–∞
    try:
        if SMTP_USE_SSL or SMTP_PORT == 465:
            with smtplib.SMTP_SSL(SMTP_HOST, SMTP_PORT, timeout=30) as s:
                if SMTP_USER:
                    s.login(SMTP_USER, SMTP_PASS)
                s.send_message(msg)
        else:
            with smtplib.SMTP(SMTP_HOST, SMTP_PORT, timeout=30) as s:
                if SMTP_USE_TLS:
                    s.starttls()
                if SMTP_USER:
                    s.login(SMTP_USER, SMTP_PASS)
                s.send_message(msg)
        logging.info("Email notification (Markdown->HTML) sent successfully")
        return True
    except Exception as ex:
        logging.warning(f"Email send failed: {ex}")
        return False

def _slack_try_join_channel(channel_id: str) -> bool:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ—Ç–∞ –≤ PUBLIC-–∫–∞–Ω–∞–ª (—Ç—Ä–µ–±—É–µ—Ç scope channels:join).
    –î–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é /invite –≤ Slack.
    """
    if not (SLACK_BOT_TOKEN and channel_id):
        return False
    try:
        resp = requests.post(
            "https://slack.com/api/conversations.join",
            headers={
                "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
                "Content-Type": "application/json; charset=utf-8",
            },
            json={"channel": channel_id},
            timeout=15,
        )
        data = resp.json()
        if not data.get("ok"):
            logging.debug(f"Slack join failed/ignored: {data.get('error')}")
            return False
        return True
    except Exception as ex:
        logging.debug(f"Slack join error: {ex}")
        return False

def send_slack_text_only(message_markdown: str) -> bool:
    """
    –§–æ–ª–ª–±—ç–∫ –Ω–∞ —á–∞—Ç –±–µ–∑ —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç chat.postMessage.
    """
    if not (SLACK_BOT_TOKEN and SLACK_CHANNEL_ID):
        logging.debug("Slack disabled/misconfigured; skip text.")
        return False

    url = "https://slack.com/api/chat.postMessage"
    # Slack –ø–æ–Ω–∏–º–∞–µ—Ç mrkdwn (–Ω–µ —Å–æ–≤—Å–µ–º Markdown). –ú–æ–∂–Ω–æ —Å–ª–µ–≥–∫–∞ ¬´–æ—á–∏—Å—Ç–∏—Ç—å¬ª —Ç–µ–∫—Å—Ç:
    text_plain = sanitize_whatsapp_text(message_markdown) or ""

    headers = {
        "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
        "Content-Type": "application/json; charset=utf-8",
    }
    payload = {
        "channel": SLACK_CHANNEL_ID,
        "text": text_plain,
        "mrkdwn": True,
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        if not data.get("ok"):
            logging.warning(f"Slack chat.postMessage error: {data}")
            return False
        logging.info("Slack text message sent successfully")
        return True
    except Exception as ex:
        logging.warning(f"Slack text send failed: {ex}")
        return False


def send_slack_message_with_image_from_jellyfin(photo_id: str, caption_markdown: str) -> bool:
    """
    Slack: –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ –Ω–æ–≤–æ–º—É –ø–æ—Ç–æ–∫—É:
      1) files.getUploadURLExternal (–ø–æ–ª—É—á–∞–µ–º upload_url –∏ file_id)
      2) POST –±–∞–π—Ç–æ–≤ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞ upload_url
      3) files.completeUploadExternal (channel_id + initial_comment)
    –§–æ–ª–ª–±—ç–∫: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ chat.postMessage.
    """
    if not (SLACK_BOT_TOKEN and SLACK_CHANNEL_ID):
        logging.debug("Slack disabled/misconfigured; skip.")
        return False

    # 1) –¥–æ—Å—Ç–∞—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ Jellyfin
    img_bytes = None
    filename = "poster.jpg"
    mimetype = "image/jpeg"
    try:
        if "_fetch_jellyfin_primary" in globals():
            b, mt, fn = _fetch_jellyfin_primary(photo_id)
            img_bytes, mimetype, filename = b, mt, fn
        else:
            jf_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
            r = requests.get(jf_url, timeout=30)
            r.raise_for_status()
            img_bytes = r.content
            ct = r.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
            if "png" in ct:
                filename, mimetype = "poster.png", "image/png"
            elif "webp" in ct:
                filename, mimetype = "poster.webp", "image/webp"
    except Exception as ex:
        logging.warning(f"Slack: failed to fetch image from Jellyfin: {ex}")

    if not img_bytes:
        # –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º —Ç–µ–∫—Å—Ç
        return send_slack_text_only(caption_markdown)

    # 2) files.getUploadURLExternal
    auth_h = {"Authorization": f"Bearer {SLACK_BOT_TOKEN}"}
    try:
        resp = requests.post(
            "https://slack.com/api/files.getUploadURLExternal",
            headers=auth_h,
            data={"filename": filename, "length": str(len(img_bytes))},
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        if not data.get("ok"):
            logging.warning(f"Slack getUploadURLExternal error: {data}")
            return send_slack_text_only(caption_markdown)
        upload_url = data["upload_url"]
        file_id    = data["file_id"]
    except Exception as ex:
        logging.warning(f"Slack getUploadURLExternal failed: {ex}")
        return send_slack_text_only(caption_markdown)

    # 3) POST —Ñ–∞–π–ª–∞ –Ω–∞ upload_url
    try:
        # –º–æ–∂–Ω–æ —Å—ã—Ä—ã–º–∏ –±–∞–π—Ç–∞–º–∏:
        up_headers = {"Content-Type": mimetype}
        up = requests.post(upload_url, data=img_bytes, headers=up_headers, timeout=60)
        # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ: multipart (–∏–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ –ø—Ä–æ–∫—Å–∏):
        # up = requests.post(upload_url, files={"filename": (filename, img_bytes, mimetype)}, timeout=60)
        if up.status_code != 200:
            logging.warning(f"Slack upload_url returned {up.status_code}: {up.text[:200]}")
            return send_slack_text_only(caption_markdown)
    except Exception as ex:
        logging.warning(f"Slack raw upload failed: {ex}")
        return send_slack_text_only(caption_markdown)

    # 4) files.completeUploadExternal (—à–∞—Ä–∏–º —Ñ–∞–π–ª –≤ –∫–∞–Ω–∞–ª + –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π)
    def _complete_upload():
        comp_payload = {
            "files": [{"id": file_id, "title": filename}],
            "channel_id": SLACK_CHANNEL_ID,
            "initial_comment": sanitize_whatsapp_text(caption_markdown) or "",
        }
        return requests.post(
            "https://slack.com/api/files.completeUploadExternal",
            headers={**auth_h, "Content-Type": "application/json; charset=utf-8"},
            json=comp_payload,
            timeout=30,
        )

    # –ø–æ–ø—ã—Ç–∫–∞ –∑–∞—Ä–∞–Ω–µ–µ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è (–Ω–∞ —Å–ª—É—á–∞–π –ø—É–±–ª–∏—á–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞)
    _slack_try_join_channel(SLACK_CHANNEL_ID)

    try:
        comp = _complete_upload()
        comp.raise_for_status()
        comp_data = comp.json()
        if not comp_data.get("ok"):
            if comp_data.get("error") == "not_in_channel":
                # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑
                if _slack_try_join_channel(SLACK_CHANNEL_ID):
                    comp = _complete_upload()
                    comp.raise_for_status()
                    comp_data = comp.json()
                    if comp_data.get("ok"):
                        logging.info("Slack image sent successfully (after join).")
                        return True
                logging.warning("Slack: bot is not in the channel. Invite the app (/invite @Bot) and retry.")
            else:
                logging.warning(f"Slack completeUploadExternal error: {comp_data}")
            return send_slack_text_only(caption_markdown)

        logging.info("Slack image (external upload flow) sent successfully")
        return True

    except Exception as ex:
        logging.warning(f"Slack completeUploadExternal failed: {ex}")
        return send_slack_text_only(caption_markdown)

def send_notification(photo_id, caption):
    uploaded_url = get_jellyfin_image_and_upload_imgbb(photo_id)
    """
    1. –í—Å–µ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Telegram –Ω–∞–ø—Ä—è–º—É—é (send_telegram_photo).
    2. –ù–µ–∑–∞–≤–∏—Å–∏–º–æ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ Gotify (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω).
    3. –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã ‚Äî —á–µ—Ä–µ–∑ Apprise.
    """
    # –¢–µ–∫—Å—Ç –±–µ–∑ Markdown (–ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è plain-—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞, –≤ —Ç.—á. WhatsApp)
    caption_plain = clean_markdown_for_apprise(caption)
    if TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID:
        tg_response = send_telegram_photo(photo_id, caption)
        if tg_response and tg_response.ok:
            logging.info("Notification sent via Telegram")
        else:
            # –§–û–õ–ë–≠–ö: —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –¥–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (—Ñ–æ—Ç–æ -> —Ç–µ–∫—Å—Ç)
            logging.warning("Telegram (photo+caption) failed; trying split: photo-only then text‚Ä¶")
            ok_photo = send_telegram_photo_only(photo_id)
            ok_text  = send_telegram_text(caption)
            if ok_photo and ok_text:
                logging.info("Telegram split (photo then text) sent successfully")
            else:
                logging.warning("Telegram split fallback failed")
#    tg_GOTIFY = send_gotify_message(photo_id, caption)

    # Gotify: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞–Ω—ã
#    gotify_message = clean_markdown_for_apprise(caption)
#    gotify_response = None
    if GOTIFY_URL and GOTIFY_TOKEN:
        gotify_response = send_gotify_message(photo_id, caption, uploaded_url=uploaded_url)
        if gotify_response and gotify_response.ok:
            logging.info("Notification sent via Gotify")
        else:
            logging.warning("Notification failed via Gotify")

    # ======= –î–û–ë–ê–í–õ–ï–ù–û –î–õ–Ø DISCORD =======
    if DISCORD_WEBHOOK_URL:
        discord_response = send_discord_message(photo_id, caption, uploaded_url=uploaded_url)
        if discord_response and discord_response.ok:
            logging.info("Notification sent via Discord")
        else:
            logging.warning("Notification failed via Discord")
    # =====================================
    # ======= SLACK: —Ñ–∞–π–ª-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º =======
    try:
        if SLACK_BOT_TOKEN and SLACK_CHANNEL_ID:
            ok = send_slack_message_with_image_from_jellyfin(photo_id, caption)
            if ok:
                logging.info("Notification sent via Slack")
            else:
                logging.warning("Notification failed via Slack")
        else:
            logging.debug("Slack disabled or not configured; skip.")
    except Exception as sl_ex:
        logging.warning(f"Slack send failed: {sl_ex}")
    # ======================================================
#–û—Ç–ø—Ä–∞–∫–∞ –≤ reddit
    try:
        if REDDIT_ENABLED:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ = ¬´—à–∞–ø–∫–∞¬ª (–ø–µ—Ä–≤–∞—è –∂–∏—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞), —Ç–µ–ª–æ = caption –ë–ï–ó ¬´—à–∞–ø–∫–∏¬ª
            post_title, body_md = _split_caption_for_reddit(caption or "")
            external_url = uploaded_url or None  # –ø—Ä—è–º–æ–π URL –Ω–∞ –ø–æ—Å—Ç–µ—Ä (–µ—Å–ª–∏ –µ—Å—Ç—å)

            if REDDIT_SPLIT_TO_COMMENT and external_url:
                # –†–µ–∂–∏–º 1: –ø–æ—Å—Ç-—Å—Å—ã–ª–∫–∞ (–∫–∞—Ä—Ç–∏–Ω–∫–∞), –æ–ø–∏—Å–∞–Ω–∏–µ ‚Äî –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º
                send_reddit_link_post_with_comment(
                    title=post_title,
                    url=external_url,
                    body_markdown=body_md
                )
            else:
                # –†–µ–∂–∏–º 0: –æ–±—ã—á–Ω—ã–π self-post; –µ—Å–ª–∏ –µ—Å—Ç—å URL ‚Äî –ø–æ—Å—Ç–∞–≤–∏–º –µ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π –≤ —Å–∞–º–æ–º –ø–æ—Å—Ç–µ
                send_reddit_post(
                    title=post_title,
                    body_markdown=body_md,
                    external_image_url=external_url  # –º–æ–∂–µ—Ç –±—ã—Ç—å None ‚Äî —Ç–æ–≥–¥–∞ –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç
                )
    except Exception as ex:
        logging.warning(f"Reddit wrapper failed: {ex}")
#–æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ jellyfin
    try:
        if JELLYFIN_INAPP_ENABLED:
            # –î–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤ Jellyfin –ª—É—á—à–µ plain text –±–µ–∑ Markdown
            jf_header, jf_text = make_jf_inapp_payload_from_caption(caption or "")
            send_jellyfin_inapp_message(
                message=jf_text,
                title=jf_header
            )
    except Exception as ex:
        logging.warning(f"Jellyfin in-app notify failed: {ex}")
#–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ home assistant
    try:
        if HA_BASE_URL and HA_TOKEN:
            _title = "Jellyfin"
            # –ú–æ–∂–Ω–æ –∫—Ä–∞—Å–∏–≤–æ –≤—ã—Ç–∞—â–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –ø–µ—Ä–≤–æ–π –∂–∏—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–∏, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ:
            # m = re.match(r"\*\s*(.+?)\s*\*", caption); _title = (m.group(1)[:120] if m else _title)

            # uploaded_url ‚Äî —ç—Ç–æ –≤–∞—à URL –ø–æ—Å—Ç–µ—Ä–∞ (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
            send_homeassistant_message(
                message=caption,
                title=_title,
                service_path=None,  # –±–µ—Ä—ë—Ç—Å—è –∏–∑ HA_DEFAULT_SERVICE
                notification_id="jellyfin",  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è persistent_notification
                image_url=uploaded_url  # <-- –≤–æ—Ç —Ç—É—Ç –ø–µ—Ä–µ–¥–∞—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É
            )
    except Exception as ex:
        logging.warning(f"Home Assistant notify wrapper failed: {ex}")
#–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ pushover
    try:
        if PUSHOVER_USER_KEY and PUSHOVER_TOKEN:
            _title = "Jellyfin"
            # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –≤—ã—Ç–∞—â–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –ø–µ—Ä–≤–æ–π –∂–∏—Ä–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
            img_bytes = _safe_fetch_jellyfin_image_bytes(photo_id)  # <‚Äî –Ω–∞–ø—Ä—è–º—É—é –∏–∑ Jellyfin
            # uploaded_url ‚Äî –≤–∞—à —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–π URL –ø–æ—Å—Ç–µ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            html_msg = markdown_to_pushover_html(caption or "")
            send_pushover_message(
                message=html_msg,
                title=_title,
                image_bytes=img_bytes,  # <‚Äî –ø–µ—Ä–µ–¥–∞—ë–º –±–∞–π—Ç—ã, –Ω–∏–∫–∞–∫–∏—Ö i.ibb.co
                sound=(PUSHOVER_SOUND or None),
                priority=PUSHOVER_PRIORITY,
                device=(PUSHOVER_DEVICE or None),
                html=True
            )
    except Exception as ex:
        logging.warning(f"Pushover wrapper failed: {ex}")
    # ======= MATRIX (REST): –°–ù–ê–ß–ê–õ–ê –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç =======
    try:
        if MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID:
            ok = send_matrix_image_then_text_from_jellyfin(photo_id, caption)
            if ok:
                logging.info("Notification sent via Matrix (REST, image from Jellyfin then text)")
            else:
                logging.warning("Matrix (REST, Jellyfin): image+text flow failed; trying text-only fallback")
                send_matrix_text_rest(caption)
        else:
            logging.debug("Matrix disabled or not configured; skip.")
    except Exception as m_ex:
        logging.warning(f"Matrix send failed: {m_ex}")
    # ========================================================================
    # --- –û–¢–ü–†–ê–í–ö–ê –í SIGNAL ---
    # Plain text –¥–ª—è Signal (–±–µ–∑ Markdown)
    if SIGNAL_URL and SIGNAL_NUMBER:
        signal_resp = send_signal_message_with_image(
            photo_id,
            clean_markdown_for_apprise(caption),
            SIGNAL_NUMBER,
            SIGNAL_RECIPIENTS
        )
        if signal_resp and signal_resp.ok:
            logging.info("Notification sent via Signal")
        else:
            logging.warning("Notification failed via Signal")
    # --------------------------
    # ======= Synology Chat =======
    try:
        if SYNOCHAT_ENABLED and SYNOCHAT_WEBHOOK_URL:
            # plain-—Ç–µ–∫—Å—Ç (Chat –Ω–µ —Ä–µ–Ω–¥–µ—Ä–∏—Ç Markdown –∫–∞–∫ Telegram)
            caption_plain = clean_markdown_for_apprise(caption or "")
            file_url = uploaded_url if (SYNOCHAT_INCLUDE_POSTER and uploaded_url) else None
            send_synology_chat_message(caption_plain, file_url=file_url)
    except Exception as ex:
        logging.warning(f"Synology Chat wrapper failed: {ex}")
    # =============================

    # ======= EMAIL: –ø–∏—Å—å–º–æ —Å inline-–∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∏–∑ Jellyfin =======
    try:
        email_ok = send_email_with_image_jellyfin(photo_id, subject=SMTP_SUBJECT, body_markdown=caption)
        if email_ok:
            logging.info("Notification sent via Email")
        else:
            logging.warning("Notification failed via Email")
    except Exception as em_ex:
        logging.warning(f"Email send failed: {em_ex}")

    # ======= WHATSAPP: —Å–Ω–∞—á–∞–ª–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∞ —Å –ø–æ–¥–ø–∏—Å—å—é (—Å —Ä–µ—Ç—Ä–∞—è–º–∏), –ø—Ä–∏ –ø—Ä–æ–≤–∞–ª–µ ‚Äî —Ç–µ–∫—Å—Ç =======
    try:
        wa_jid = _wa_get_jid_from_env()
        if WHATSAPP_API_URL and wa_jid:
            ok_img = send_whatsapp_image_with_retries(
                caption=caption,
                phone_jid=wa_jid,
                image_url=uploaded_url
            )
            if not ok_img:
                logging.warning("WhatsApp image failed after retries; sending text-only fallback")
                send_whatsapp_text_via_rest(caption, phone_jid=wa_jid)
        else:
            logging.debug("WhatsApp disabled or no JID; skip WhatsApp send.")
    except Exception as wa_ex:
        logging.warning(f"WhatsApp send block failed: {wa_ex}")

#    other_services = [url for url in APPRISE_URLS.split() if url]  # —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
#    if other_services:
#        apprise_obj = Apprise()
#        for url in other_services:
#            apprise_obj.add(url)

        # –ì–æ—Ç–æ–≤–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ (–µ—Å–ª–∏ —Ñ–æ—Ç–æ –µ—Å—Ç—å)

#    base_photo_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
#    attach_param = None
#    try:
#        image_response = requests.get(base_photo_url, timeout=10)
#        if image_response.ok:
#            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
#            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
#                tmp.write(image_response.content)
#                tmp_path = tmp.name
#            attach_param = tmp_path
#        else:
#            attach_param = None
#    except Exception as ex:
#        logging.warning(f"Cannot download image: {ex}")
#        attach_param = None

#    caption_plain = clean_markdown_for_apprise(caption)
#    result = apobj.notify(
#        body=caption_plain,
#        title="",
#        attach=attach_param
#    )

#    if attach_param and os.path.exists(attach_param):
#        try:
#            os.remove(attach_param)
#        except Exception as ex:
#            logging.warning(f"Cannot remove temp image: {ex}")

#    if result:
#        logging.info("Notification sent via Apprise")
#    else:
#        logging.warning("Notification failed via Apprise")
#    return None
def _fetch_jellyfin_image_with_retries(photo_id: str, attempts: int = 3, timeout: int = 10, delay: float = 1.5):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å Primary-–ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes –∏–ª–∏ None.
    """
    url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    last_err = None
    for i in range(1, attempts + 1):
        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ)
            head = requests.head(url, timeout=timeout)
            if head.ok:
                resp = requests.get(url, timeout=timeout)
                resp.raise_for_status()
                return resp.content
            else:
                last_err = f"HTTP {head.status_code}"
        except Exception as ex:
            last_err = ex
        logging.warning(f"Jellyfin image try {i}/{attempts} failed: {last_err}")
        if i < attempts:
            time.sleep(delay)
    return None

def send_telegram_photo(photo_id, caption):
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º caption –¥–æ 1024 —Å–∏–º–≤–æ–ª–æ–≤
    #    if caption and len(caption) > 1024:
    #        caption = caption[:1023] + "..."  # –¥–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–æ–µ—Ç–æ—á–∏–µ, –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∞–µ–º

#        base_photo_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images"
#        primary_photo_url = f"{base_photo_url}/Primary"

        # Download the image from the jellyfin
#        image_response = requests.get(primary_photo_url)

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏
        image_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        if not image_bytes:
            logging.warning("Telegram: Jellyfin image unavailable after retries")
            return None

        # Upload the image to the Telegram bot
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
        data = {
            "chat_id": TELEGRAM_CHAT_ID,
            "caption": caption,
            "parse_mode": "Markdown"
        }

        files = {'photo': ('photo.jpg', image_bytes, 'image/jpeg')}
        response = requests.post(url, data=data, files=files, timeout=30)
        logging.info("Telegram notification sent successfully")
        return response

    except Exception as ex:
        logging.warning(f"Error sending to Telegram: {ex}")
        return None

def send_telegram_photo_only(photo_id):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ñ–æ—Ç–æ (–±–µ–∑ caption) –≤ Telegram.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    try:
        image_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        if not image_bytes:
            logging.warning("Telegram(photo-only): Jellyfin image unavailable after retries")
            return None

        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
        data = {"chat_id": TELEGRAM_CHAT_ID}
        files = {'photo': ('photo.jpg', image_bytes, 'image/jpeg')}
        resp = requests.post(url, data=data, files=files, timeout=30)
        resp.raise_for_status()
        logging.info("Telegram photo-only sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Telegram photo-only failed: {ex}")
        return None


def send_telegram_text(message: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤ Telegram.
    –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Markdown, –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–∞–¥–∞–µ–º –≤ plain-text (–æ—á–∏—â–µ–Ω–Ω—ã–π).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    if not (TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID):
        return None

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ1: Markdown
        resp = requests.post(url, data={
            "chat_id": TELEGRAM_CHAT_ID,
            "text": message,
            "parse_mode": "Markdown"
        }, timeout=30)
        if resp.ok:
            logging.info("Telegram text sent (Markdown)")
            return resp

        # –ï—Å–ª–∏ –Ω–µ ok ‚Äî –ø—Ä–æ–±—É–µ–º plain
        logging.warning(f"Telegram text markdown failed: {resp.status_code} {resp.text}")
        raise HTTPError(response=resp)

    except Exception as md_ex:
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ2: plain (–æ—á–∏—â–∞–µ–º markdown, —Å—Å—ã–ª–∫–∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–æ—Å—Ç–æ–º—É –≤–∏–¥—É)
            plain = clean_markdown_for_apprise(message) or message
            resp2 = requests.post(url, data={
                "chat_id": TELEGRAM_CHAT_ID,
                "text": plain
            }, timeout=30)
            resp2.raise_for_status()
            logging.info("Telegram text sent (plain fallback)")
            return resp2
        except Exception as ex2:
            logging.warning(f"Telegram text send failed: {ex2}")
            return None

def send_matrix_text_rest(message_markdown: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤ Matrix —á–µ—Ä–µ–∑ REST (v3).
    1) –ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π PUT –ø–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏.
    2) –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç PUT (405) ‚Äî –¥–µ–ª–∞–µ—Ç POST —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ —Ç–æ—Ç –∂–µ –ø—É—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID):
        logging.debug("Matrix not configured; skip.")
        return None

    try:
        # room_id –≤–∏–¥–∞ "!MNddurK...:example.org" –Ω—É–∂–Ω–æ URL-—ç–Ω–∫–æ–¥–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é
        room_enc = quote(MATRIX_ROOM_ID, safe="")
        base = f"{MATRIX_URL.rstrip('/')}/_matrix/client/v3/rooms/{room_enc}/send/m.room.message"

        headers = {
            "Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}",
            "Content-Type": "application/json",
        }

        # –ß–∏—Å—Ç–∏–º Markdown –¥–ª—è plain-—Ç–µ–∫—Å—Ç–∞ (Matrix –∫–ª–∏–µ–Ω—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–æ–∫–∞–∂—É—Ç)
        body_plain = clean_markdown_for_apprise(message_markdown) or ""
        payload = {"msgtype": "m.text", "body": body_plain}

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π txnId (–≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö)
        txn_id = f"{int(time.time() * 1000)}txt"
        url = f"{base}/{txn_id}"

        # 1) –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å: PUT (—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è)
        try:
            resp = requests.put(url, headers=headers, json=payload, timeout=30)
            resp.raise_for_status()
            logging.info("Matrix text sent successfully via PUT v3")
            return resp
        except requests.exceptions.HTTPError as e:
            status = getattr(e.response, "status_code", None)
            if status == 405:
                # 2) –§–æ–ª–ª–±—ç–∫: POST —Ç–µ–º –∂–µ —É—Ä–ª–æ–º (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ reverse-proxy —Ä–µ–∂—É—Ç PUT)
                logging.warning("Matrix PUT blocked (405). Trying POST fallback‚Ä¶")
                resp2 = requests.post(url, headers=headers, json=payload, timeout=30)
                resp2.raise_for_status()
                logging.info("Matrix text sent successfully via POST fallback")
                return resp2
            else:
                logging.warning(f"Matrix text send failed via PUT: {e}")
                return None

    except Exception as ex:
        logging.warning(f"Matrix text send failed: {ex}")
        return None

def matrix_upload_image_rest(image_bytes: bytes, filename: str, mimetype: str = "image/jpeg") -> str | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ Matrix content repo –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç mxc:// URI.
    –ü—Ä–æ–±—É–µ–º v3, –ø—Ä–∏ 404/405/501 ‚Äî —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ r0.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN):
        logging.debug("Matrix not configured for media upload; skip.")
        return None

    headers = {"Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}", "Content-Type": mimetype}
    base = MATRIX_URL.rstrip("/")
    url_v3 = f"{base}/_matrix/media/v3/upload?filename={quote(filename)}"

    try:
        r = requests.post(url_v3, headers=headers, data=image_bytes, timeout=30)
        r.raise_for_status()
        return r.json().get("content_uri")
    except requests.exceptions.HTTPError as e:
        code = getattr(e.response, "status_code", None)
        if code in (404, 405, 501):
            logging.warning(f"media/v3/upload returned {code}, trying r0‚Ä¶")
            try:
                url_r0 = f"{base}/_matrix/media/r0/upload?filename={quote(filename)}"
                r2 = requests.post(url_r0, headers=headers, data=image_bytes, timeout=30)
                r2.raise_for_status()
                return r2.json().get("content_uri")
            except Exception as ex2:
                logging.warning(f"Matrix r0 upload failed: {ex2}")
                return None
        logging.warning(f"Matrix v3 upload failed: {e}")
        return None
    except Exception as ex:
        logging.warning(f"Matrix upload failed: {ex}")
        return None


def _matrix_send_event_rest(room_id: str, event_type: str, content: dict):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –∫–æ–º–Ω–∞—Ç—É:
      PUT /_matrix/client/v3/rooms/{roomId}/send/{eventType}/{txnId}
    –ü—Ä–∏ 405 ‚Äî POST –Ω–∞ —Ç–æ—Ç –∂–µ –ø—É—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –∏–ª–∏ None.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and room_id):
        return None

    room_enc = quote(room_id, safe="")
    base = f"{MATRIX_URL.rstrip('/')}/_matrix/client/v3/rooms/{room_enc}/send/{event_type}"
    txn_id = f"{int(time.time()*1000)}evt"
    url = f"{base}/{txn_id}"
    headers = {"Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}", "Content-Type": "application/json"}

    try:
        resp = requests.put(url, headers=headers, json=content, timeout=30)
        resp.raise_for_status()
        return resp
    except requests.exceptions.HTTPError as e:
        if getattr(e.response, "status_code", None) == 405:
            logging.warning("PUT blocked (405). Trying POST fallback‚Ä¶")
            try:
                resp2 = requests.post(url, headers=headers, json=content, timeout=30)
                resp2.raise_for_status()
                return resp2
            except Exception as ex2:
                logging.warning(f"Matrix POST fallback failed: {ex2}")
                return None
        logging.warning(f"Matrix send event failed via PUT: {e}")
        return None
    except Exception as ex:
        logging.warning(f"Matrix send event failed: {ex}")
        return None

def _fetch_jellyfin_primary(photo_id: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (bytes, mimetype, filename) –¥–ª—è Primary-–ø–æ—Å—Ç–µ—Ä–∞ –∏–∑ Jellyfin.
    """
    url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    resp = requests.get(url, timeout=30)
    resp.raise_for_status()
    mimetype = resp.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
    ext = ".jpg"
    if "png" in mimetype:
        ext = ".png"
    elif "webp" in mimetype:
        ext = ".webp"
    filename = f"poster{ext}"
    return resp.content, mimetype, filename


def send_matrix_image_then_text_from_jellyfin(photo_id: str, caption_markdown: str) -> bool:
    """
    1) –¢—è–Ω–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin
    2) –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Matrix (media repo) -> mxc://
    3) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º m.image (body = –∏–º—è —Ñ–∞–π–ª–∞)
    4) –û—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç (m.text)
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID):
        logging.debug("Matrix not configured; skip.")
        return False

    # 1) –∫–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ Jellyfin
    try:
        img_bytes, mimetype, filename = _fetch_jellyfin_primary(photo_id)
    except Exception as ex:
        logging.warning(f"Matrix(JF): cannot fetch image from Jellyfin: {ex}")
        # —Ö–æ—Ç—è –±—ã —Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏–º
        resp_txt = send_matrix_text_rest(caption_markdown)
        return bool(resp_txt and resp_txt.ok)

    # 2) upload -> mxc://
    mxc_uri = matrix_upload_image_rest(img_bytes, filename, mimetype)
    if not mxc_uri:
        logging.warning("Matrix(JF): media upload failed; sending text only.")
        resp_txt = send_matrix_text_rest(caption_markdown)
        return bool(resp_txt and resp_txt.ok)

    # 3) m.image (–í–ê–ñ–ù–û: body ‚Äî –∏–º—è —Ñ–∞–π–ª–∞)
    content_img = {
        "msgtype": "m.image",
        "body": filename,
        "url": mxc_uri,
        "info": {
            "mimetype": mimetype,
            "size": len(img_bytes),
        },
    }
    resp_img = _matrix_send_event_rest(MATRIX_ROOM_ID, "m.room.message", content_img)
    img_ok = bool(resp_img and resp_img.ok)

    # 4) –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
    resp_txt = send_matrix_text_rest(caption_markdown)
    txt_ok = bool(resp_txt and resp_txt.ok)

    if img_ok and txt_ok:
        logging.info("Matrix(JF): image then text sent successfully.")
    else:
        logging.warning("Matrix(JF): image+text flow partially/fully failed.")
    return img_ok and txt_ok

def send_gotify_message(photo_id, message, title="Jellyfin", priority=5, uploaded_url=None):
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Gotify. –ï—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ –≥–æ—Ç–æ–≤–∞ ‚Äî —à–ª—ë–º —Ç–µ–∫—Å—Ç –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    if not GOTIFY_URL or not GOTIFY_TOKEN:
        logging.warning("GOTIFY_URL or GOTIFY_TOKEN not set, skipping Gotify notification.")
        return None

    # –ï—Å–ª–∏ URL –µ—â—ë –Ω–µ –∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –ø–æ–¥–æ–∂–¥—ë–º —á—É—Ç—å-—á—É—Ç—å, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º—Å—è –Ω–∞–¥–æ–ª–≥–æ.
    if uploaded_url is None:
        uploaded_url = wait_for_imgbb_upload(timeout=0.5)

    if uploaded_url:
        message = f"![Poster]({uploaded_url})\n\n{message}"
        big_image_url = uploaded_url
    else:
        big_image_url = None
        logging.debug("IMGBB URL missing ‚Äî sending Gotify text-only.")

    gotify_url = GOTIFY_URL.rstrip('/')
    url = f"{gotify_url}/message?token={GOTIFY_TOKEN}"

    data = {
        "title": title,
        "message": message,
        "priority": priority,
        "extras": {
            "client::display": {"contentType": "text/markdown"}
        }
    }
    if big_image_url:
        data["extras"]["client::notification"] = {"bigImageUrl": big_image_url}
    headers = {"X-Gotify-Format": "markdown"}

    try:
        response = requests.post(url, json=data, headers=headers)
        response.raise_for_status()
        logging.info("Gotify notification sent successfully")
        return response
    except Exception as ex:
        logging.warning(f"Error sending to Gotify: {ex}")
        return None

def send_pushover_message(message: str,
                          title: str | None = None,
                          image_url: str | None = None,
                          image_bytes: bytes | None = None,
                          *,
                          sound: str | None = None,
                          priority: int | None = None,
                          device: str | None = None,
                          html: bool = False) -> bool:
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Pushover —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏/—Ç–∞–π–º–∞—É—Ç—ã.
    - –†–µ—Ç—Ä–∞–π –ø—Ä–∏: requests.Timeout/ConnectionError, HTTP 5xx, HTTP 429.
    - –ü–∞—É–∑–∞: —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è (base * backoff^(attempt-1)).
    """
    try:
        if not (PUSHOVER_USER_KEY and PUSHOVER_TOKEN):
            return False

        endpoint = "https://api.pushover.net/1/messages.json"
        data = {
            "token":   PUSHOVER_TOKEN,
            "user":    PUSHOVER_USER_KEY,
            "message": (message or "")[:1024],
        }
        if title:
            data["title"] = title[:250]
        if device:
            data["device"] = device
        if sound:
            data["sound"] = sound
        if priority is not None:
            data["priority"] = str(priority)
            if int(priority) == 2:
                data["retry"]  = str(max(30, int(PUSHOVER_EMERGENCY_RETRY)))
                data["expire"] = str(max(1,  int(PUSHOVER_EMERGENCY_EXPIRE)))
        if html:
            data["html"] = "1"

        files = None
        # –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –±–∞–π—Ç—ã; fallback –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø–æ URL –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–º
        if image_bytes:
            files = {"attachment": ("poster.jpg", image_bytes, "image/jpeg")}
        elif image_url:
            try:
                ir = requests.get(image_url, timeout=6)
                ir.raise_for_status()
                content = ir.content
                if len(content) <= 5242880:
                    mime = ir.headers.get("Content-Type") or "image/jpeg"
                    files = {"attachment": ("poster.jpg", content, mime)}
                else:
                    logging.warning("Pushover: image > 5MB, sending without attachment.")
            except Exception as ex:
                logging.warning(f"Pushover: image fetch failed: {ex}")

        # --- –†–µ—Ç—Ä–∞–∏ –Ω–∞ –æ—Ç–ø—Ä–∞–≤–∫—É ---
        import time
        from requests.exceptions import Timeout, ConnectionError

        attempts = max(1, PUSHOVER_RETRIES)
        delay = max(0.0, PUSHOVER_RETRY_BASE_DELAY)
        for attempt in range(1, attempts + 1):
            try:
                resp = requests.post(
                    endpoint,
                    data=data,
                    files=files,
                    timeout=PUSHOVER_TIMEOUT_SEC,
                    allow_redirects=True
                )
                # —É—Å–ø–µ—Ö
                if resp.status_code == 200:
                    logging.info("Pushover notification sent")
                    return True

                # —Ä–µ—à–∞–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–≤—Ç–æ—Ä—è—Ç—å
                retryable_http = resp.status_code in (429, 500, 502, 503, 504)
                if not retryable_http or attempt == attempts:
                    logging.warning(f"Pushover failed {resp.status_code}: {resp.text[:300]}")
                    return False

                logging.warning(f"Pushover HTTP {resp.status_code}, retry {attempt}/{attempts}...")
            except (Timeout, ConnectionError) as ex:
                if attempt == attempts:
                    logging.warning(f"Pushover notify error: {ex}")
                    return False
                logging.warning(f"Pushover network error, retry {attempt}/{attempts}: {ex}")
            except Exception as ex:
                # –ø—Ä–æ—á–µ–µ ‚Äî –Ω–µ —Ä–µ—Ç—Ä–∞–∏–º
                logging.warning(f"Pushover notify error: {ex}")
                return False

            # –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
            time.sleep(delay)
            delay *= max(1.0, PUSHOVER_RETRY_BACKOFF)

        return False  # —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –¥–æ–π–¥—ë–º

    except Exception as ex:
        logging.warning(f"Pushover notify error: {ex}")
        return False


def _safe_fetch_jellyfin_image_bytes(item_id: str) -> bytes | None:
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –ø–æ—Å—Ç–µ—Ä –Ω–∞–ø—Ä—è–º—É—é –∏–∑ Jellyfin, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes –ª–∏–±–æ None.
    """
    try:
        url = f"{JELLYFIN_BASE_URL}/Items/{item_id}/Images/Primary"
        # –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–ª—é—á –≤ query, —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É:
        # url = f"{url}?api_key={JELLYFIN_API_KEY}"
        r = requests.get(url, timeout=6)
        r.raise_for_status()
        return r.content
    except Exception as ex:
        logging.debug(f"Pushover: Jellyfin image fetch failed for {item_id}: {ex}")
        return None



def send_homeassistant_message(message: str,
                               title: str | None = None,
                               service_path: str | None = None,
                               notification_id: str | None = None,
                               image_url: str | None = None) -> bool:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–µ—Ä–≤–∏—Å–∞ Home Assistant.
    –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è persistent_notification/create.
    - –î–ª—è persistent_notification: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è message, title, notification_id.
      –ö–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è ‚Äî –º–æ–∂–µ–º (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –¥–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫—É –≤ —Ç–µ–∫—Å—Ç.
    - –î–ª—è –ø—Ä–æ—á–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ —É–º–µ—é—Ç –ø–æ–ª–µ 'image', –ø–µ—Ä–µ–¥–∞–¥–∏–º –µ–≥–æ –≤ 'data.image'.
    """
    try:
        if not HA_BASE_URL or not HA_TOKEN:
            return False

        service_path = (service_path or HA_DEFAULT_SERVICE).strip().strip("/")
        domain, _, service = service_path.partition("/")
        if not domain or not service:
            logging.warning(f"Home Assistant: invalid service_path '{service_path}'")
            return False

        url = f"{HA_BASE_URL}/api/services/{domain}/{service}"
        headers = {
            "Authorization": f"Bearer {HA_TOKEN}",
            "Content-Type": "application/json",
        }

        # –ë–∞–∑–æ–≤—ã–π payload
        final_message = message

        # –ï—Å–ª–∏ —ç—Ç–æ persistent_notification ‚Äî –¥–æ–±–∞–≤–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
        if domain == "persistent_notification" and image_url and HA_PN_IMAGE_LINK:
            final_message = f"{message}\n\n{HA_PN_IMAGE_LABEL}: {image_url}"

        payload = {"message": final_message}
        if title:
            payload["title"] = title
        if domain == "persistent_notification" and notification_id:
            payload["notification_id"] = notification_id

        # –î–ª—è –¥—Ä—É–≥–∏—Ö –¥–æ–º–µ–Ω–æ–≤ –ø–æ–ø—Ä–æ–±—É–µ–º –≤–ª–æ–∂–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º –æ–±—Ä–∞–∑–æ–º
        if domain != "persistent_notification" and image_url:
            payload["data"] = {"image": image_url}

        resp = requests.post(url, headers=headers, json=payload, timeout=8, verify=HA_VERIFY_SSL)
        if resp.status_code != 200:
            logging.warning(f"Home Assistant notify failed {resp.status_code}: {resp.text[:300]}")
            return False

        logging.info(f"Home Assistant notification sent via {domain}/{service}")
        return True

    except Exception as ex:
        logging.warning(f"Home Assistant notify error: {ex}")
        return False

def send_signal_message_with_image(photo_id, message, SIGNAL_NUMBER, SIGNAL_RECIPIENTS, api_url=SIGNAL_URL):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin –≤ Signal —á–µ—Ä–µ–∑ base64_attachments.
    """
    # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    try:
        image_resp = requests.get(jellyfin_image_url)
        image_resp.raise_for_status()
        image_bytes = image_resp.content
        # –ö–æ–¥–∏—Ä—É–µ–º –≤ base64
        image_b64 = base64.b64encode(image_bytes).decode("utf-8")

        data = {
            "message": message,
            "number": SIGNAL_NUMBER,
            "recipients": SIGNAL_RECIPIENTS if isinstance(SIGNAL_RECIPIENTS, list) else [SIGNAL_RECIPIENTS],
            "base64_attachments": [image_b64],
        }

        resp = requests.post(api_url, json=data)
        resp.raise_for_status()
        logging.info("Signal image message sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Error sending Signal image message: {ex}")
        return None


def send_whatsapp_image_via_rest(
    caption: str,
    phone_jid: str = None,
    image_url: str = None,
    view_once: bool = False,
    compress: bool = False,
    duration: int = 0,
    is_forwarded: bool = False,
):
    img_url = wait_for_imgbb_upload()
    if not img_url:
        logging.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –≤ WhatsApp.")
        return
    if not WHATSAPP_API_URL:
        logging.warning("WHATSAPP_API_URL not set, skipping WhatsApp image.")
        return None

    phone_jid = phone_jid or _wa_get_jid_from_env()
    if not phone_jid:
        logging.warning("WhatsApp JID is empty, skip sending image.")
        return None

    url = f"{WHATSAPP_API_URL.rstrip('/')}/send/image"
    auth = (WHATSAPP_API_USERNAME, WHATSAPP_API_PWD)

    form = {
        "phone": phone_jid,
        "caption": sanitize_whatsapp_text(caption or ""),
        "view_once": str(bool(view_once)).lower(),
        "compress": str(bool(compress)).lower(),
        "duration": str(int(duration)),
        "is_forwarded": str(bool(is_forwarded)).lower(),
    }

    files = None
    jellyfin_used = False

    if image_url:
        form["image_url"] = image_url
    else:
        logging.warning("WhatsApp image: image_url –Ω–µ –∑–∞–¥–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return None

    try:
        resp = requests.post(url, data=form, files=files, auth=auth, timeout=30)
        resp.raise_for_status()
        logging.info("WhatsApp image sent successfully")
        return resp
    except requests.exceptions.RequestException as e:
        logging.warning(f"Error sending WhatsApp image: {e}")
        return None

def send_whatsapp_text_via_rest(message: str, phone_jid: str | None = None):
    """
    –®–ª—ë—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç. –°–Ω–∞—á–∞–ª–∞ /send/text, –ø—Ä–∏ 404 ‚Äî /send/message.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –∏–ª–∏ None.
    """
    if not WHATSAPP_API_URL:
        logging.debug("WhatsApp API URL not set; skip text.")
        return None

    phone_jid = phone_jid or _wa_get_jid_from_env()
    if not phone_jid:
        logging.debug("WhatsApp JID empty; skip text.")
        return None

    base = WHATSAPP_API_URL.rstrip("/")
    url_text = f"{base}/send/text"
    url_msg  = f"{base}/send/message"
    auth = (WHATSAPP_API_USERNAME, WHATSAPP_API_PWD) if (WHATSAPP_API_USERNAME or WHATSAPP_API_PWD) else None

    form = {
        "phone": phone_jid,
        "message": sanitize_whatsapp_text(message or "")
    }

    try:
        r = requests.post(url_text, data=form, auth=auth, timeout=20)
        if r.status_code == 404:
            r = requests.post(url_msg, data=form, auth=auth, timeout=20)
        r.raise_for_status()
        logging.info("WhatsApp text sent successfully")
        return r
    except Exception as ex:
        logging.warning(f"WhatsApp text send failed: {ex}")
        return None

def send_whatsapp_image_with_retries(
    caption: str,
    phone_jid: str | None,
    image_url: str | None = None
) -> bool:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–¥–ø–∏—Å—å—é –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑.
    True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –µ—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å.
    """
    attempts = max(1, WHATSAPP_IMAGE_RETRY_ATTEMPTS)
    delay = max(0, WHATSAPP_IMAGE_RETRY_DELAY_SEC)

    for i in range(1, attempts + 1):
        try:
            resp = send_whatsapp_image_via_rest(
                caption=caption,
                phone_jid=phone_jid,
                image_url=image_url
            )
            ok = (resp is not None) and (getattr(resp, "ok", True))
            if ok:
                logging.info(f"WhatsApp image sent on attempt {i}")
                return True
            else:
                logging.warning(f"WhatsApp image attempt {i} failed (no/negative response)")
        except Exception as ex:
            logging.warning(f"WhatsApp image attempt {i} exception: {ex}")
        if i < attempts:
            time.sleep(delay)
    return False


def get_item_details(item_id):
    headers = {'accept': 'application/json', }
    params = {'api_key': JELLYFIN_API_KEY, }
    url = f"{JELLYFIN_BASE_URL}/emby/Items?Recursive=true&Fields=DateCreated, Overview&Ids={item_id}"
    response = requests.get(url, headers=headers, params=params)
    response.raise_for_status()  # Check if request was successful
    return response.json()

def jellyfin_count_tracks_in_album(album_id: str) -> int | None:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Å–µ–Ω –≤ –º—É–∑—ã–∫–∞–ª—å–Ω–æ–º –∞–ª—å–±–æ–º–µ.
    –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –≤–∑—è—Ç—å ChildCount —É —Å–∞–º–æ–≥–æ –∞–ª—å–±–æ–º–∞; –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å—á–∏—Ç–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ Audio-—ç–ª–µ–º–µ–Ω—Ç—ã.
    """
    try:
        # 1) –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–∞–º –∞–ª—å–±–æ–º —Å ChildCount
        params = {'api_key': JELLYFIN_API_KEY, 'Ids': album_id, 'Fields': 'ChildCount'}
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        items = (r.json() or {}).get('Items') or []
        if items:
            cc = items[0].get('ChildCount')
            if isinstance(cc, int) and cc >= 0:
                return cc

        # 2) –§–æ–ª–±—ç–∫: —Å—á–∏—Ç–∞–µ–º –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã-–∞—É–¥–∏–æ—Ç—Ä–µ–∫–∏
        params = {
            'api_key': JELLYFIN_API_KEY,
            'ParentId': album_id,
            'IncludeItemTypes': 'Audio',
            'Recursive': 'false',
            'IsMissing': 'false',
            'LocationTypes': 'FileSystem',
            'Fields': 'LocationType,Path',
        }
        r = requests.get(url, params=params, timeout=12)
        r.raise_for_status()
        return len((r.json() or {}).get('Items') or [])
    except Exception as ex:
        logging.warning(f"Album track count failed for {album_id}: {ex}")
        return None

def jellyfin_list_tracks_in_album(album_id: str, *, limit: int | None = None) -> list[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–æ–ª—è) –¥–ª—è –∞–ª—å–±–æ–º–∞.
    –ü–æ–ª—è: Name, IndexNumber, RunTimeTicks
    """
    try:
        params = {
            'api_key': JELLYFIN_API_KEY,
            'ParentId': album_id,
            'IncludeItemTypes': 'Audio',
            'Recursive': 'false',
            'IsMissing': 'false',
            'LocationTypes': 'FileSystem',
            'SortBy': 'IndexNumber,Name',
            'SortOrder': 'Ascending',
            'Fields': 'IndexNumber,RunTimeTicks'
        }
        if limit and limit > 0:
            params['Limit'] = str(limit)
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=12)
        r.raise_for_status()
        return (r.json() or {}).get('Items') or []
    except Exception as ex:
        logging.warning(f"Album track list failed for {album_id}: {ex}")
        return []


def is_within_last_x_days(date_str, x):
    days_ago = datetime.now() - timedelta(days=x)
    return date_str >= days_ago.isoformat()


def is_not_within_last_x_days(date_str, x):
    days_ago = datetime.now() - timedelta(days=x)
    return date_str < days_ago.isoformat()


def get_youtube_trailer_url(query):
    base_search_url = "https://www.googleapis.com/youtube/v3/search"
    if not YOUTUBE_API_KEY:
        return None
    api_key = YOUTUBE_API_KEY

    params = {
        'part': 'snippet',
        'q': query,
        'type': 'video',
        'key': api_key
    }

    response = requests.get(base_search_url, params=params)
    response.raise_for_status()  # Check for HTTP errors before processing the data
    response_data = response.json()
    video_id = response_data.get("items", [{}])[0].get('id', {}).get('videoId')

    return f"https://www.youtube.com/watch?v={video_id}" if video_id else "Video not found!"


def item_already_notified(item_type, item_name, release_year):
    # –í —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –≤—Å–µ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –µ—â—ë –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏
    if DISABLE_DEDUP:
        logging.debug("Dedup is disabled: treating as NOT notified.")
        return False

    key = f"{item_type}:{item_name}:{release_year}"
    return notified_items.get(key) is True


def mark_item_as_notified(item_type, item_name, release_year, max_items=100):
    # –í —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∏—à–µ–º –≤ —Ñ–∞–π–ª
    if DISABLE_DEDUP:
        logging.debug("Dedup is disabled: NOT recording notified key.")
        return

    key = f"{item_type}:{item_name}:{release_year}"
    notified_items[key] = True

    # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä ¬´–ø–∞–º—è—Ç–∏¬ª
    if len(notified_items) > max_items:
        # –µ—Å–ª–∏ —É–∂–µ —Ö—Ä–∞–Ω–∏—Ç–µ timestamp ‚Äî —É–¥–∞–ª—è–π—Ç–µ —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π; –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ pop –ø–µ—Ä–≤–æ–≥–æ
        notified_items.pop(next(iter(notified_items)))
    save_notified_items(notified_items)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –≤–∏–¥–µ–æ

def _get_item_media_info_movie(item_id: str) -> dict:
    """
    –¢—è–Ω–µ–º MediaSources/MediaStreams –¥–ª—è —Ñ–∏–ª—å–º–∞ –∏ —É–ø–ª–æ—â–∞–µ–º –≤ dict.
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º:
      - —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫: audio_tracks + –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
      - –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: image_profiles (['DV','HDR10',...]) –∏ image_profile_str ("DV, HDR10")
    """
    try:
        headers = {'accept': 'application/json'}
        params = {'api_key': JELLYFIN_API_KEY}
        url = f"{JELLYFIN_BASE_URL}/emby/Items?Ids={item_id}&Fields=MediaSources,RunTimeTicks"
        r = requests.get(url, headers=headers, params=params, timeout=12)
        r.raise_for_status()
        data = r.json()
        item = (data.get("Items") or [{}])[0]
        sources = item.get("MediaSources") or []
        if not sources:
            return {}
        src = sources[0]

        container = src.get("Container")
        overall_bitrate = src.get("Bitrate")
        size_bytes = src.get("Size")
        duration_ticks = src.get("RunTimeTicks") or item.get("RunTimeTicks")
        duration_sec = duration_ticks / 10_000_000 if duration_ticks else None

        vcodec = None; vbitrate = None; width = None; height = None; dyn = None; vdepth = None; fps = None
        acodec = None; abitrate = None; channels = None

        audio_tracks = []
        image_profiles = None  # NEW

        for s in (src.get("MediaStreams") or []):
            stype = s.get("Type")
            if stype == "Video" and vcodec is None:
                # ... –≤–∞—à –∫–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π ...
                try:
                    image_profiles = _detect_image_profiles_from_fields(s)
                except Exception:
                    image_profiles = None
                # >>> –§–û–õ–ë–≠–ö
                if not image_profiles:
                    image_profiles = ["SDR"]
                # <<<
                vcodec = s.get("Codec")
                vbitrate = s.get("BitRate") or s.get("bitrate") or overall_bitrate
                width = s.get("Width"); height = s.get("Height")
                fps = s.get("AverageFrameRate") or s.get("RealFrameRate")
                vdepth = s.get("BitDepth") or s.get("VideoBitDepth")
                dyn = s.get("ColorTransfer") or s.get("VideoRange") or s.get("ColorPrimaries")
                if isinstance(dyn, str):
                    u = dyn.upper()
                    dyn = "HDR" if ("PQ" in u or "HLG" in u or "HDR" in u or "BT2020" in u) else "SDR"

                # NEW: –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (DV / HDR10+ / HDR10 / HLG / HDR / SDR)
                try:
                    image_profiles = _detect_image_profiles_from_fields(s)
                except Exception:
                    image_profiles = None

            elif stype == "Audio":
                # –æ—Å–Ω–æ–≤–Ω–æ–π –∞—É–¥–∏–æ-—Å–Ω–∏–º–æ–∫ (–¥–ª—è —Å–≤–æ–¥–∫–∏)
                if acodec is None:
                    acodec = s.get("Codec")
                    abitrate = s.get("BitRate") or s.get("bitrate")
                    channels = s.get("Channels")
                # —á–∏—Ç–∞–µ–º ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ¬ª –∏–º—è –¥–æ—Ä–æ–∂–∫–∏
                label = s.get("DisplayTitle") or s.get("Title")
                if not label:
                    lang = s.get("Language")
                    codec = s.get("Codec")
                    ch = s.get("Channels")
                    layout = s.get("ChannelLayout")
                    parts = []
                    if lang:   parts.append(str(lang).upper())
                    if codec:  parts.append(str(codec).upper())
                    if ch:     parts.append(f"{ch}ch")
                    if layout: parts.append(layout)
                    label = " ".join(parts) or "Audio"
                audio_tracks.append(label)

        approx_kbps = None
        if (not vbitrate) and size_bytes and duration_sec and duration_sec > 0:
            approx_kbps = int((size_bytes * 8) / duration_sec / 1000)

        return {
            "video_codec": vcodec,
            "video_bitrate": vbitrate,
            "approx_video_kbps": approx_kbps,
            "width": width,
            "height": height,
            "fps": fps,
            "bit_depth": vdepth,
            "dynamic_range": dyn or "SDR",
            "audio_codec": acodec,
            "audio_bitrate": abitrate,
            "audio_channels": channels,
            "container": container,
            "size_bytes": size_bytes,
            "duration_sec": duration_sec,
            # –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏
            "audio_tracks": audio_tracks,
            "audio_track_count": len(audio_tracks),
            # NEW: –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ñ–æ–ª–±—ç–∫–æ–º
            "image_profiles": image_profiles or ["SDR"],
            "image_profile_str": ", ".join(image_profiles or ["SDR"]),
        }
    except Exception as ex:
        logging.warning(f"Media info fetch failed for movie {item_id}: {ex}")
        return {}

def build_audio_tracks_block(q: dict) -> str:
    tracks = (q or {}).get("audio_tracks") or []
    if not tracks:
        return ""
    header = t("audio_tracks")
    lines = "\n".join(f"- {name}" for name in tracks)
    return f"\n\n*{header} ({len(tracks)})*\n{lines}"

def _quality_signature(q: dict) -> str:
    """
    –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–ª—é—á –∫–∞—á–µ—Å—Ç–≤–∞: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–µ–∞–ª—å–Ω–æ–π –∑–∞–º–µ–Ω–µ —Ñ–∞–π–ª–∞.
    """
    def part(x): return "-" if x in (None, "", 0) else str(x)
    vbr = q.get("video_bitrate") or q.get("approx_video_kbps")
    return "|".join([
        part(q.get("video_codec")),
        f"{part(q.get('width'))}x{part(q.get('height'))}",
        part(vbr),
        part(q.get("dynamic_range")),
        part(q.get("bit_depth")),
        part(q.get("fps")),
        part(q.get("audio_codec")),
        part(q.get("audio_channels")),
        part(q.get("audio_bitrate")),
        part(q.get("container")),
        part(q.get("size_bytes")),
    ])

def _quality_is_substantial(q: dict | None) -> bool:
    """False, –µ—Å–ª–∏ ¬´–ø—É—Å—Ç–æ–π¬ª —Å–Ω–∏–º–æ–∫ (Jellyfin –µ—â—ë –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª –ø–æ—Ç–æ–∫–∏)."""
    if not q: return False
    return any([
        q.get("video_codec"),
        (q.get("width") and q.get("height")),
        q.get("audio_codec"),
        q.get("container"),
        q.get("size_bytes"),
    ])

def _fmt_mbps(q: dict) -> str:
    vbr = q.get("video_bitrate")
    if vbr:
        try: return f"{int(vbr)/1000:.1f} Mbps"
        except: return f"{vbr} kbps"
    kbps = q.get("approx_video_kbps")
    return f"{kbps/1000:.1f} Mbps (‚âà)" if kbps else "-"

def _movie_logical_key(*, tmdb_id: str | None, imdb_id: str | None, name: str, year: int | None) -> str:
    if tmdb_id: return f"movie:tmdb:{tmdb_id}"
    if imdb_id: return f"movie:imdb:{imdb_id}"
    # —Ñ–æ–ª–±—ç–∫: name+year –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    key_name = re.sub(r"\s+", " ", (name or "").strip().lower())
    return f"movie:nameyear:{key_name}:{year or ''}"

def store_quality_snapshot_movie(*, item_id: str, name: str, year: int | None,
                                 tmdb_id: str | None, imdb_id: str | None) -> dict:
    """
    1) –¢—è–Ω–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑ Jellyfin
    2) Upsert –≤ media_quality (–ø–æ ItemId)
    3) –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ upsert –≤ content_quality (–ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É)
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–ª–∞–≥–∏: logical_inserted, logical_changed, old_quality, new_quality
    """
    q = _get_item_media_info_movie(item_id)
    sig = _quality_signature(q)
    now = datetime.now().isoformat(timespec='seconds')

    profiles_str = (q.get("image_profile_str") or
                    ",".join(_profiles_from_q(q)))  # "DV,HDR10" –∏–ª–∏ "SDR"

    result = {
        "logical_inserted": False,
        "logical_changed": False,
        "old_quality": None,
        "new_quality": q,
        "old_signature": None,
        "new_signature": sig,
        "logical_key": None
    }

    logical_key = _movie_logical_key(tmdb_id=tmdb_id, imdb_id=imdb_id, name=name, year=year)
    result["logical_key"] = logical_key

    conn = sqlite3.connect(QUALITY_DB_FILE)
    try:
        cur = conn.cursor()
        # --- media_quality –ø–æ ItemId
        cur.execute("SELECT signature FROM media_quality WHERE item_id=?", (item_id,))
        if cur.fetchone() is None:
            cur.execute("""INSERT INTO media_quality
                           (item_id, movie_name, year, video_codec, video_bitrate, width, height, fps, bit_depth,
                            dynamic_range,
                            audio_codec, audio_bitrate, audio_channels, container, size_bytes, duration_sec, signature,
                            date_seen, image_profiles)
                           VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                        (item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                         q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                         q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                         q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now, profiles_str)
                        )
        else:
            cur.execute("""UPDATE media_quality
                           SET movie_name=?,
                               year=?,
                               video_codec=?,
                               video_bitrate=?,
                               width=?,
                               height=?,
                               fps=?,
                               bit_depth=?,
                               dynamic_range=?,
                               audio_codec=?,
                               audio_bitrate=?,
                               audio_channels=?,
                               container=?,
                               size_bytes=?,
                               duration_sec=?,
                               signature=?,
                               date_seen=?,
                               image_profiles=?
                           WHERE item_id = ?""",
                        (name, year, q.get("video_codec"), q.get("video_bitrate"),
                         q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                         q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                         q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now, profiles_str,
                         item_id)
                        )

        # --- content_quality –ø–æ logical_key
        cur.execute("""SELECT signature,
                              last_item_id,
                              video_codec,
                              video_bitrate,
                              width,
                              height,
                              fps,
                              bit_depth,
                              dynamic_range,
                              image_profiles,
                              audio_codec,
                              audio_bitrate,
                              audio_channels,
                              container,
                              size_bytes,
                              duration_sec
                       FROM content_quality
                       WHERE logical_key = ?""", (logical_key,))
        row = cur.fetchone()
        if row is None:
            if _quality_is_substantial(q):
                cur.execute("""INSERT INTO content_quality
                               (logical_key, last_item_id, movie_name, year, video_codec, video_bitrate, width, height,
                                fps, bit_depth,
                                dynamic_range, image_profiles, audio_codec, audio_bitrate, audio_channels, container,
                                size_bytes, duration_sec, signature, date_seen)
                               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                            (logical_key, item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                             q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                             profiles_str, q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                             q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now)
                            )
                result["logical_inserted"] = True
        else:
            old_sig, old_item_id = row[0], row[1]
            old_q = {
                "video_codec": row[2], "video_bitrate": row[3], "width": row[4], "height": row[5],
                "fps": row[6], "bit_depth": row[7], "dynamic_range": row[8],
                "image_profiles": ([p.strip() for p in row[9].split(",")] if row[9] else None),
                "audio_codec": row[10], "audio_bitrate": row[11], "audio_channels": row[12],
                "container": row[13], "size_bytes": row[14], "duration_sec": row[15]
            }
            result["old_signature"] = old_sig
            result["old_quality"] = old_q

            if old_sig != sig and _quality_is_substantial(old_q) and _quality_is_substantial(q):
                result["logical_changed"] = True
                cur.execute("""UPDATE content_quality
                               SET last_item_id=?,
                                   movie_name=?,
                                   year=?,
                                   video_codec=?,
                                   video_bitrate=?,
                                   width=?,
                                   height=?,
                                   fps=?,
                                   bit_depth=?,
                                   dynamic_range=?,
                                   image_profiles=?,
                                   audio_codec=?,
                                   audio_bitrate=?,
                                   audio_channels=?,
                                   container=?,
                                   size_bytes=?,
                                   duration_sec=?,
                                   signature=?,
                                   date_seen=?
                               WHERE logical_key = ?""",
                            (item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                             q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                             profiles_str, q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                             q.get("container"), q.get("size_bytes"), q.get("duration_sec"),
                             sig, now, logical_key)
                            )
        conn.commit()
    finally:
        conn.close()
    return result

def _labels():
    if LANG == "ru":
        return {
            "changes": "–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞",
            "resolution": "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ",
            "video_codec": "–í–∏–¥–µ–æ-–∫–æ–¥–µ–∫",
            "bitrate": "–ë–∏—Ç—Ä–µ–π—Ç (–≤–∏–¥–µ–æ)",
            "dynamic_range": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω",
            "audio": "–ê—É–¥–∏–æ",
            "container": "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä",
            "fps": "–ö–∞–¥—Ä–æ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞",
            "bit_depth": "–ë–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞",
        }
    return {
        "changes": "Quality changes",
        "resolution": "Resolution",
        "video_codec": "Video codec",
        "bitrate": "Bitrate (video)",
        "dynamic_range": "Dynamic range",
        "audio": "Audio",
        "container": "Container",
        "fps": "Frame rate",
        "bit_depth": "Bit depth",
    }

def build_quality_changes_block(old_q: dict, new_q: dict) -> str:
    L = _labels()
    lines = []

    def arrow(a, b):
        return f"{a} ‚Üí {b}"

    # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    # --- Resolution (—Å —è—Ä–ª—ã–∫–∞–º–∏) ---
    res_old = _res_display_from_q(old_q)
    res_new = _res_display_from_q(new_q)
    if res_old != res_new:
        lines.append(f"- {L['resolution']}: {arrow(res_old, res_new)}")

    # –í–∏–¥–µ–æ-–∫–æ–¥–µ–∫
    vc_old = (old_q.get("video_codec") or "-").upper()
    vc_new = (new_q.get("video_codec") or "-").upper()
    if vc_old != vc_new:
        lines.append(f"- {L['video_codec']}: {arrow(vc_old, vc_new)}")

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω (SDR/HDR –∏ —Ç.–ø.)
    dr_old = old_q.get("dynamic_range") or "-"
    dr_new = new_q.get("dynamic_range") or "-"
    if dr_old != dr_new:
        lines.append(f"- {L['dynamic_range']}: {arrow(dr_old, dr_new)}")

    # –ü—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (SDR/HDR/HDR10/HDR10+/DV/HLG)
    old_profiles = ", ".join(_profiles_from_q(old_q))
    new_profiles = ", ".join(_profiles_from_q(new_q))
    if old_profiles != new_profiles:
        lines.append(f"- {t('image_profiles')}: {old_profiles} ‚Üí {new_profiles}")
    logging.debug(f"Quality delta profiles: old='{old_profiles}' new='{new_profiles}'")
    if not lines:
        return ""
    return f"\n\n*{L['changes']}*\n" + "\n".join(lines)

def build_initial_quality_changes_block(new_q: dict) -> str:
    """
    –ë–ª–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –ù–û–í–û–ì–û —Ñ–∏–ª—å–º–∞ –±–µ–∑ —Å—Ç—Ä–µ–ª–æ–∫ –∏ –±–µ–∑ 'Dynamic range'.
    –ü–æ–∫–∞–∑—ã–≤–∞–µ–º: Resolution, Video codec, Image profiles.
    """
    L = _labels()
    lines = []

    # Resolution
    # Resolution -> —è—Ä–ª—ã–∫ (–∏–ª–∏ WxH –ø—Ä–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º)
    res_new = _res_display_from_q(new_q)
    if res_new != "-":
        lines.append(f"- {L['resolution']}: {res_new}")

    # Video codec
    vc_new = (new_q.get("video_codec") or "-").upper()
    if vc_new != "-":
        lines.append(f"- {L['video_codec']}: {vc_new}")

    # Image profiles (SDR/HDR/HDR10/HDR10+/DV/HLG)
    profiles = ", ".join(_profiles_from_q(new_q))
    lines.append(f"- {t('image_profiles')}: {profiles}")

    if not lines:
        return ""
    return f"\n\n*{L['changes']}*\n" + "\n".join(lines)



def maybe_notify_movie_quality_change(*, item_id: str, movie_name_cleaned: str, release_year: int | None,
                                      tmdb_id: str | None, imdb_id: str | None,
                                      overview: str | None, runtime: str | None) -> bool:
    """
    –ï—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å–º–∞ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å (–ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É) ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    —Ç–µ–º –∂–µ —à–∞–±–ª–æ–Ω–æ–º, —á—Ç–æ –∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞, + –±–ª–æ–∫ '–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ (–æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ 'New Movie' —Å–ª–∞—Ç—å –Ω–µ –Ω–∞–¥–æ).
    """
    res = store_quality_snapshot_movie(
        item_id=item_id, name=movie_name_cleaned, year=release_year,
        tmdb_id=tmdb_id, imdb_id=imdb_id
    )
    if not res.get("logical_changed"):
        return False

    old_q = res.get("old_quality")
    new_q = res.get("new_quality")
    # –ï—Å–ª–∏ —Å—Ç–∞—Ä—ã–π —Å–Ω–∏–º–æ–∫ ¬´–ø—É—Å—Ç–æ–π¬ª ‚Äî —ç—Ç–æ –ø–µ—Ä–≤—ã–π –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å –Ω–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞; —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ –ù–ï –∞–ø–≥—Ä–µ–π–¥.
    if not _quality_is_substantial(old_q):
        logging.info("(Movie guard) Old quality is empty -> treat as NEW content, not a quality update.")
        return False

    # –°–æ–±–∏—Ä–∞–µ–º ¬´–∫–∞–∫ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏¬ª
    notification_message = (
        f"*{t('quality_updated')}*\n\n*{movie_name_cleaned}* *({release_year})*\n\n{overview or ''}\n\n"
        f"*{t('new_runtime')}*\n{runtime or ''}"
    )

    # —Ä–µ–π—Ç–∏–Ω–≥–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å tmdb_id)
    if tmdb_id:
        ratings_text = safe_fetch_mdblist_ratings("movie", tmdb_id)
        if ratings_text:
            notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"

    # —Ç—Ä–µ–π–ª–µ—Ä
    trailer_url = safe_get_trailer_prefer_tmdb(f"{movie_name_cleaned} Trailer {release_year}",
                                context="webhook", subkind="movie", tmdb_id=tmdb_id)
    if trailer_url:
        notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

    # –¥–æ–±–∞–≤–∏–º –±–ª–æ–∫ ¬´—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å¬ª
    # –¥–æ–±–∞–≤–∏–º –±–ª–æ–∫ ¬´—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å¬ª
    delta = build_quality_changes_block(old_q, new_q)
    if delta:
        notification_message += delta

    # –î–û–ë–ê–í–¨ –£–°–õ–û–í–ò–ï:
    if INCLUDE_AUDIO_TRACKS:
        tracks_block = build_audio_tracks_block(new_q)
        if tracks_block:
            notification_message += tracks_block

    send_notification(item_id, notification_message)
    touch_quality_update_marker(res.get("logical_key") or _movie_logical_key(
        tmdb_id=tmdb_id, imdb_id=imdb_id, name=movie_name_cleaned, year=release_year
    ), item_id=item_id)
    logging.info(f"(Movie) Quality update sent for {movie_name_cleaned} ({release_year}); logical_key={res.get('logical_key')}")
    return True

def _format_runtime_from_ticks(runtime_ticks) -> str:
    if not runtime_ticks:
        return ""
    try:
        total_sec = int(runtime_ticks) // 10_000_000
        h = total_sec // 3600
        m = (total_sec % 3600) // 60
        if h > 0:
            return f"{h}h {m}m"
        return f"{m}m"
    except Exception:
        return ""

def _format_title_with_year(title: str, year) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç 'Title (YYYY)' –µ—Å–ª–∏ –≥–æ–¥ –∑–∞–¥–∞–Ω, –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ 'Title'.
    –ì–æ–¥ –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ None/''/0/—Å—Ç—Ä–æ–∫–æ–π.
    """
    try:
        y = ("" if year is None else str(year)).strip()
    except Exception:
        y = ""
    return f"{title} ({y})" if y else title


def poll_recent_movies_once():
    """
    –ü–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ç—è–Ω–µ–º —Ñ–∏–ª—å–º—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞–ø–≥—Ä–µ–π–¥—ã –∫–∞—á–µ—Å—Ç–≤–∞.
    –ù–æ–≤—ã–µ (–æ—á–µ–Ω—å —Å–≤–µ–∂–∏–µ) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –∏—Ö –æ–±—ä—è–≤–∏—Ç –≤–µ–±—Ö—É–∫.
    """
    page_size = MOVIE_POLL_PAGE_SIZE
    # —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Å—Ç–∞—Ä—ã–π MOVIE_POLL_LIMIT –∏ MAX_TOTAL == 0, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –ø—Ä–µ–¥–µ–ª
    max_total = MOVIE_POLL_MAX_TOTAL  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    while True:
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        current_limit = page_size
        if max_total and (max_total - fetched) < page_size:
            current_limit = max_total - fetched
            if current_limit <= 0:
                break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                # DateCreated –Ω—É–∂–µ–Ω –¥–ª—è –≥—Ä–µ–π—Å-—Ñ–∏–ª—å—Ç—Ä–∞ (—á—Ç–æ–±—ã –≤–µ–±—Ö—É–∫ –æ–±—ä—è–≤–ª—è–ª ¬´–Ω–æ–≤—ã–µ¬ª)
                "Fields": "MediaSources,RunTimeTicks,ProviderIds,ProductionYear,Overview,DateCreated"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Movie poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            try:
                # --- –≥—Ä–µ–π—Å: —Å–≤–µ–∂–∏–µ –Ω–æ–≤–∏–Ω–∫–∏ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º (–ø—É—Å—Ç—å –≤–µ–±—Ö—É–∫ –ø–æ—à–ª—ë—Ç 'New Movie Added')

                # -------------------------------------------------------------

                item_id = it.get("Id")
                name = it.get("Name") or ""
                year = it.get("ProductionYear")
                prov = it.get("ProviderIds") or {}
                tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
                imdb_id = prov.get("Imdb") or prov.get("ImdbId")

                # –ò–º—è –±–µ–∑ –≥–æ–¥–∞ –≤ —Å–∫–æ–±–∫–∞—Ö (–∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ)
                name_clean = name.replace(f" ({year})", "").strip()

                # Overview/Runtime –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                overview = it.get("Overview") or ""
                runtime_str = _format_runtime_from_ticks(it.get("RunTimeTicks"))

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –∞–ø–¥–µ–π—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–Ω–µ ¬´–Ω–æ–≤—ã–π —Ñ–∏–ª—å–º¬ª)
                sent = maybe_notify_movie_quality_change(
                    item_id=item_id,
                    movie_name_cleaned=name_clean,
                    release_year=year,
                    tmdb_id=tmdb_id,
                    imdb_id=imdb_id,
                    overview=overview,
                    runtime=runtime_str
                )
                if sent:
                    # –∑–∞–ø–∏—Å—å –≤ –ë–î —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞; –ø–æ–≤—Ç–æ—Ä–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –ø—Ä–æ—Ö–æ–¥–µ –Ω–µ –±—É–¥–µ—Ç
                    continue

                # --- NEW: –µ—Å–ª–∏ —ç—Ç–æ ¬´–Ω–æ–≤—ã–π —Ñ–∏–ª—å–º¬ª –∏ –ø–æ –Ω–µ–º—É –µ—â—ë –Ω–µ –±—ã–ª–æ –∞–Ω–æ–Ω—Å–∞ ‚Äî —à–ª—ë–º ¬´New Movie Added¬ª
                if not item_already_notified("Movie", name, year):
                    logical_key = _movie_logical_key(
                        tmdb_id=tmdb_id,
                        imdb_id=imdb_id,
                        name=name_clean,
                        year=year
                    )
                    # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ –±—ã–ª quality-update ‚Äî –Ω–µ –¥—É–±–ª–∏—Ä—É–µ–º ¬´–Ω–æ–≤—ã–π —Ñ–∏–ª—å–º¬ª
                    if was_quality_update_recent(logical_key):
                        logging.info(
                            f"(Movie poll) Suppressed 'new movie' due to recent quality update (logical_key={logical_key})")
                    else:
                        # --- Pre-DB cutoff: baseline –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –ë–î (movie_announced)
                        try:
                            db_created_iso = _db_get_created_at_iso()
                            db_created_dt = _parse_iso_dt(db_created_iso)
                            created_iso = it.get("DateCreated")
                            created_dt = _parse_iso_dt(created_iso)

                            # –ï—Å–ª–∏ —É–∂–µ —Å—Ç–∞–≤–∏–ª–∏ baseline –≤ –ë–î ‚Äî –º–æ–ª—á–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                            if _movie_announced_get(logical_key):
                                continue

                            if db_created_dt and created_dt and (created_dt < db_created_dt):
                                _movie_announced_mark(
                                    logical_key,
                                    item_id=item_id,
                                    name=name_clean,
                                    year=year
                                )
                                logging.debug(f"(Movie poll) Pre-DB cutoff baseline set: {name_clean} ({year})")
                                continue
                        except Exception as ex:
                            logging.warning(f"Movie cutoff check failed for {item_id}: {ex}")

                        notification_message = (
                            f"*{t('new_movie_title')}*\n\n"
                            f"*{name_clean}* *({year})*\n\n"
                            f"{overview}\n\n"
                            f"*{t('new_runtime')}*\n{runtime_str}"
                        )

                        # –†–µ–π—Ç–∏–Ω–≥–∏ (MDBList), –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                        try:
                            ratings_text = safe_fetch_mdblist_ratings("movie", tmdb_id) if tmdb_id else ""
                            if ratings_text:
                                notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"
                        except Exception as ex:
                            logging.warning(f"Movie poll: ratings fetch failed for {name_clean} ({year}): {ex}")

                        # –¢—Ä–µ–π–ª–µ—Ä ‚Äî –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ –ø–æ TMDb
                        try:
                            trailer_url = safe_get_trailer_prefer_tmdb(
                                f"{name_clean} Trailer {year}",
                                context="poll",
                                subkind="movie",
                                tmdb_id=tmdb_id
                            )
                            if trailer_url:
                                notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"
                        except Exception as ex:
                            logging.warning(f"Movie poll: trailer fetch failed for {name_clean} ({year}): {ex}")

                        # –ü–µ—Ä–≤–∏—á–Ω—ã–π –±–ª–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ (baseline), –ø–ª—é—Å –¥–æ—Ä–æ–∂–∫–∏ ‚Äî –∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ
                        # –ö–∞—á–µ—Å—Ç–≤–æ: –∫–∞–∫ –≤ maybe_notify_movie_quality_change ‚Äî —á–µ—Ä–µ–∑ store_quality_snapshot_movie
                        try:
                            res_q = store_quality_snapshot_movie(
                                item_id=item_id,
                                name=name_clean,
                                year=year,
                                tmdb_id=tmdb_id,
                                imdb_id=imdb_id
                            )
                            new_q = (res_q.get("new_quality") or {})
                            old_q = res_q.get("old_quality")

                            if old_q:
                                # –ï—Å–ª–∏ —Ä–∞–Ω–µ–µ –≤ –ë–î –µ—Å—Ç—å —Å–ª–µ–ø–æ–∫ ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å ¬´–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞¬ª,
                                # –∞ –µ—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ—Ç ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å –ø–µ—Ä–≤–∏—á–Ω—ã–π –±–ª–æ–∫
                                delta = build_quality_changes_block(old_q, new_q)
                                if delta:
                                    notification_message += delta
                                else:
                                    init_block = build_initial_quality_changes_block(new_q)
                                    if init_block:
                                        notification_message += init_block
                            else:
                                # –ò–Ω–∞—á–µ ‚Äî ¬´–ø–µ—Ä–≤–∏—á–Ω—ã–π¬ª –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π –±–ª–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞
                                init_block = build_initial_quality_changes_block(new_q)
                                if init_block:
                                    notification_message += init_block

                            if INCLUDE_AUDIO_TRACKS:
                                tracks_block = build_audio_tracks_block(new_q)
                                if tracks_block:
                                    notification_message += tracks_block

                        except Exception as ex:
                            logging.warning(
                                f"Movie poll: failed to build quality block for {name_clean} ({year}): {ex}")

                        send_notification(item_id, notification_message)
                        _movie_announced_mark(logical_key, item_id=item_id, name=name_clean, year=year)
                        logging.info(f"(Movie poll) NEW movie announced: {name_clean} ({year})")
                        continue
                # --- /NEW

            except Exception as ex:
                logging.warning(f"Movie poll: item {it.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        logging.debug(f"Movie poll: page fetched {n} items (total {fetched})")

        # –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ–ø–æ–ª–Ω–∞—è ‚Äî –¥–∞–ª—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç
        if n < current_limit:
            break

        # –º—è–≥–∫–æ–µ –¥—ã—Ö–∞–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        time.sleep(0.1)

    # ... –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ —Ñ—É–Ω–∫—Ü–∏–∏:
    _meta_set('touched_movies','1')
    _maybe_send_onboarding_congrats()

def _detect_image_profiles_from_fields(s: dict) -> list[str]:
    """
    –î–µ—Ç–µ–∫—Ç DV / HDR10+ / HDR10 / HLG / HDR / SDR –ø–æ –ø–æ–ª—è–º –≤–∏–¥–µ–æ-–ø–æ—Ç–æ–∫–∞.
    –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º ['SDR'].
    """
    txt_parts = []
    for k in ("ColorTransfer","VideoRange","VideoRangeType","ColorPrimaries","ColorSpace",
              "Profile","Hdr","Hdr10Plus","DolbyVision","DoVi","VideoDoViProfile"):
        v = s.get(k)
        if isinstance(v, bool):
            v = "1" if v else "0"
        if v is not None:
            txt_parts.append(str(v))
    txt = " ".join(txt_parts).upper()

    prof = []
    def add(tag):
        if tag not in prof:
            prof.append(tag)

    if "DOLBY VISION" in txt or "DOVI" in txt or "VIDEO DOVIPROFILE" in txt or re.search(r"\bDV\b", txt or ""):
        add("DV")
    if "HDR10+" in txt or "HDR10PLUS" in txt or "HDR10 PLUS" in txt:
        add("HDR10+")
    if "HDR10" in txt:
        add("HDR10")
    if "HLG" in txt:
        add("HLG")
    if ("HDR" in txt or "PQ" in txt or "BT2020" in txt) and not any(p in prof for p in ("DV","HDR10+","HDR10","HLG")):
        add("HDR")
    if not prof:
        add("SDR")

    order = {"DV":0,"HDR10+":1,"HDR10":2,"HLG":3,"HDR":4,"SDR":5}
    prof.sort(key=lambda x: order.get(x, 99))
    return prof

def _profiles_from_q(q: dict | None) -> list[str]:
    order = {"DV": 0, "HDR10+": 1, "HDR10": 2, "HLG": 3, "HDR": 4, "SDR": 5}
    if not q:
        return ["SDR"]

    profs = (q.get("image_profiles") or [])
    if not profs:
        dr = (q.get("dynamic_range") or "").upper()
        if "DV" in dr or "DOLBY" in dr:
            profs = ["DV"]
        elif "HDR10+" in dr:
            profs = ["HDR10+"]
        elif "HDR10" in dr:
            profs = ["HDR10"]
        elif "HLG" in dr:
            profs = ["HLG"]
        elif "HDR" in dr:
            profs = ["HDR"]
        else:
            profs = ["SDR"]

    # ‚Üê –≤–æ—Ç —ç—Ç–∏ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ:
    profs = [str(p).strip().upper() for p in profs if str(p).strip()]
    profs = list(dict.fromkeys(profs))

    profs.sort(key=lambda p: order.get(p, 99))
    return profs

def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')

def _iso_to_dt(s: str | None) -> datetime | None:
    if not s: return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00'))
    except Exception:
        return None

def touch_quality_update_marker(logical_key: str, item_id: str | None = None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""INSERT INTO recent_quality_updates (logical_key, notified_at, item_id)
                       VALUES (?, ?, ?)
                       ON CONFLICT(logical_key) DO UPDATE SET
                         notified_at=excluded.notified_at,
                         item_id=excluded.item_id
                    """, (logical_key, _now_utc_iso(), item_id))
        conn.commit()
    except Exception as ex:
        logging.warning(f"touch_quality_update_marker failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def was_quality_update_recent(logical_key: str) -> bool:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT notified_at FROM recent_quality_updates WHERE logical_key=?", (logical_key,))
        row = cur.fetchone()
    except Exception as ex:
        logging.warning(f"was_quality_update_recent check failed: {ex}")
        return False
    finally:
        try: conn.close()
        except: pass

    if not row:
        return False
    ts = _iso_to_dt(row[0])
    if not ts:
        return False
    return (datetime.now(timezone.utc) - ts) < timedelta(minutes=SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN)

def _parse_iso_utc(s: str | None):
    if not s:
        return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00')).astimezone(timezone.utc)
    except Exception:
        return None


def _movie_poll_loop():
    while True:
        try:
            poll_recent_movies_once()
        except Exception as ex:
            logging.warning(f"Movie poll loop error: {ex}")
        time.sleep(MOVIE_POLL_INTERVAL_SEC)

if MOVIE_POLL_ENABLED:
    threading.Thread(target=_movie_poll_loop, name="movie-poll", daemon=True).start()
    logging.info(f"Movie quality polling enabled every {MOVIE_POLL_INTERVAL_SEC}s (limit={MOVIE_POLL_MAX_TOTAL})")

def _resolution_label(width: int | None, height: int | None) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —è—Ä–ª—ã–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è (8K, 5K, 4K (UltraHD), 1440p, 1080p, 720p, 576p, 480p, 360p, 240p).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã—Å–æ—Ç—É –∫–∞–¥—Ä–∞ —Å –¥–æ–ø—É—Å–∫–æ–º (~8%) –Ω–∞ ¬´–Ω–µ–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ¬ª –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2026 ‚âà 2160).
    –ï—Å–ª–∏ –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –Ω–∏ –≤ –æ–¥–∏–Ω –¥–∏–∞–ø–∞–∑–æ–Ω ‚Äî –≤–µ—Ä–Ω—ë—Ç None.
    """
    if not height:
        return None

    # (target_height, label)
    targets = [
        (4320, "8K"),
        (2880, "5K"),
        (2160, "4K (UltraHD)"),
        (1440, "1440p"),
        (1080, "1080p"),
        (720,  "720p"),
        (576,  "576p"),
        (480,  "480p"),
        (360,  "360p"),
        (240,  "240p"),
    ]
    for h, label in targets:
        tol = max(int(h * 0.08), 12)  # ~8% –∏–ª–∏ –º–∏–Ω–∏–º—É–º 12px
        if abs(height - h) <= tol:
            return label
    return None

def _res_display_from_q(q: dict | None) -> str:
    """
    –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:
    - –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —è—Ä–ª—ã–∫ 8K/4K/... -> –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ
    - –∏–Ω–∞—á–µ –≤–µ—Ä–Ω—É—Ç—å 'WxH'
    - –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç -> '-'
    """
    if not q:
        return "-"
    w, h = q.get("width"), q.get("height")
    if not (w and h):
        return "-"
    label = _resolution_label(w, h)
    return label or f"{w}x{h}"

#–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Å–µ—Ä–∏–∞–ª–æ–≤
def _get_item_resolution_label(item_id: str) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, '1080p'/'4K' –∏–ª–∏ 'WxH') –¥–ª—è –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ Jellyfin.
    –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π MediaSource -> –ø–µ—Ä–≤—ã–π Video stream.
    """
    try:
        params = {'api_key': JELLYFIN_API_KEY, 'Ids': item_id, 'Fields': 'MediaSources'}
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        item = (r.json().get("Items") or [{}])[0]
        sources = item.get("MediaSources") or []
        if not sources:
            return None
        streams = sources[0].get("MediaStreams") or []
        v = next((s for s in streams if (s.get("Type") == "Video")), None)
        if not v:
            return None
        w = v.get("Width") or v.get("PixelWidth")
        h = v.get("Height") or v.get("PixelHeight")
        q = {"width": w, "height": h}
        res = _res_display_from_q(q)
        return None if (not res or res == "-") else res
    except Exception as ex:
        logging.debug(f"_get_item_resolution_label failed for {item_id}: {ex}")
        return None


def _season_resolution_label(season_id: str, *, scan_limit: int | None = None) -> str | None:
    """
    –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ —Å–µ–∑–æ–Ω–∞: –±–µ—Ä—ë–º –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ø–∏–∑–æ–¥—ã, —Å—á–∏—Ç–∞–µ–º (w,h),
    –≤—ã–±–∏—Ä–∞–µ–º —Å–∞–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω–æ–µ; –ø—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ ‚Äî —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤—ã—Å–æ—Ç–æ–π.
    """
    try:
        eps = _season_fetch_episodes(season_id, max_items=scan_limit)
        present = [ep for ep in eps if _episode_has_file(ep)]
        if not present:
            return None

        from collections import Counter
        dims = []

        for ep in present:
            sources = ep.get("MediaSources") or []
            if not sources:
                continue
            streams = sources[0].get("MediaStreams") or []
            v = next((s for s in streams if (s.get("Type") == "Video")), None)
            if not v:
                continue
            w = v.get("Width") or v.get("PixelWidth")
            h = v.get("Height") or v.get("PixelHeight")
            if w and h:
                try:
                    dims.append((int(w), int(h)))
                except Exception:
                    pass

        if not dims:
            return None

        cnt = Counter(dims)
        # —Å–∞–º–æ–µ —á–∞—Å—Ç–æ–µ; –ø—Ä–∏ —Ä–∞–≤–Ω–æ–º —Å—á—ë—Ç–µ –±–µ—Ä—ë–º —Å max –≤—ã—Å–æ—Ç–æ–π
        best = max(cnt.items(), key=lambda kv: (kv[1], kv[0][1]))[0]  # -> (w,h)
        label = _resolution_label(best[0], best[1]) or f"{best[0]}x{best[1]}"
        return label
    except Exception as ex:
        logging.debug(f"_season_resolution_label failed for season {season_id}: {ex}")
        return None

#–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace("+00:00", "Z")

def _iso_to_dt(s: str | None) -> datetime | None:
    if not s: return None
    try: return datetime.fromisoformat(s.replace("Z","+00:00")).astimezone(timezone.utc)
    except Exception: return None

def _collect_current_movie_keys_and_ids() -> tuple[set[str], set[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (set –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–π, set ItemId) –¥–ª—è –í–°–ï–• —Ñ–∏–ª—å–º–æ–≤ –≤ Jellyfin.
    –ö–ª—é—á —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ _movie_logical_key(...) –ø–æ ProviderIds/Tmdb/Imdb -> name+year.
    """
    current_keys: set[str] = set()
    current_ids: set[str] = set()

    start = 0
    page_size = QUALITY_GC_PAGE_SIZE

    while True:
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateCreated",
                "SortOrder": "Descending",
                "Limit": str(page_size),
                "StartIndex": str(start),
                "Fields": "ProviderIds,ProductionYear"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Quality GC: failed to list movies page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            item_id = it.get("Id")
            name = it.get("Name") or ""
            year = it.get("ProductionYear")
            prov = it.get("ProviderIds") or {}
            tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
            imdb_id = prov.get("Imdb") or prov.get("ImdbId")
            # –∏–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ "(year)"
            name_clean = name.replace(f" ({year})", "").strip()

            key = _movie_logical_key(
                tmdb_id=tmdb_id,
                imdb_id=imdb_id,
                name=name_clean,
                year=year
            )
            current_keys.add(key)
            if item_id:
                current_ids.add(item_id)

        n = len(items)
        start += n
        if n < page_size:
            break

    return current_keys, current_ids

def _collect_current_movie_keys_and_ids() -> tuple[set[str], set[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (set –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–π, set ItemId) –¥–ª—è –í–°–ï–• —Ñ–∏–ª—å–º–æ–≤ –≤ Jellyfin.
    –ö–ª—é—á —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ _movie_logical_key(...) –ø–æ ProviderIds/Tmdb/Imdb -> name+year.
    """
    current_keys: set[str] = set()
    current_ids: set[str] = set()

    start = 0
    page_size = QUALITY_GC_PAGE_SIZE

    while True:
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateCreated",
                "SortOrder": "Descending",
                "Limit": str(page_size),
                "StartIndex": str(start),
                "Fields": "ProviderIds,ProductionYear"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Quality GC: failed to list movies page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            item_id = it.get("Id")
            name = it.get("Name") or ""
            year = it.get("ProductionYear")
            prov = it.get("ProviderIds") or {}
            tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
            imdb_id = prov.get("Imdb") or prov.get("ImdbId")
            # –∏–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ "(year)"
            name_clean = name.replace(f" ({year})", "").strip()

            key = _movie_logical_key(
                tmdb_id=tmdb_id,
                imdb_id=imdb_id,
                name=name_clean,
                year=year
            )
            current_keys.add(key)
            if item_id:
                current_ids.add(item_id)

        n = len(items)
        start += n
        if n < page_size:
            break

    return current_keys, current_ids

def gc_quality_db_once():
    """
    –£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏:
      - content_quality: –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ last seen —Å—Ç–∞—Ä—à–µ GRACE
      - media_quality: item_id, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ last seen —Å—Ç–∞—Ä—à–µ GRACE
      - recent_quality_updates: –º–∞—Ä–∫–µ—Ä—ã –ø–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º –∫–ª—é—á–∞–º
    """
    try:
        current_keys, current_ids = _collect_current_movie_keys_and_ids()
        cutoff = datetime.now(timezone.utc) - timedelta(days=QUALITY_GC_GRACE_DAYS)

        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()

        # --- content_quality
        cur.execute("SELECT logical_key, date_seen FROM content_quality")
        rows = cur.fetchall()
        to_del_keys = []
        for logical_key, date_seen in rows:
            if logical_key in current_keys:
                continue
            dt = _iso_to_dt(date_seen)
            if (dt is None) or (dt < cutoff):
                to_del_keys.append(logical_key)

        if to_del_keys:
            for key in to_del_keys:
                cur.execute("DELETE FROM content_quality WHERE logical_key=?", (key,))
            logging.info(f"Quality GC: removed {len(to_del_keys)} content_quality rows")

        # --- media_quality
        cur.execute("SELECT item_id, date_seen FROM media_quality")
        rows = cur.fetchall()
        to_del_ids = []
        for item_id, date_seen in rows:
            if item_id in current_ids:
                continue
            dt = _iso_to_dt(date_seen)
            if (dt is None) or (dt < cutoff):
                to_del_ids.append(item_id)

        if to_del_ids:
            for iid in to_del_ids:
                cur.execute("DELETE FROM media_quality WHERE item_id=?", (iid,))
            logging.info(f"Quality GC: removed {len(to_del_ids)} media_quality rows")

        # --- recent_quality_updates (–º–∞—Ä–∫–µ—Ä—ã –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –≤–µ–±—Ö—É–∫–∞)
        if to_del_keys:
            for key in to_del_keys:
                cur.execute("DELETE FROM recent_quality_updates WHERE logical_key=?", (key,))

        conn.commit()

        # –ø–æ –∂–µ–ª–∞–Ω–∏—é –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –¥–µ–ª–∞—Ç—å VACUUM (—Ä–µ–¥–∫–æ)
        # cur.execute("VACUUM")  # –µ—Å–ª–∏ –±–∞–∑–∞ –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–∞

    except Exception as ex:
        logging.warning(f"Quality GC error: {ex}")
    finally:
        try:
            conn.close()
        except Exception:
            pass

_init_quality_db()

# --- –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ) ---
if FORCE_QUALITY_GC_ON_START:
    old_grace = QUALITY_GC_GRACE_DAYS
    try:
        # –ï—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ —è–≤–Ω–æ ‚Äî —á–∏—Å—Ç–∏–º –±–µ–∑ ¬´–≥—Ä–µ–π—Å–∞¬ª (—Å—Ä–∞–∑—É)
        QUALITY_GC_GRACE_DAYS = int(FORCE_QUALITY_GC_GRACE_DAYS) if FORCE_QUALITY_GC_GRACE_DAYS is not None else 0
    except Exception:
        logging.warning(f"FORCE_QUALITY_GC_GRACE_DAYS is not an int: {FORCE_QUALITY_GC_GRACE_DAYS}")
        QUALITY_GC_GRACE_DAYS = 0

    logging.info(f"Quality DB GC (startup forced): grace={QUALITY_GC_GRACE_DAYS}d, vacuum={FORCE_QUALITY_GC_VACUUM}")
    try:
        gc_quality_db_once()  # —É–¥–∞–ª–∏—Ç –∑–∞–ø–∏—Å–∏ –ø–æ —Ñ–∏–ª—å–º–∞–º, –∫–æ—Ç–æ—Ä—ã—Ö —É–∂–µ –Ω–µ—Ç –≤ Jellyfin
        if FORCE_QUALITY_GC_VACUUM:
            try:
                conn = sqlite3.connect(QUALITY_DB_FILE)
                conn.execute("VACUUM")
                conn.close()
                logging.info("Quality DB GC (startup) VACUUM done.")
            except Exception as ex:
                logging.warning(f"Quality DB GC (startup) VACUUM failed: {ex}")
    finally:
        # –≤–µ—Ä–Ω—ë–º –æ–±—ã—á–Ω—ã–π grace –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–∏
        QUALITY_GC_GRACE_DAYS = old_grace

#–†–∞–±–æ—Ç–∞ —è youtube –∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–º

# --- SAFE trailer & ratings helpers ---
_youtube_forbid_until = 0.0
_trailer_cache = {}   # –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å
_ratings_cache = {}   # –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å

def safe_get_trailer(query: str, *, context: str = "", subkind: str | None = None, tmdb_id: str | None = None) -> str | None:
    """
    –ò—â–µ–º —Ç—Ä–µ–π–ª–µ—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ + –∫—ç—à–∏—Ä—É–µ–º –≤ –ë–î.
    –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫—ç—à–∞ –±–µ—Ä—ë–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É: tmdb_id ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π query.
    subkind: 'movie' | 'show' (–¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ TTL/–∞–Ω–∞–ª–∏—Ç–∏–∫–∏; –∫ –∫–ª—é—á—É –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    """
    # –ø—Ä–∞–≤–∏–ª–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è
    try:
        if os.getenv("TRAILER_FETCH_ENABLED", "1").lower() not in ("1","true","yes","on"):
            return None
        if os.getenv("DISABLE_TRAILER_IN_POLLS", "1").lower() in ("1","true","yes","on") and context == "series_poll":
            return None
    except Exception:
        pass

    # –∫–ª—é—á –∫—ç—à–∞
    identity = tmdb_id or query.strip()
    # 1) —á–∏—Ç–∞–µ–º –∫—ç—à
    cached_val, cached_at = _extcache_read("trailer", subkind, identity)
    if _is_fresh(cached_at, TRAILER_CACHE_TTL_DAYS) and cached_val:
        return cached_val

    # 2) –Ω–µ —Å–≤–µ–∂–∏–π ‚Äî –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑ —Å–µ—Ç–∏ (—Å 403-–ø—Ä–µ–¥–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–µ–º)
    try:
        # –ª–æ–∫–∞–ª—å–Ω—ã–π ¬´—Å—Ç–æ–ø¬ª –ø–æ 403
        import time as _t
        forbid_until = globals().get("_youtube_forbid_until", 0.0)
        if _t.time() < forbid_until:
            return cached_val or None

        url = get_youtube_trailer_url(query)  # —Ç–≤–æ—è –∏—Å—Ö–æ–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        if url:
            _extcache_write("trailer", subkind, identity, url)
            return url
        # –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–µ—Ä–Ω—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ç–µ–∫—Å—Ç
        return cached_val or None

    except requests.HTTPError as ex:
        resp = getattr(ex, "response", None)
        if getattr(resp, "status_code", None) == 403:
            # –ø—Ä–∏ 403 ‚Äî —Å—Ç–∞–≤–∏–º ¬´—Ñ–æ—Ä–±–∏–¥¬ª –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
            import time as _t
            suspend_min = int(os.getenv("TRAILER_FORBID_SUSPEND_MIN", "60"))
            globals()["_youtube_forbid_until"] = _t.time() + suspend_min * 60
            logging.warning(f"YouTube 403; suspend {suspend_min} min; use cache if any")
            return cached_val or None
        logging.warning(f"YouTube HTTP error: {ex}")
        return cached_val or None
    except Exception as ex:
        logging.warning(f"YouTube trailer fetch failed: {ex}")
        return cached_val or None

def safe_fetch_mdblist_ratings(kind: str, tmdb_id: str | None) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ä–µ–π—Ç–∏–Ω–≥–æ–≤. –°–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –∫—ç—à –∏–∑ –ë–î, –µ—Å–ª–∏ –æ–Ω —Å–≤–µ–∂–∏–π.
    –ï—Å–ª–∏ –∫—ç—à –ø—Ä–æ—Å—Ä–æ—á–µ–Ω ‚Äî –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å; –ø—Ä–∏ –æ—à–∏–±–∫–µ –æ—Ç–¥–∞—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ.
    kind: 'movie' | 'show'
    """
    if not tmdb_id:
        return ""
    # 1) —á–∏—Ç–∞–µ–º –∫—ç—à
    cached_val, cached_at = _extcache_read("ratings", kind, tmdb_id)
    if _is_fresh(cached_at, RATINGS_CACHE_TTL_DAYS) and cached_val:
        return cached_val

    # 2) –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑ —Å–µ—Ç–∏
    fresh = ""
    try:
        fresh = fetch_mdblist_ratings(kind, tmdb_id) or ""
    except Exception as ex:
        logging.warning(f"MDblist ratings fetch failed: {ex}")

    if fresh:
        _extcache_write("ratings", kind, tmdb_id, fresh)
        return fresh

    # 3) –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å ‚Äî –≤–µ—Ä–Ω—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ (–Ω–µ –ª–æ–º–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è)
    return cached_val or ""

#–†–∞–±–æ—Ç–∞ —Å —Å–µ–∑–æ–Ω–Ω—ã–º–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏
def jellyfin_count_present_episodes_in_season(season_id: str) -> int | None:
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ParentId": season_id,
            "IncludeItemTypes": "Episode",
            "Recursive": "false",
            "LocationTypes": "FileSystem",
            "IsMissing": "false",
            "Limit": "1",
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json() or {}
        cnt = data.get("TotalRecordCount")
        return int(cnt) if isinstance(cnt, int) else len(data.get("Items") or [])
    except requests.HTTPError as ex:
        status = getattr(getattr(ex, "response", None), "status_code", None)
        if status in (400, 404):
            # —Å–∏–≥–Ω–∞–ª ¬´—Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω¬ª
            return -1
        logging.warning(f"Failed to count PRESENT episodes for season {season_id}: {ex}")
        return None
    except Exception as ex:
        logging.warning(f"Failed to count PRESENT episodes for season {season_id}: {ex}")
        return None

def jellyfin_count_missing_episodes_in_season(season_id: str) -> int | None:
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ParentId": season_id,
            "IncludeItemTypes": "Episode",
            "Recursive": "false",
            "IsMissing": "true",
            "IsUnaired": "false",
            "IsVirtualUnaired": "false",
            "LocationTypes": "Virtual",
            "Limit": "1",
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json() or {}
        cnt = data.get("TotalRecordCount")
        return int(cnt) if isinstance(cnt, int) else len(data.get("Items") or [])
    except requests.HTTPError as ex:
        status = getattr(getattr(ex, "response", None), "status_code", None)
        if status in (400, 404):
            # —Å–∏–≥–Ω–∞–ª ¬´—Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω¬ª
            return -1
        logging.warning(f"Failed to count MISSING episodes for season {season_id}: {ex}")
        return None
    except Exception as ex:
        logging.warning(f"Failed to count MISSING episodes for season {season_id}: {ex}")
        return None

def jellyfin_get_season_counts_resilient(season_id: str) -> tuple[int, int] | tuple[int, int, bool]:
    attempts = max(int(os.getenv("SEASON_EP_COUNT_RETRY_ATTEMPTS", "5")), 1)
    delay = max(int(os.getenv("SEASON_EP_COUNT_RETRY_DELAY_SEC", "3")), 0)

    present, total = 0, 0
    for i in range(1, attempts + 1):
        p = jellyfin_count_present_episodes_in_season(season_id)
        if p == -1:
            # —Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω ‚Äî —á–∏—Å—Ç–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
            _sp_delete(season_id)
            logging.info(f"Season {season_id} removed from Jellyfin ‚Äî purged from DB.")
            return (-1, -1)  # —Å–∏–≥–Ω–∞–ª –Ω–∞–≤–µ—Ä—Ö

        m = jellyfin_count_missing_episodes_in_season(season_id)
        if m == -1:
            _sp_delete(season_id)
            logging.info(f"Season {season_id} removed from Jellyfin ‚Äî purged from DB.")
            return (-1, -1)

        if isinstance(p, int):
            present = p
        if isinstance(m, int):
            total = present + m
        else:
            total = present

        if total > 0 and (present > 0 or i == attempts):
            if i > 1:
                logging.debug(f"Season counts after {i} attempts: present={present}, total={total}")
            break
        time.sleep(delay)

    return (present, total)

def poll_recent_episodes_once():
    """
    –ò—â–µ–º —Å–≤–µ–∂–∏–µ —ç–ø–∏–∑–æ–¥—ã –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ, –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–µ–∑–æ–Ω—É –∏ —à–ª—ë–º –û–î–ù–û —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ ¬´–ù–æ–≤—ã–π —Å–µ–∑–æ–Ω: –¥–æ–±–∞–≤–ª–µ–Ω–æ N –∏–∑ M¬ª.
    –°–≤–µ–∂–∏–µ (–º–æ–ª–æ–∂–µ SERIES_POLL_GRACE_MIN) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –ø—É—Å—Ç—å –∏—Ö –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –≤–µ–±—Ö—É–∫.
    """
    page_size = SERIES_POLL_PAGE_SIZE
    max_total = SERIES_POLL_MAX_TOTAL or 0  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    processed_seasons: set[str] = set()

    while True:
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø—Ä–∏ max_total
        current_limit = page_size if (not max_total or (max_total - fetched) >= page_size) else (max_total - fetched)
        if current_limit <= 0:
            break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Episode",
                "Recursive": "true",
                "SortBy": "DateCreated,DateModified",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                "Fields": "ParentId,SeriesId,SeasonName,DateCreated,ProductionYear,Overview"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Series poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        # —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º —ç–ø–∏–∑–æ–¥—ã –ø–æ —Å–µ–∑–æ–Ω—É
        for ep in items:
            try:
                season_id = ep.get("ParentId") or ep.get("SeasonId")
                if not season_id or season_id in processed_seasons:
                    continue

                # –≥—Ä–µ–π—Å: –µ—Å–ª–∏ —ç–ø–∏–∑–æ–¥ —Å–æ–≤—Å–µ–º —Å–≤–µ–∂–∏–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–∑–æ–Ω, –ø—É—Å—Ç—å –≤–µ–±—Ö—É–∫ –æ–±—ä—è–≤–∏—Ç
                created_iso = ep.get("DateCreated")
                created_dt = _parse_iso_utc(created_iso) if ' _parse_iso_utc' in globals() else None
                if created_dt and (now_utc - created_dt) < timedelta(minutes=SERIES_POLL_GRACE_MIN):
                    logging.debug(f"Series poll: skip fresh season (ep created {created_dt.isoformat()}) season={season_id}")
                    continue

                # –ø–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ —Å–µ–∑–æ–Ω–∞/—Å–µ—Ä–∏–∞–ª–∞
                season_details = get_item_details(season_id)
                s_item = (season_details.get("Items") or [{}])[0]
                series_id = s_item.get("SeriesId")
                season_name = s_item.get("Name") or ep.get("SeasonName") or "Season"
                release_year = s_item.get("ProductionYear") or ep.get("ProductionYear")

                series_details = get_item_details(series_id) if series_id else {"Items": [{}]}
                series_item = (series_details.get("Items") or [{}])[0]
                series_name = series_item.get("Name") or ""
                overview_to_use = s_item.get("Overview") or series_item.get("Overview") or ""

                # –∞–Ω—Ç–∏—Å–ø–∞–º-–∫–ª—é—á, –∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ
                series_name_cleaned = series_name.replace(f" ({release_year})", "").strip()
                key_name = f"{series_name_cleaned} {season_name}".strip()

                if item_already_notified("Season", key_name, release_year):
                    processed_seasons.add(season_id)
                    continue

                # —Å—á–∏—Ç–∞–µ–º ¬´—Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å / —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ¬ª –ø–æ —Å–µ–∑–æ–Ω—É (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ–π resilient-—Ö–µ–ª–ø–µ—Ä)
                # –≤ poll_recent_episodes_once(), –ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ –ø–æ–¥—Å—á—ë—Ç–æ–º present/total:
                wait_until_scan_idle("season counts build")
                present, total = jellyfin_get_season_counts_resilient(season_id)
                # —Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if isinstance(present, int) and isinstance(total, int) and present == -1 and total == -1:
                    processed_seasons.add(season_id)
                    continue

                # --- –°—Ä–µ–∑ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î: baseline —Ç–æ–ª—å–∫–æ –û–î–ò–ù –†–ê–ó, –µ—Å–ª–∏ —Å–µ–∑–æ–Ω–∞ –µ—â—ë –Ω–µ—Ç –≤ –ë–î ---
                row_existing = _sp_get(season_id)
                if row_existing is None:
                    try:
                        db_created_iso = _db_get_created_at_iso()
                        db_created_dt = _parse_iso_dt(db_created_iso)

                        # DateCreated —É —Å–µ–∑–æ–Ω–∞ –±–µ—Ä—ë–º –∏–∑ —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ s_item; –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ—Ç ‚Äî –¥—ë—Ä–Ω–µ–º –¥–µ—Ç–∞–ª–∏
                        season_created_iso = s_item.get("DateCreated")
                        if not season_created_iso:
                            s_det_fallback = get_item_details(season_id)
                            season_created_iso = ((s_det_fallback.get("Items") or [{}])[0]).get("DateCreated")
                        season_created_dt = _parse_iso_dt(season_created_iso)

                        if db_created_dt and season_created_dt and (season_created_dt < db_created_dt):
                            # –°–µ–∑–æ–Ω –±—ã–ª –î–û —Å–æ–∑–¥–∞–Ω–∏—è –ë–î ‚Äî –ø–∏—à–µ–º baseline –∏ –ù–ï —à–ª—ë–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                            _sp_upsert(
                                season_id,
                                present=present, total=total,
                                series_id=series_id,
                                season_number=int(s_item.get("IndexNumber")) if s_item.get(
                                    "IndexNumber") is not None else None,
                                series_name=series_name_cleaned,
                                release_year=release_year,
                                mark_notified=True  # baseline: —Å—Ä–∞–∑—É —Å—á–∏—Ç–∞–µ–º ¬´–æ–±—ä—è–≤–ª–µ–Ω–Ω—ã–º¬ª
                            )
                            logging.info(
                                f"(Series poll) Season pre-DB cutoff baseline: {series_name_cleaned} {season_name} ‚Äî {present}/{total}")
                            processed_seasons.add(season_id)
                            continue
                    except Exception as ex:
                        logging.warning(f"Season cutoff check failed for {season_id}: {ex}")
                # --- –∫–æ–Ω–µ—Ü —Å—Ä–µ–∑–∞ ---

                # 1) —Å–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ¬ª (–±–µ–∑ mark_notified) ‚Äî —á—Ç–æ–±—ã –∏–º–µ—Ç—å –±–∞–∑—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–∞
                _sp_upsert(
                    season_id,
                    present=present, total=total,
                    series_id=series_id,
                    season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                    series_name=series_name_cleaned,
                    release_year=release_year,
                    mark_notified=False
                )

                # 2) —Ä–µ—à–∞–µ–º, –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ present –≤—ã—Ä–æ—Å —Å–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–æ—à–ª–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                if not _sp_should_notify(season_id, present):
                    processed_seasons.add(season_id)
                    continue
                # –º—ã —Ä–µ—à–∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å: —Å—Ä–∞–∑—É ¬´–∑–∞–∫—Ä—ã–≤–∞–µ–º¬ª —Å–µ–∑–æ–Ω –Ω–∞ —ç—Ç–æ—Ç –ø—Ä–æ–≥–æ–Ω,
                # —á—Ç–æ–±—ã —Å–ª–µ–¥—É—é—â–∏–µ —ç–ø–∏–∑–æ–¥—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª–∏ –≤–Ω–µ—à–Ω–∏–µ –≤—ã–∑–æ–≤—ã
                processed_seasons.add(season_id)

                # —Ä–µ–π—Ç–∏–Ω–≥–∏/—Ç—Ä–µ–π–ª–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                tmdb_id = jellyfin_get_tmdb_id(series_id) if 'jellyfin_get_tmdb_id' in globals() else None
                trailer_url = safe_get_trailer_prefer_tmdb(f"{series_name_cleaned} Trailer {release_year}",
                                subkind="show", tmdb_id=tmdb_id, context="")

                # 3) —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                notification_message = (
                    f"*{t('new_season_title')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n"
                    f"*{season_name}*"
                )
                if total >= present and total > 0:
                    notification_message += f"\n\n{t('season_added_progress').format(added=present, total=total)}"
                elif present > 0:
                    notification_message += f"\n\n{t('season_added_count_only').format(added=present)}"
                if overview_to_use:
                    notification_message += f"\n\n{overview_to_use}"
                if tmdb_id:
                    ratings_text = safe_fetch_mdblist_ratings("show", tmdb_id)
                    if ratings_text:
                        notification_message += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"
                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # ‚Üì‚Üì‚Üì –¥–æ–±–∞–≤–∏—Ç—å —ç—Ç–æ –∑–¥–µ—Å—å
                try:
                    res_label = _season_resolution_label(season_id)
                    if res_label:
                        L = _labels()
                        notification_message += f"\n\n*{L['resolution']}*\n{res_label}"
                except Exception as ex:
                    logging.debug(f"(Season) resolution block failed for {season_id}: {ex}")

                if INCLUDE_AUDIO_TRACKS:
                    tracks_block = build_audio_tracks_block_for_season(season_id)
                    if tracks_block:
                        notification_message += tracks_block

                # 4) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ–º ¬´–¥–æ –∫—É–¥–∞ —Å–æ–æ–±—â–∏–ª–∏¬ª
                if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                    send_notification(season_id, notification_message)
                else:
                    send_notification(series_id, notification_message)
                    logging.warning(
                        f"(Series poll) {series_name_cleaned} {season_name} image missing; using series image")

                # –ø–æ–º–µ—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å: —Ç–µ–ø–µ—Ä—å last_notified_present = present
                _sp_upsert(
                    season_id,
                    present=present, total=total,
                    series_id=series_id,
                    season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                    series_name=series_name_cleaned,
                    release_year=release_year,
                    mark_notified=True
                )

                logging.info(
                    f"(Series poll) Season announced: {series_name_cleaned} {season_name} ‚Äî {present} / {total}")
                processed_seasons.add(season_id)

            except Exception as ex:
                logging.warning(f"Series poll: season from ep {ep.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        logging.debug(f"Series poll: page fetched {n} episodes (total {fetched})")
        if n < current_limit:
            break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

    # <<< –î–û–ë–ê–í–ò–¢–¨ –í–û–¢ –ó–î–ï–°–¨ (—É–∫–∞–∑–∞—Ç—å —Ç–æ—Ç –∂–µ –æ—Ç—Å—Ç—É–ø, —á—Ç–æ –∏ —É while) >>>
    _meta_set('touched_series', '1')
    _maybe_send_onboarding_congrats()

def _series_poll_loop():
    while True:
        try:
            poll_recent_episodes_once()
        except Exception as ex:
            logging.warning(f"Series poll loop error: {ex}")
        time.sleep(SERIES_POLL_INTERVAL_SEC)

if SERIES_POLL_ENABLED:
    threading.Thread(target=_series_poll_loop, name="series-poll", daemon=True).start()
    logging.info(f"Series polling enabled every {SERIES_POLL_INTERVAL_SEC}s "
                 f"(page={SERIES_POLL_PAGE_SIZE}, max_total={SERIES_POLL_MAX_TOTAL}, grace={SERIES_POLL_GRACE_MIN}m)")


def _sq_get(season_id: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""
            SELECT season_id, series_id, series_name, season_number, release_year, signature, updated_at, episode_count
            FROM season_quality WHERE season_id=?""", (season_id,))
        row = cur.fetchone()
        if not row:
            return None
        return {
            "season_id": row[0],
            "series_id": row[1],
            "series_name": row[2],
            "season_number": row[3],
            "release_year": row[4],
            "signature": row[5],
            "updated_at": row[6],
            "episode_count": row[7],
        }
    except Exception as ex:
        logging.warning(f"_sq_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass


def _sq_upsert(season_id: str, *, signature: str,
               episode_count: int | None,
               series_id: str | None = None,
               series_name: str | None = None,
               season_number: int | None = None,
               release_year: int | None = None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')
        cur.execute("""
            INSERT INTO season_quality (season_id, series_id, series_name, season_number, release_year, signature, updated_at, episode_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ON CONFLICT(season_id) DO UPDATE SET
              signature=excluded.signature,
              updated_at=excluded.updated_at,
              episode_count=excluded.episode_count,
              series_id=COALESCE(excluded.series_id, season_quality.series_id),
              series_name=COALESCE(excluded.series_name, season_quality.series_name),
              season_number=COALESCE(excluded.season_number, season_quality.season_number),
              release_year=COALESCE(excluded.release_year, season_quality.release_year)
        """, (season_id, series_id, series_name, season_number, release_year, signature, nowz, episode_count))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sq_upsert failed: {ex}")
    finally:
        try: conn.close()
        except: pass


def _sp_get(season_id: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""
            SELECT season_id, series_id, series_name, season_number, release_year,
                   present, total, last_notified_present, updated_at
            FROM season_progress WHERE season_id=?""", (season_id,))
        row = cur.fetchone()
        if not row:
            return None
        return {
            "season_id": row[0], "series_id": row[1], "series_name": row[2],
            "season_number": row[3], "release_year": row[4],
            "present": row[5], "total": row[6],
            "last_notified_present": row[7], "updated_at": row[8],
        }
    except Exception as ex:
        logging.warning(f"_sp_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _sp_upsert(season_id: str, *, present: int, total: int,
               series_id: str | None = None, season_number: int | None = None,
               series_name: str | None = None, release_year: int | None = None,
               mark_notified: bool = False):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å —Å–µ–∑–æ–Ω–∞ –¢–û–õ–¨–ö–û –ø—Ä–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö.
    - –±–µ–∑ mark_notified: –æ–±–Ω–æ–≤–ª—è–µ–º, –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å present/total
    - —Å mark_notified: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–∏—à–µ–º last_notified_present=present (–µ—Å–ª–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è)
    –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –∏ ¬´–º–∏–≥–∞–Ω–∏–µ¬ª mtime —É —Ñ–∞–π–ª–∞ –ë–î.
    """
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')

        # —á–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        cur.execute("""
            SELECT present, total, last_notified_present
            FROM season_progress WHERE season_id=?
        """, (season_id,))
        row = cur.fetchone()

        if row:
            old_present, old_total, old_last = (row[0] or 0), (row[1] or 0), (row[2] or 0)

            # —Ä–µ—à–∞–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–∏—Å–∞—Ç—å
            need_update = False
            set_last = None

            if present != old_present or total != old_total:
                need_update = True
            if mark_notified and old_last != present:
                need_update = True
                set_last = present

            if not need_update:
                # –Ω–∏—á–µ–≥–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ‚Äî –≤—ã—Ö–æ–¥–∏–º –±–µ–∑ –∑–∞–ø–∏—Å–∏
                return

            if mark_notified:
                cur.execute("""
                    UPDATE season_progress
                    SET present=?, total=?, last_notified_present=?, updated_at=?,
                        series_id=COALESCE(?, series_id),
                        series_name=COALESCE(?, series_name),
                        season_number=COALESCE(?, season_number),
                        release_year=COALESCE(?, release_year)
                    WHERE season_id=?
                """, (present, total, (set_last if set_last is not None else old_last), nowz,
                      series_id, series_name, season_number, release_year, season_id))
            else:
                cur.execute("""
                    UPDATE season_progress
                    SET present=?, total=?, updated_at=?,
                        series_id=COALESCE(?, series_id),
                        series_name=COALESCE(?, series_name),
                        season_number=COALESCE(?, season_number),
                        release_year=COALESCE(?, release_year)
                    WHERE season_id=?
                """, (present, total, nowz,
                      series_id, series_name, season_number, release_year, season_id))
        else:
            # –ø–µ—Ä–≤–∞—è –∑–∞–ø–∏—Å—å –ø–æ —Å–µ–∑–æ–Ω—É
            cur.execute("""
                INSERT INTO season_progress (
                    season_id, series_id, series_name, season_number, release_year,
                    present, total, last_notified_present, updated_at
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (season_id, series_id, series_name, season_number, release_year,
                  int(present), int(total),
                  int(present) if mark_notified else 0,
                  nowz))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sp_upsert failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _sp_should_notify(season_id: str, present_now: int) -> bool:
    row = _sp_get(season_id)
    if row is None:
        # –≤–ø–µ—Ä–≤—ã–µ –≤–∏–¥–∏–º —Å–µ–∑–æ–Ω: —Å–ª–∞—Ç—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –∏ –µ—Å—Ç—å —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ
        return SERIES_POLL_INITIAL_ANNOUNCE and present_now > 0
    last = int(row.get("last_notified_present") or 0)
    return present_now > last

#–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–π–ª–µ—Ä–æ–≤ –∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
def _utcnow_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')

def _movie_announced_get(logical_key: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""SELECT logical_key, announced_at, item_id, movie_name, year
                       FROM movie_announced WHERE logical_key=?""", (logical_key,))
        row = cur.fetchone()
        if not row:
            return None
        return {
            "logical_key": row[0],
            "announced_at": row[1],
            "item_id": row[2],
            "movie_name": row[3],
            "year": row[4],
        }
    except Exception as ex:
        logging.debug(f"_movie_announced_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass


def _movie_announced_mark(logical_key: str, *, item_id: str | None, name: str | None, year: int | None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
        cur.execute("""
            INSERT INTO movie_announced (logical_key, announced_at, item_id, movie_name, year)
            VALUES (?, ?, ?, ?, ?)
            ON CONFLICT(logical_key) DO UPDATE SET
              announced_at = excluded.announced_at,
              item_id      = COALESCE(excluded.item_id, movie_announced.item_id),
              movie_name   = COALESCE(excluded.movie_name, movie_announced.movie_name),
              year         = COALESCE(excluded.year, movie_announced.year)
        """, (logical_key, nowz, item_id, name, year))
        conn.commit()
    except Exception as ex:
        logging.debug(f"_movie_announced_mark failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _extcache_key(kind: str, subkind: str | None, identity: str) -> str:
    # –ï–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–∞
    s = subkind or "-"
    return f"{kind}:{s}:{identity}".strip()

def _extcache_read(kind: str, subkind: str | None, identity: str) -> tuple[str | None, str | None]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (value, updated_at_iso) –∏–∑ external_cache –∏–ª–∏ (None, None).
    """
    if not EXTERNAL_CACHE_ENABLED:
        return (None, None)
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        ck = _extcache_key(kind, subkind, identity)
        cur.execute("SELECT value, updated_at FROM external_cache WHERE cache_key=?", (ck,))
        row = cur.fetchone()
        return (row[0], row[1]) if row else (None, None)
    except Exception as ex:
        logging.warning(f"_extcache_read fail: {ex}")
        return (None, None)
    finally:
        try: conn.close()
        except: pass

def _extcache_write(kind: str, subkind: str | None, identity: str, value: str | None):
    if not EXTERNAL_CACHE_ENABLED:
        return
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        ck = _extcache_key(kind, subkind, identity)
        cur.execute("""
            INSERT INTO external_cache (cache_key, kind, subkind, value, updated_at)
            VALUES (?, ?, ?, ?, ?)
            ON CONFLICT(cache_key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at
        """, (ck, kind, subkind or "", value or "", _utcnow_iso()))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_extcache_write fail: {ex}")
    finally:
        try: conn.close()
        except: pass

def _is_fresh(updated_iso: str | None, ttl_days: int) -> bool:
    if not updated_iso:
        return False
    try:
        dt = datetime.fromisoformat(updated_iso.replace('Z', '+00:00'))
        return datetime.now(timezone.utc) - dt <= timedelta(days=max(ttl_days, 0))
    except Exception:
        return False

#–ü–æ–∏—Å–∫ —Ç—Ä–µ–π–ª–µ—Ä–æ–≤ –Ω–∞ tmdb
def _tmdb_pick_best_video(results: list[dict]) -> str | None:
    """
    –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ç—Ä–µ–π–ª–µ—Ä –∏–∑ TMDB /videos.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: YouTube + type=Trailer + official=true ‚Üí YouTube + Trailer ‚Üí YouTube ‚Üí Vimeo.
    """
    if not results:
        return None

    def to_url(site: str | None, key: str | None) -> str | None:
        if not site or not key:
            return None
        s = site.lower()
        if s == "youtube":
            return f"https://www.youtube.com/watch?v={key}"
        if s == "vimeo":
            return f"https://vimeo.com/{key}"
        return None

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    vids = []
    for v in results:
        vids.append({
            "site": (v.get("site") or v.get("Site") or "").strip(),
            "type": (v.get("type") or v.get("Type") or "").strip(),
            "official": bool(v.get("official") if v.get("official") is not None else v.get("Official")),
            "key": v.get("key") or v.get("Key"),
            "size": v.get("size") or v.get("Size") or 0,
            "published_at": v.get("published_at") or v.get("PublishedAt") or "",
        })

    # 1) YouTube + Trailer + official
    for v in vids:
        if v["site"].lower() == "youtube" and v["type"].lower() == "trailer" and v["official"]:
            u = to_url(v["site"], v["key"])
            if u: return u
    # 2) YouTube + Trailer
    for v in vids:
        if v["site"].lower() == "youtube" and v["type"].lower() == "trailer":
            u = to_url(v["site"], v["key"])
            if u: return u
    # 3) –ª—é–±–æ–π YouTube
    for v in vids:
        if v["site"].lower() == "youtube":
            u = to_url(v["site"], v["key"])
            if u: return u
    # 4) Vimeo (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    for v in vids:
        if v["site"].lower() == "vimeo":
            u = to_url(v["site"], v["key"])
            if u: return u
    return None


def _tmdb_fetch_trailer_url(subkind: str, tmdb_id: str, season_number: int | None = None) -> str | None:
    """
    subkind: 'movie' | 'show'
    –î–ª—è —Ñ–∏–ª—å–º–æ–≤: /movie/{id}/videos
    –î–ª—è —Å–µ—Ä–∏–∞–ª–æ–≤: /tv/{id}/videos, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–±—É–µ–º /tv/{id}/season/{n}/videos
    """
    if not TMDB_API_KEY or not tmdb_id:
        return None
    try:
        params = {
            "api_key": TMDB_API_KEY,
            "language": TMDB_LANGUAGE,
            # –≤–∫–ª—é—á–∏—Ç—å —Ä–æ–ª–∏–∫–∏ –±–µ–∑ —è–∑—ã–∫–æ–≤–æ–π –º–µ—Ç–∫–∏
            "include_video_language": f"{TMDB_LANGUAGE},null"
        }
        if subkind == "movie":
            url = f"{TMDB_BASE}/movie/{tmdb_id}/videos"
            r = requests.get(url, params=params, timeout=10)
            r.raise_for_status()
            data = r.json() or {}
            return _tmdb_pick_best_video(data.get("results") or [])
        else:
            # –ø—Ä–æ–±—É–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–µ—Ä–∏–∞–ª–∞
            url = f"{TMDB_BASE}/tv/{tmdb_id}/videos"
            r = requests.get(url, params=params, timeout=10)
            r.raise_for_status()
            data = r.json() or {}
            url_pick = _tmdb_pick_best_video(data.get("results") or [])
            if url_pick:
                return url_pick
            # –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî —É—Ä–æ–≤–µ–Ω—å —Å–µ–∑–æ–Ω–∞
            if season_number is not None:
                url = f"{TMDB_BASE}/tv/{tmdb_id}/season/{int(season_number)}/videos"
                r = requests.get(url, params=params, timeout=10)
                r.raise_for_status()
                data = r.json() or {}
                return _tmdb_pick_best_video(data.get("results") or [])
            return None
    except Exception as ex:
        logging.warning(f"TMDB trailer fetch failed ({subkind}:{tmdb_id} s{season_number}): {ex}")
        return None

def safe_get_trailer_prefer_tmdb(
    title: str,
    *,
    year: int | None = None,
    subkind: str,                 # 'movie' | 'show'
    tmdb_id: str | None = None,
    season_number: int | None = None,
    context: str = ""
) -> str | None:
    """
    1) –ß–∏—Ç–∞–µ–º –∫—ç—à external_cache('trailer', subkind, identity) ‚Äî identity=tmdb_id –∏–ª–∏ title+year.
    2) –ï—Å–ª–∏ –∫—ç—à —Å–≤–µ–∂–∏–π ‚Äî –æ—Ç–¥–∞—ë–º.
    3) –ò–Ω–∞—á–µ –ø—Ä–æ–±—É–µ–º TMDB ‚Üí –µ—Å–ª–∏ –Ω–∞—à–ª–∏ ‚Äî –ø–∏—à–µ–º –≤ –∫—ç—à –∏ –æ—Ç–¥–∞—ë–º.
    4) –ò–Ω–∞—á–µ fallback: YouTube-–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ safe_get_trailer(query, ...), —Ç–æ–∂–µ –∫–ª–∞–¥—ë–º –≤ –∫—ç—à.
    """
    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º identity –∏ query –¥–ª—è –∫—ç—à–∞/—Ñ–æ–ª–ª–±—ç–∫–∞
    identity = (tmdb_id or "").strip() or f"{title.strip()} ({year})".strip()
    cached_val, cached_at = _extcache_read("trailer", subkind, identity)
    if _is_fresh(cached_at, TRAILER_CACHE_TTL_DAYS) and cached_val:
        return cached_val

    # 1) TMDB
    url_tmdb = None
    try:
        url_tmdb = _tmdb_fetch_trailer_url(subkind, tmdb_id, season_number) if tmdb_id else None
    except Exception as ex:
        logging.warning(f"safe_get_trailer_prefer_tmdb: TMDB branch failed: {ex}")

    if url_tmdb:
        _extcache_write("trailer", subkind, identity, url_tmdb)
        return url_tmdb

    # 2) Fallback: YouTube –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é + –≥–æ–¥—É
    q_year = f" {year}" if year else ""
    query = f"{title} Trailer{q_year}".strip()
    url_yt = safe_get_trailer(query, context=context, subkind=subkind, tmdb_id=tmdb_id)
    if url_yt:
        _extcache_write("trailer", subkind, identity, url_yt)
        return url_yt

    # 3) –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏: –≤–µ—Ä–Ω—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ, –µ—Å–ª–∏ –±—ã–ª–æ
    return cached_val or None

#–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤—ã—Ö –¥–æ—Ä–æ–∂–µ–∫ –¥–ª—è —Å–µ—Ä–∏–∞–ª–æ–≤
def _label_audio_stream(stream: dict) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é¬ª –ø–æ–¥–ø–∏—Å—å –¥–æ—Ä–æ–∂–∫–∏ –∫–∞–∫ –≤ —Ñ–∏–ª—å–º–∞—Ö:
    DisplayTitle/Title -> –∏–Ω–∞—á–µ LANG CODEC Ch Layout (–Ω–∞–ø—Ä–∏–º–µ—Ä: ENG AC3 6ch 5.1)
    """
    label = stream.get("DisplayTitle") or stream.get("Title")
    if label:
        return str(label)
    lang = stream.get("Language")
    codec = stream.get("Codec")
    ch = stream.get("Channels")
    layout = stream.get("ChannelLayout")
    parts = []
    if lang:   parts.append(str(lang).upper())
    if codec:  parts.append(str(codec).upper())
    if ch:     parts.append(f"{ch}ch")
    if layout: parts.append(str(layout))
    return " ".join(parts) or "Audio"

def _collect_season_audio_labels(season_id: str) -> list[str]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫ –∏–∑ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —ç–ø–∏–∑–æ–¥–æ–≤ —Å–µ–∑–æ–Ω–∞.
    –ë–µ—Ä—ë–º –Ω–µ –±–æ–ª–µ–µ SEASON_AUDIO_SCAN_LIMIT —ç–ø–∏–∑–æ–¥–æ–≤ –∏ –Ω–µ –±–æ–ª–µ–µ SEASON_AUDIO_TRACKS_MAX —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ—Ä–æ–∂–µ–∫.
    """
    labels_seen = []
    label_set = set()

    # –∑–∞–ø—Ä–æ—Å–∏–º —ç–ø–∏–∑–æ–¥—ã —Å–µ–∑–æ–Ω–∞ —Å MediaSources (–∫–∞–∫ —É —Ç–µ–±—è —É–∂–µ –¥–µ–ª–∞–µ—Ç—Å—è)
    eps = _season_fetch_episodes(season_id)  # –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å Items —Å MediaSources/LocationType/Path
    # —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ (–µ—Å—Ç—å —Ñ–∞–π–ª)
    present_eps = [ep for ep in eps if _episode_has_file(ep)]

    # –æ–≥—Ä–∞–Ω–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –ª–∏—à–Ω–µ–µ
    for ep in present_eps[:max(SEASON_AUDIO_SCAN_LIMIT, 1)]:
        sources = ep.get("MediaSources") or []
        if not sources:
            continue
        # –≤–æ–∑—å–º—ë–º –ø–µ—Ä–≤—É—é ¬´–æ—Å–Ω–æ–≤–Ω—É—é¬ª –¥–æ—Ä–æ–∂–∫—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        src = sources[0]
        for s in (src.get("MediaStreams") or []):
            if s.get("Type") != "Audio":
                continue
            lbl = _label_audio_stream(s)
            if lbl not in label_set:
                label_set.add(lbl)
                labels_seen.append(lbl)
                if len(labels_seen) >= SEASON_AUDIO_TRACKS_MAX:
                    return labels_seen
    return labels_seen

def _season_fetch_episodes(season_id: str, *, max_items: int | None = None) -> list[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —ç–ø–∏–∑–æ–¥–æ–≤ —Å–µ–∑–æ–Ω–∞ —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ:
    - –ë–µ—Ä—ë–º –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ø–∏–∑–æ–¥—ã (IsMissing=false, LocationTypes=FileSystem)
    - –¢—è–Ω–µ–º –ø–æ–ª—è MediaSources/LocationType/Path/IndexNumber/Name
    - –ü–∞–≥–∏–Ω–∞—Ü–∏—è –¥–æ max_items (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é SEASON_AUDIO_SCAN_LIMIT –∏–ª–∏ 50)
    """
    try:
        per_page = 200
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –æ–±—ä—ë–º: –Ω–∞–º –¥–ª—è —Å–ø–∏—Å–∫–∞ –¥–æ—Ä–æ–∂–µ–∫ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç—å —Å–µ–∑–æ–Ω–∞
        default_scan_limit = 50
        try:
            default_scan_limit = max(int(globals().get("SEASON_AUDIO_SCAN_LIMIT", 50)), 1)
        except Exception:
            pass
        cap = int(max_items) if isinstance(max_items, int) and max_items > 0 else default_scan_limit

        all_eps: list[dict] = []
        start = 0
        while True:
            # –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –±–æ–ª—å—à–µ, —á–µ–º –æ—Å—Ç–∞–ª–æ—Å—å –¥–æ cap
            limit = per_page if (len(all_eps) + per_page) <= cap else (cap - len(all_eps))
            if limit <= 0:
                break

            params = {
                "api_key": JELLYFIN_API_KEY,
                "ParentId": season_id,
                "IncludeItemTypes": "Episode",
                "Recursive": "false",
                # –∫–ª—é—á–µ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã: —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
                "IsMissing": "false",
                "LocationTypes": "FileSystem",
                # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —ç–ø–∏–∑–æ–¥–∞
                "SortBy": "IndexNumber,DateCreated",
                "SortOrder": "Ascending",
                "StartIndex": str(start),
                "Limit": str(limit),
                # –ø–æ–ª—è, –Ω—É–∂–Ω—ã–µ –¥–ª—è –∞—É–¥–∏–æ-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                "Fields": "MediaSources,LocationType,Path,IndexNumber,Name"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=12)
            r.raise_for_status()
            data = r.json() or {}
            items = data.get("Items") or []
            if not items:
                break

            all_eps.extend(items)
            start += len(items)
            if len(items) < limit:
                break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

        return all_eps
    except requests.HTTPError as ex:
        status = getattr(getattr(ex, "response", None), "status_code", None)
        if status in (400, 404):
            return []  # —Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω ‚Äî –º–æ–ª—á–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ
        logging.warning(f"_season_fetch_episodes failed (season {season_id}): {ex}")
        return []
    except Exception as ex:
        logging.warning(f"_season_fetch_episodes failed (season {season_id}): {ex}")
        return []


def _episode_has_file(ep: dict) -> bool:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —É —ç–ø–∏–∑–æ–¥–∞ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª.
    –ü—Ä–æ–≤–µ—Ä—è–µ–º:
      - LocationType == FileSystem/File (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
      - –∏–ª–∏ –∑–∞–¥–∞–Ω Path
      - –∏–ª–∏ –µ—Å—Ç—å MediaSources (–Ω–µ –ø—É—Å—Ç–æ) —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ —Ñ–∞–π–ª–∞
    """
    try:
        lt = (ep.get("LocationType") or "").strip().lower()
        if lt in ("filesystem", "file"):
            return True

        if ep.get("Path"):
            return True

        ms = ep.get("MediaSources") or []
        if ms:
            for src in ms:
                # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
                src_lt = (src.get("LocationType") or "").strip().lower()
                if src_lt in ("filesystem", "file"):
                    return True
                if src.get("Path"):
                    return True
                # –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞/—Ä–∞–∑–º–µ—Ä–∞ —á–∞—Å—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ
                if src.get("Container") or src.get("Size"):
                    return True
        return False
    except Exception:
        return False

def _plural_episodes(n: int, lang: str) -> str:
    lang = (lang or "").lower()
    if lang.startswith("ru"):
        n10, n100 = n % 10, n % 100
        if n10 == 1 and n100 != 11:
            return "—ç–ø–∏–∑–æ–¥"
        if 2 <= n10 <= 4 and not (12 <= n100 <= 14):
            return "—ç–ø–∏–∑–æ–¥–∞"
        return "—ç–ø–∏–∑–æ–¥–æ–≤"
    return "episode" if n == 1 else "episodes"

def _collect_season_audio_label_counts(season_id: str) -> tuple[OrderedDict[str, int], int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (OrderedDict[display_label -> count], present_episodes_count).
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –º–µ—Ç–∫–∏ –¥–æ—Ä–æ–∂–µ–∫ —Å —É—á—ë—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (_normalize_audio_label),
    —á—Ç–æ–±—ã 'HDRezka' –∏ 'HDrezka' —Å—á–∏—Ç–∞–ª–∏—Å—å –æ–¥–Ω–æ–π –¥–æ—Ä–æ–∂–∫–æ–π.
    """
    try:
        eps = _season_fetch_episodes(season_id)
        present_eps = [ep for ep in eps if _episode_has_file(ep)]
        scan_limit = max(int(globals().get("SEASON_AUDIO_SCAN_LIMIT", 50)), 1)

        # norm_label -> [display_label (–ø–µ—Ä–≤–∞—è –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω–∞—è), count]
        groups: dict[str, list] = {}

        for ep in present_eps[:scan_limit]:
            sources = ep.get("MediaSources") or []
            if not sources:
                continue
            src = sources[0]
            for s in (src.get("MediaStreams") or []):
                if s.get("Type") != "Audio":
                    continue
                raw_label = _label_audio_stream(s)
                norm = _normalize_audio_label(raw_label)
                if norm not in groups:
                    # —Å–æ—Ö—Ä–∞–Ω–∏–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—É—é –º–µ—Ç–∫—É ¬´–∫–∞–∫ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞—Å—å –≤–ø–µ—Ä–≤—ã–µ¬ª
                    groups[norm] = [raw_label.strip(), 1]
                else:
                    groups[norm][1] += 1

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—á—ë—Ç—á–∏–∫–∞, –∑–∞—Ç–µ–º –ø–æ –º–µ—Ç–∫–µ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π)
        sorted_items = sorted(groups.items(), key=lambda kv: (-kv[1][1], kv[0]))
        ordered = OrderedDict((disp, cnt) for (_norm, (disp, cnt)) in sorted_items)
        return ordered, len(present_eps)
    except Exception as ex:
        logging.warning(f"_collect_season_audio_label_counts failed for {season_id}: {ex}")
        return OrderedDict(), 0

def build_audio_tracks_block_for_season(season_id: str) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫ –¥–ª—è —Å–µ–∑–æ–Ω–∞ –≤ –≤–∏–¥–µ:
      *Audio tracks* (N)
      - RUS AC3 5.1 √ó 5 —ç–ø–∏–∑–æ–¥–æ–≤
      - ENG EAC3 6ch √ó 3 —ç–ø–∏–∑–æ–¥–∞
      ...
    """
    try:
        labels_counts, present_cnt = _collect_season_audio_label_counts(season_id)
        if not labels_counts:
            return ""

        lang = os.environ.get("LANGUAGE", "en")
        # –∑–∞–≥–æ–ª–æ–≤–æ–∫ (fallback, –µ—Å–ª–∏ –Ω–µ—Ç –∫–ª—é—á–∞ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏)
        header = (MESSAGES.get(LANG, {}) or {}).get("audio_tracks_header") or \
                 ( "–ê—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏" if lang.lower().startswith("ru") else "Audio tracks" )

        max_labels = max(int(globals().get("SEASON_AUDIO_TRACKS_MAX", 12)), 1)
        lines = [f"\n\n*{header}* ({min(len(labels_counts), max_labels)})"]

        i = 0
        for label, count in labels_counts.items():
            if i >= max_labels:
                break
            lines.append(f"- {label} √ó {count} {_plural_episodes(count, lang)}")
            i += 1

        return "\n".join(lines)
    except Exception as ex:
        logging.warning(f"Season audio block build failed for {season_id}: {ex}")
        return ""

def _normalize_audio_label(label: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –º–µ—Ç–∫—É –∫ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º—É –≤–∏–¥—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
    - casefold (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
    - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–∏—Ä–µ –∫ '-'
    - –µ–¥–∏–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–µ—Ñ–∏—Å–∞ –∏ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏
    """
    s = (label or "").strip()
    s = re.sub(r"[‚Äì‚Äî‚àí]", "-", s)              # –≤—Å–µ —Ç–∏—Ä–µ -> '-'
    s = re.sub(r"\s*-\s*", " - ", s)          # –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–µ—Ñ–∏—Å–∞
    s = re.sub(r"\s+", " ", s)                # —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø—Ä–æ–±–µ–ª—ã
    return s.casefold()                        # —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ

#–ö–æ–Ω—Ç—Ä–æ–ª—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è)
def _db_get_created_at_iso() -> str | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT value FROM app_meta WHERE key='db_created_at'")
        row = cur.fetchone()
        return row[0] if row else None
    except Exception as ex:
        logging.warning(f"db_created_at read failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _parse_iso_dt(s: str | None):
    if not s:
        return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00'))
    except Exception:
        return None

def _sp_delete(season_id: str):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("DELETE FROM season_progress WHERE season_id=?", (season_id,))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sp_delete failed for {season_id}: {ex}")
    finally:
        try: conn.close()
        except: pass

#–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–µ–∑–æ–Ω–æ–≤
def _episode_media_quality_signature_from_ep(ep: dict) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä—É –∫–∞—á–µ—Å—Ç–≤–∞ —ç–ø–∏–∑–æ–¥–∞ –ø–æ –ø–µ—Ä–≤–æ–º—É MediaSource (–±–µ–∑ —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤).
    """
    try:
        sources = ep.get("MediaSources") or []
        if not sources:
            return ""
        src = sources[0]
        streams = src.get("MediaStreams") or []

        v = next((s for s in streams if s.get("Type")=="Video"), None)
        a = next((s for s in streams if s.get("Type")=="Audio"), None)

        q = {}
        # –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä/—Ä–∞–∑–º–µ—Ä/–±–∏—Ç—Ä–µ–π—Ç
        q["container"] = (src.get("Container") or "").lower()
        try: q["size_bytes"] = int(src.get("Size") or 0)
        except Exception: q["size_bytes"] = 0
        try: q["video_bitrate_kbps"] = int((src.get("Bitrate") or 0)) // 1000
        except Exception: q["video_bitrate_kbps"] = None

        if v:
            q["video_codec"] = (v.get("Codec") or "").lower()
            q["width"]  = v.get("Width") or v.get("PixelWidth")
            q["height"] = v.get("Height") or v.get("PixelHeight")
            q["bit_depth"] = v.get("BitDepth")
            # fps
            fps = v.get("RealFrameRate") or v.get("AverageFrameRate") or v.get("FrameRate")
            try: q["fps"] = float(fps) if fps is not None else None
            except Exception: q["fps"] = None
            # –ø—Ä–æ—Ñ–∏–ª–∏ HDR/DV
            q["image_profiles"] = _detect_image_profiles_from_fields(v)

        if a:
            q["audio_codec"] = (a.get("Codec") or "").lower()
            try: q["audio_channels"] = int(a.get("Channels") or 0)
            except Exception: q["audio_channels"] = None
            try: q["audio_bitrate_kbps"] = int((a.get("BitRate") or 0)) // 1000
            except Exception: q["audio_bitrate_kbps"] = None

        sig = _quality_signature(q)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
        return sig or ""
    except Exception as ex:
        logging.debug(f"episode quality signature failed: {ex}")
        return ""

def _season_quality_signature(season_id: str, *, scan_limit: int | None = None) -> str:
    """
    –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ —Å–µ–∑–æ–Ω–∞ = sha1 –æ—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä —ç–ø–∏–∑–æ–¥–æ–≤ (—Å —Ñ–∞–π–ª–∞–º–∏).
    """
    eps = _season_fetch_episodes(season_id)
    present_eps = [ep for ep in eps if _episode_has_file(ep)]
    lim = max(int(globals().get("SEASON_QUALITY_SIG_LIMIT", 80)), 1)
    if scan_limit is not None:
        lim = max(int(scan_limit), 1)

    sigs = []
    for ep in present_eps[:lim]:
        s = _episode_media_quality_signature_from_ep(ep)
        if s:
            sigs.append(s)

    if not sigs:
        return ""

    sigs.sort()
    joined = "||".join(sigs).encode("utf-8", errors="ignore")
    return hashlib.sha1(joined).hexdigest()


def _season_quality_snapshot(season_id: str, *, scan_limit: int | None = None) -> tuple[str, int]:
    sig = _season_quality_signature(season_id, scan_limit=scan_limit)
    eps = _season_fetch_episodes(season_id)
    present = len([ep for ep in eps if _episode_has_file(ep)])
    return (sig, present)

def _notify_season_quality_updated(season_id: str):
    # –¥–µ—Ç–∞–ª–∏ —Å–µ–∑–æ–Ω–∞/—Å–µ—Ä–∏–∞–ª–∞
    season_details = get_item_details(season_id)
    s_item = (season_details.get("Items") or [{}])[0]
    series_id = s_item.get("SeriesId")
    season_name = s_item.get("Name") or "Season"
    release_year = s_item.get("ProductionYear")

    series_details = get_item_details(series_id) if series_id else {"Items":[{}]}
    series_item = (series_details.get("Items") or [{}])[0]
    series_name = series_item.get("Name") or ""
    overview = s_item.get("Overview") or series_item.get("Overview") or ""

    series_name_cleaned = series_name.replace(f" ({release_year})","").strip()

    # —Ä–µ–π—Ç–∏–Ω–≥–∏ + —Ç—Ä–µ–π–ª–µ—Ä
    tmdb_id = jellyfin_get_tmdb_id(series_id) if 'jellyfin_get_tmdb_id' in globals() else None
    trailer_url = safe_get_trailer_prefer_tmdb(f"{series_name_cleaned} Trailer {release_year}",
                                               subkind="show", tmdb_id=tmdb_id, context="")

    msg = f"*{t('quality_updated')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n*{season_name}*"
    if overview:
        msg += f"\n\n{overview}"
    if tmdb_id:
        ratings_text = safe_fetch_mdblist_ratings("show", tmdb_id)
        if ratings_text:
            msg += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"
    if trailer_url:
        msg += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

    try:
        res_label = _season_resolution_label(season_id)
        if res_label:
            L = _labels()
            msg += f"\n\n*{L['resolution']}*\n{res_label}"
    except Exception as ex:
        logging.debug(f"(Season) resolution block failed for {season_id}: {ex}")

    if INCLUDE_AUDIO_TRACKS:
        tracks_block = build_audio_tracks_block_for_season(season_id)
        if tracks_block:
            msg += tracks_block

    # –ø–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–æ—Å—Ç–µ—Ä —Å–µ—Ä–∏–∞–ª–∞
    if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
        send_notification(season_id, msg)
    else:
        send_notification(series_id, msg)
        logging.warning(f"(EpQuality poll) season image missing; used series image for {series_name_cleaned} {season_name}")

def _maybe_notify_season_quality_change(season_id: str) -> bool:
    # –¢–µ–∫—É—â–∏–π —Å–Ω–∏–º–æ–∫
    new_sig, new_count = _season_quality_snapshot(season_id)
    if not new_sig:
        return False  # –∂–¥—ë–º, –∫–æ–≥–¥–∞ Jellyfin –æ—Ç–¥–∞—Å—Ç MediaSources/—Ñ–∞–π–ª—ã

    row = _sq_get(season_id)
    if row is None:
        # Baseline: —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É –∏ count, –±–µ–∑ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        try:
            sd = get_item_details(season_id)
            s_item = (sd.get("Items") or [{}])[0]
            _sq_upsert(
                season_id,
                signature=new_sig,
                episode_count=new_count,
                series_id=s_item.get("SeriesId"),
                series_name=None,
                season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                release_year=s_item.get("ProductionYear"),
            )
        except Exception:
            _sq_upsert(season_id, signature=new_sig, episode_count=new_count)
        return False

    old_sig = row.get("signature") or ""
    old_count = row.get("episode_count")
    # 1) –ï—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å —á–∏—Å–ª–æ —ç–ø–∏–∑–æ–¥–æ–≤ –≤ —Å–µ–∑–æ–Ω–µ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º baseline –∏ –≤—ã—Ö–æ–¥–∏–º –ë–ï–ó —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
    if (old_count is None) or (old_count != new_count):
        _sq_upsert(season_id, signature=new_sig, episode_count=new_count)
        logging.info(f"(EpQuality) suppressed due to episode_count change: {old_count} -> {new_count} for season {season_id}")
        return False

    # 2) –ï—Å–ª–∏ —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å ‚Äî –≤—ã—Ö–æ–¥–∏–º
    if old_sig == new_sig:
        return False

    # 3) –ß–∏—Å—Ç–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–º —á–∏—Å–ª–µ —ç–ø–∏–∑–æ–¥–æ–≤ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    _notify_season_quality_updated(season_id)
    _sq_upsert(season_id, signature=new_sig, episode_count=new_count)
    return True

_last_epq_since = datetime.now(timezone.utc)

def poll_episode_quality_once():
    """
    –ò—â–µ–º —ç–ø–∏–∑–æ–¥—ã –ø–æ DateModified (—Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è), —Å–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–µ–∑–æ–Ω—ã,
    –∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∑–æ–Ω–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
    –ù–æ–≤—ã–µ (–æ—á–µ–Ω—å —Å–≤–µ–∂–∏–µ) —ç–ø–∏–∑–æ–¥—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –∏—Ö –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –≤–µ–±—Ö—É–∫/—Å–µ—Ä–∏–π–Ω—ã–π –ø–æ–ª–ª–µ—Ä.
    """
    page_size = EP_QUALITY_POLL_PAGE_SIZE
    max_total = EP_QUALITY_POLL_MAX_TOTAL or 0
    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)
    processed_seasons: set[str] = set()
    triggered = 0

    while True:
        current_limit = page_size if (not max_total or (max_total - fetched) >= page_size) else (max_total - fetched)
        if current_limit <= 0:
            break
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Episode",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                "Fields": "ParentId,DateCreated"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"EpQuality poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            season_id = it.get("ParentId") or it.get("SeasonId")
            if not season_id or season_id in processed_seasons:
                continue

            # –≥—Ä–µ–π—Å –¥–ª—è ¬´—Å–æ–≤—Å–µ–º –Ω–æ–≤—ã—Ö¬ª —ç–ø–∏–∑–æ–¥–æ–≤
            created_iso = it.get("DateCreated")
            created_dt = _parse_iso_utc(created_iso)
            if created_dt and (now_utc - created_dt) < timedelta(minutes=SERIES_POLL_GRACE_MIN):
                continue

            try:
                if _maybe_notify_season_quality_change(season_id):
                    triggered += 1
                processed_seasons.add(season_id)
            except Exception as ex:
                logging.warning(f"EpQuality poll: season {season_id} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        if n < current_limit:
            break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

    global _last_epq_since
#    logging.info(f"(EpQuality poll) processed={len(processed_seasons)}, triggered={triggered}, since={_last_epq_since.isoformat()}")
    _last_epq_since = now_utc

def _ep_quality_poll_loop():
    while True:
        try:
            poll_episode_quality_once()
        except Exception as ex:
            logging.warning(f"EpQuality poll loop error: {ex}")
        time.sleep(EP_QUALITY_POLL_INTERVAL_SEC)

if EP_QUALITY_POLL_ENABLED:
    threading.Thread(target=_ep_quality_poll_loop, name="ep-quality-poll", daemon=True).start()
    logging.info(f"Episode/Season quality polling enabled every {EP_QUALITY_POLL_INTERVAL_SEC}s "
                 f"(page={EP_QUALITY_POLL_PAGE_SIZE}, max_total={EP_QUALITY_POLL_MAX_TOTAL}, grace={SERIES_POLL_GRACE_MIN}m)")

#–û—Ç–ø—Ä–∞–≤–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–æ–≤—ã—Ö –∞–ª—å–±–æ–º–∞—Ö
def _album_announced_get(logical_key: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""SELECT logical_key, announced_at, item_id, album_name, artist_name, year
                       FROM album_announced WHERE logical_key=?""", (logical_key,))
        row = cur.fetchone()
        if not row:
            return None
        return {"logical_key": row[0], "announced_at": row[1], "item_id": row[2],
                "album_name": row[3], "artist_name": row[4], "year": row[5]}
    except Exception as ex:
        logging.debug(f"_album_announced_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _album_announced_mark(logical_key: str, *, item_id: str | None, album: str | None,
                          artist: str | None, year: int | None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
        cur.execute("""
            INSERT INTO album_announced (logical_key, announced_at, item_id, album_name, artist_name, year)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(logical_key) DO UPDATE SET
              announced_at = excluded.announced_at,
              item_id      = COALESCE(excluded.item_id, album_announced.item_id),
              album_name   = COALESCE(excluded.album_name, album_announced.album_name),
              artist_name  = COALESCE(excluded.artist_name, album_announced.artist_name),
              year         = COALESCE(excluded.year, album_announced.year)
        """, (logical_key, nowz, item_id, album, artist, year))
        conn.commit()
    except Exception as ex:
        logging.debug(f"_album_announced_mark failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _album_logical_key(*, musicbrainz_id: str | None, artist: str, album: str, year: int | None) -> str:
    if musicbrainz_id:
        return f"album:mb:{musicbrainz_id}"
    a = re.sub(r"\s+", " ", (artist or "").strip().lower())
    n = re.sub(r"\s+", " ", (album  or "").strip().lower())
    return f"album:nameyear:{a}‚Äì{n}:{year or ''}"

def poll_recent_albums_once():
    """
    –ü–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ç—è–Ω–µ–º MusicAlbum –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ –ù–û–í–´–• –∞–ª—å–±–æ–º–∞—Ö.
    –°–≤–µ–∂–∏–µ (–æ—á–µ–Ω—å –Ω–µ–¥–∞–≤–Ω–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ) –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å —á–µ—Ä–µ–∑ GRACE (—É –Ω–∞—Å –ø–æ-—É–º–æ–ª—á–∞–Ω–∏—é 0).
    """
    page_size = ALBUM_POLL_PAGE_SIZE
    max_total = ALBUM_POLL_MAX_TOTAL  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    while True:
        current_limit = page_size if not max_total else max(0, max_total - fetched)
        if current_limit == 0:
            break

        try:
            params = {
                'api_key': JELLYFIN_API_KEY,
                'IncludeItemTypes': 'MusicAlbum',
                'Recursive': 'true',
                'SortBy': 'DateModified,DateCreated',
                'SortOrder': 'Descending',
                'Limit': str(current_limit),
                'StartIndex': str(start),
                'Fields': 'ProviderIds,ProductionYear,Overview,DateCreated,RunTimeTicks,Artists,AlbumArtist',
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            items = (r.json() or {}).get('Items') or []
        except Exception as ex:
            logging.warning(f"Album poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            try:
                item_id = it.get('Id')
                album_name = (it.get('Name') or '').strip()
                year = it.get('ProductionYear')
                # artist: –ø—Ä–æ–±—É–µ–º AlbumArtist, –∑–∞—Ç–µ–º –ø–µ—Ä–≤—ã–π –∏–∑ Artists
                artist = (it.get('AlbumArtist') or '').strip()
                if not artist:
                    artists = it.get('Artists') or []
                    artist = (artists[0] if artists else '') or ''

                name_clean = re.sub(r"\s+", " ", album_name).strip()
                artist_clean = re.sub(r"\s+", " ", artist).strip()
                key_name = f"{artist_clean} ‚Äì {name_clean}".strip(" ‚Äì")

                prov = it.get('ProviderIds') or {}
                mb_id = prov.get('MusicBrainzAlbum')
                logical_key = _album_logical_key(musicbrainz_id=mb_id, artist=artist_clean, album=name_clean, year=year)

                # 1) –£–∂–µ –æ–±—ä—è–≤–ª–µ–Ω? ‚Äî –≤—ã—Ö–æ–¥–∏–º –º–æ–ª—á–∞
                if _album_announced_get(logical_key):
                    continue

                # GRACE: –æ—á–µ–Ω—å —Å–≤–µ–∂–∏–µ –ø—É—Å—Ç—å –ø—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –≤–∫–ª—é—á–∏–ª–∏
                created_iso = it.get('DateCreated')
                created_dt = _parse_iso_dt(created_iso)
                if ALBUM_POLL_GRACE_MIN and created_dt:
                    if (now_utc - created_dt).total_seconds() < ALBUM_POLL_GRACE_MIN * 60:
                        continue

                # --- –°—Ä–µ–∑ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î (–±–µ–∑ UnboundLocalError) ---
                db_created_iso = None
                db_created_dt = None

                try:
                    db_created_iso = _db_get_created_at_iso()
                    db_created_dt = _parse_iso_dt(db_created_iso)
                except Exception as ex:
                    logging.warning(f"Album cutoff: DB date parse failed for {item_id}: {ex}")

                try:
                    created_iso = it.get('DateCreated')  # –º–æ–∂–µ—Ç –±—ã—Ç—å None/–ø—É—Å—Ç–æ
                    created_dt = _parse_iso_dt(created_iso) if created_iso else None
                except Exception as ex:
                    logging.warning(f"Album cutoff: item date parse failed for {item_id}: {ex}")

                # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –ò –¢–û–õ–¨–ö–û –ó–î–ï–°–¨, —É–∂–µ –≤–Ω–µ try/except
                if db_created_dt and created_dt and (created_dt < db_created_dt):
                    _album_announced_mark(
                        logical_key,
                        item_id=item_id,
                        album=name_clean,
                        artist=artist_clean,
                        year=year
                    )
                    logging.debug(f"(Album poll) Pre-DB cutoff baseline set: {artist_clean} ‚Äì {name_clean} ({year})")
                    continue

                # –°–æ–æ–±—â–µ–Ω–∏–µ
                overview = it.get('Overview') or ''
                runtime = _format_runtime_from_ticks(it.get('RunTimeTicks')) if 'RunTimeTicks' in it else None
                prov = it.get('ProviderIds') or {}
                mb_id = prov.get('MusicBrainzAlbum')
                mb_link = f"https://musicbrainz.org/release/{mb_id}" if mb_id else ''

                title_line = _format_title_with_year(name_clean, year)

                notification_message = (
                    f"*{t('new_album_title')}*\n\n"
                    f"*{artist_clean}*\n\n"
                    f"*{title_line}*\n\n"
                    f"{(overview + '\n\n') if overview else ''}"
                )
                if runtime:
                    notification_message += f"*{t('new_runtime')}*\n{runtime}\n\n"

                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–∫–æ–≤
                tracks = jellyfin_count_tracks_in_album(item_id)
                if tracks is not None:
                    notification_message += f"*{t('new_track_count')}*\n{tracks}\n\n"

                # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤ (—Ç–æ—á–Ω—ã–π —Ä–∞—Å—á—ë—Ç ¬´—Å–∫–æ–ª—å–∫–æ –Ω–µ –ø–æ–∫–∞–∑–∞–ª–∏¬ª)
                if ALBUM_TRACKLIST_ENABLED:
                    try:
                        # –í–ê–ñ–ù–û: –±–µ—Ä—ë–º —Ä–æ–≤–Ω–æ –ª–∏–º–∏—Ç ‚Äî –±–µ–∑ +1
                        raw_tracks = jellyfin_list_tracks_in_album(item_id, limit=ALBUM_TRACKLIST_LIMIT)
                        if raw_tracks:
                            lines = []
                            for i, tr in enumerate(raw_tracks, 1):
                                idx = tr.get("IndexNumber") or i
                                title = tr.get("Name") or f"Track {i}"
                                if ALBUM_TRACKLIST_SHOW_DURATION:
                                    dur = _format_runtime_from_ticks(
                                        tr.get("RunTimeTicks")) if "RunTimeTicks" in tr else None
                                else:
                                    dur = None
                                line = f"{idx:02d}. {title}" + (f" ‚Äî {dur}" if dur else "")
                                lines.append(line)

                            if lines:
                                notification_message += f"*{t('album_tracklist')}*\n\n" + "\n".join(lines) + "\n"

                            # tracks ‚Äî —ç—Ç–æ –û–ë–©–ï–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —É–∂–µ –ø–æ–ª—É—á–µ–Ω–æ –≤—ã—à–µ —á–µ—Ä–µ–∑ jellyfin_count_tracks_in_album(item_id)
                            displayed = len(lines)
                            if isinstance(tracks, int):
                                remaining = max(0, tracks - displayed)
                                if remaining > 0:
                                    more_tpl = t('album_tracklist_more')  # —Å–æ–¥–µ—Ä–∂–∏—Ç {n}
                                    notification_message += more_tpl.replace("{n}", str(remaining)) + "\n"

                            notification_message += "\n"
                    except Exception as ex:
                        logging.warning(f"Album tracklist render failed for {item_id}: {ex}")

                if mb_link:
                    notification_message += f"[MusicBrainz]({mb_link})\n"

                send_notification(item_id, notification_message)
                _album_announced_mark(
                    logical_key,
                    item_id=item_id,
                    album=name_clean,
                    artist=artist_clean,
                    year=year
                )
                logging.info(f"(Album poll) NEW album: {artist_clean} ‚Äì {name_clean} ({year})")
            except Exception as ex:
                logging.warning(f"Album poll: item {it.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        if max_total and fetched >= max_total:
            break
        if n < current_limit:
            break

    _meta_set('touched_albums', '1')
    _maybe_send_onboarding_congrats()

def _album_poll_loop():
    while True:
        try:
            wait_until_scan_idle("album poll")
            poll_recent_albums_once()
        except Exception as ex:
            logging.warning(f"Album poll loop error: {ex}")
        time.sleep(ALBUM_POLL_INTERVAL_SEC)

if ALBUM_POLL_ENABLED:
    threading.Thread(target=_album_poll_loop, name="album-poll", daemon=True).start()
    logging.info(f"Album polling enabled every {ALBUM_POLL_INTERVAL_SEC}s "
                 f"(page={ALBUM_POLL_PAGE_SIZE}, max_total={ALBUM_POLL_MAX_TOTAL}, grace={ALBUM_POLL_GRACE_MIN}m)")

#–û—Ç–ø—Ä–∞–≤–∫–∞ –∫–Ω–∏–≥
def _book_announced_get(logical_key: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""SELECT logical_key, announced_at, item_id, title, authors, year
                       FROM book_announced WHERE logical_key=?""", (logical_key,))
        row = cur.fetchone()
        if not row:
            return None
        return {"logical_key": row[0], "announced_at": row[1], "item_id": row[2],
                "title": row[3], "authors": row[4], "year": row[5]}
    except Exception as ex:
        logging.debug(f"_book_announced_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _book_announced_mark(logical_key: str, *, item_id: str | None, title: str | None,
                         authors: str | None, year: int | None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
        cur.execute("""
            INSERT INTO book_announced (logical_key, announced_at, item_id, title, authors, year)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(logical_key) DO UPDATE SET
              announced_at = excluded.announced_at,
              item_id      = COALESCE(excluded.item_id, book_announced.item_id),
              title        = COALESCE(excluded.title, book_announced.title),
              authors      = COALESCE(excluded.authors, book_announced.authors),
              year         = COALESCE(excluded.year, book_announced.year)
        """, (logical_key, nowz, item_id, title, authors, year))
        conn.commit()
    except Exception as ex:
        logging.debug(f"_book_announced_mark failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _book_logical_key(*, isbn: str | None, title: str, authors: str, year: int | None) -> str:
    if isbn:
        return f"book:isbn:{isbn.strip()}"
    a = re.sub(r"\s+", " ", (authors or "").strip().lower())
    t = re.sub(r"\s+", " ", (title   or "").strip().lower())
    return f"book:titleauthoryear:{t}‚Äì{a}:{year or ''}"

def _extract_book_authors(it: dict) -> list[str]:
    ppl = it.get("People") or []
    authors = [p.get("Name") for p in ppl if (p.get("Type") or "").lower() == "author" and p.get("Name")]
    if not authors:
        authors = [p.get("Name") for p in ppl if p.get("Name")]
    # –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –ø—É—Å—Ç–æ ‚Äî –≤–µ—Ä–Ω—ë–º []
    return [a for a in authors if a]

def _extract_isbn(it: dict) -> str | None:
    prov = it.get("ProviderIds") or {}
    # –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ä–∞–∑–Ω—ã–µ –∫–ª—é—á–∏, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ
    for k in ("Isbn", "ISBN", "Isbn13", "ISBN13"):
        if prov.get(k):
            return str(prov[k]).strip()
    return None

def poll_recent_books_once():
    """
    –ò—â–µ–º –Ω–æ–≤—ã–µ Book/AudioBook –≤ Jellyfin –∏ —à–ª—ë–º –û–î–ù–û —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –∫–Ω–∏–≥—É/–∞—É–¥–∏–æ–∫–Ω–∏–≥—É.
    –î–ª—è –∞—É–¥–∏–æ–∫–Ω–∏–≥ —á–∞—Å—Ç–∏ –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è: ¬´‚Ä¶ –ß–∞—Å—Ç—å 1‚Äì3¬ª. –î–µ–¥—É–ø ‚Äî –≤ —Ç–∞–±–ª–∏—Ü–µ book_announced.
    –ó–∞–≥–æ–ª–æ–≤–æ–∫:
      - –æ–±—ã—á–Ω–∞—è –∫–Ω–∏–≥–∞:   t('new_book_header')      => ¬´–ù–æ–≤–∞—è –∫–Ω–∏–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞¬ª
      - –∞—É–¥–∏–æ–∫–Ω–∏–≥–∞:      t('new_audiobook_header') => ¬´–ù–æ–≤–∞—è –∞—É–¥–∏–æ–∫–Ω–∏–≥–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞¬ª
    """
    page_size = BOOK_POLL_PAGE_SIZE
    max_total = BOOK_POLL_MAX_TOTAL  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    # –ö–æ–ø–∏–º –≥—Ä—É–ø–ø—ã –Ω–∞ –≤–µ—Å—å –ø—Ä–æ—Ö–æ–¥ (–æ–±—ä–µ–¥–∏–Ω–∏–º —á–∞—Å—Ç–∏, –ø—Ä–∏—à–µ–¥—à–∏–µ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ö)
    groups: dict[str, dict] = {}  # logical_key -> –∞–≥—Ä–µ–≥–∞—Ç

    while True:
        current_limit = page_size if not max_total else max(0, max_total - fetched)
        if current_limit == 0:
            break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Book,AudioBook",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                # –≤–∞–∂–Ω–æ: People/ProviderIds/DateCreated/Overview
                "Fields": "People,ProviderIds,ProductionYear,Overview,DateCreated",
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            items = (r.json() or {}).get("Items") or []
        except Exception as ex:
            logging.warning(f"Book poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            try:
                item_id = it.get("Id")
                raw_title = (it.get("Name") or "").strip()
                year = it.get("ProductionYear")
                overview = (it.get("Overview") or "").strip()

                # –ê–≤—Ç–æ—Ä—ã / ISBN
                authors_list = _extract_book_authors(it)
                authors = ", ".join(a for a in authors_list if a) if authors_list else ""
                isbn = _extract_isbn(it)

                title_clean = re.sub(r"\s+", " ", raw_title).strip()
                authors_clean = re.sub(r"\s+", " ", authors).strip()

                media_type = (it.get("Type") or "").lower()
                if media_type == "audiobook":
                    base_title, part_num, part_label = _strip_book_part_suffix(title_clean)
                else:
                    base_title, part_num, part_label = title_clean, None, None

                # –õ–æ–≥–∏—á–µ—Å–∫–∏–π –∫–ª—é—á (–ø–æ ISBN, –∏–Ω–∞—á–µ title+authors+year; –¥–ª—è –∞—É–¥–∏–æ–∫–Ω–∏–≥ ‚Äî –ë–ï–ó –Ω–æ–º–µ—Ä–∞ —á–∞—Å—Ç–∏)
                logical_key = _book_logical_key(
                    isbn=isbn,
                    title=base_title,
                    authors=authors_clean,
                    year=year,
                )

                # –£–∂–µ –æ–±—ä—è–≤–ª—è–ª–∏? ‚Äî –º–æ–ª—á–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if _book_announced_get(logical_key):
                    continue

                # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ
                created_iso = it.get("DateCreated")
                created_dt = None
                db_created_dt = None
                try:
                    created_dt = _parse_iso_dt(created_iso) if created_iso else None
                except Exception as ex:
                    logging.debug(f"Book cutoff: item date parse failed for {item_id}: {ex}")
                try:
                    db_created_iso = _db_get_created_at_iso()
                    db_created_dt = _parse_iso_dt(db_created_iso)
                except Exception as ex:
                    logging.debug(f"Book cutoff: DB date parse failed: {ex}")

                # Pre-DB cutoff ‚Üí baseline –≤ –ë–î
                if db_created_dt and created_dt and (created_dt < db_created_dt):
                    _book_announced_mark(
                        logical_key,
                        item_id=item_id,
                        title=base_title,
                        authors=authors_clean,
                        year=year,
                    )
                    logging.debug(f"(Book poll) Pre-DB baseline set: {authors_clean} ‚Äì {base_title} ({year})")
                    continue

                # GRACE (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)
                if BOOK_POLL_GRACE_MIN and created_dt:
                    if (now_utc - created_dt).total_seconds() < BOOK_POLL_GRACE_MIN * 60:
                        continue

                # –ö–æ–ø–∏–º –≤ –≥—Ä—É–ø–ø—É (–æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –∫–Ω–∏–≥—É/–∞—É–¥–∏–æ–∫–Ω–∏–≥—É)
                g = groups.setdefault(
                    logical_key,
                    {
                        "item_ids": [],
                        "base_title": base_title,
                        "authors": authors_clean,
                        "year": year,
                        "parts": [],
                        "label": part_label,
                        "overview": "",
                        "isbn": isbn,
                        "is_audiobook": (media_type == "audiobook"),
                    },
                )
                g["item_ids"].append(item_id)
                if overview and not g["overview"]:
                    g["overview"] = overview
                if isinstance(part_num, int):
                    g["parts"].append(part_num)
                # –µ—Å–ª–∏ —É –∫–∞–∫–æ–≥–æ-—Ç–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –Ω–µ—Ç ISBN, –∞ —É –¥—Ä—É–≥–æ–≥–æ –µ—Å—Ç—å ‚Äî —Å–æ—Ö—Ä–∞–Ω–∏–º –∏–º–µ—é—â–∏–π—Å—è
                if not g["isbn"] and isbn:
                    g["isbn"] = isbn
                # –µ—Å–ª–∏ –≤ –≥—Ä—É–ø–ø–µ —Å–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã (–Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π)
                g["is_audiobook"] = g.get("is_audiobook") or (media_type == "audiobook")

            except Exception as ex:
                logging.warning(f"Book poll: item {it.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        if max_total and fetched >= max_total:
            break
        if n < current_limit:
            break

    _meta_set('touched_books', '1')
    _maybe_send_onboarding_congrats()


    # ---- –°–ë–†–û–° –ì–†–£–ü–ü: –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ –∫–Ω–∏–≥—É/–∞—É–¥–∏–æ–∫–Ω–∏–≥—É ----
    for lk, g in groups.items():
        title_for_msg = g["base_title"]
        if g["parts"]:
            rng = _format_number_ranges(g["parts"])
            if rng:
                label = g["label"] or "–ß–∞—Å—Ç—å"
                title_for_msg = f"{title_for_msg}. {label} {rng}"

        title_line = _format_title_with_year(title_for_msg, g["year"])
        header_key = "new_audiobook_header" if g.get("is_audiobook") else "new_book_header"

        msg = (
            f"*{t(header_key)}*\n\n"
            f"*{title_line}*\n"
        )
        if g["authors"]:
            msg += f"\n*{t('new_authors')}*\n{g['authors']}\n"
        if g["isbn"]:
            msg += f"\n*{t('new_isbn')}*\n{g['isbn']}\n"
        if g["overview"]:
            msg += f"\n{g['overview']}\n"

        first_id = (g["item_ids"][0] if g["item_ids"] else None) or "books"
        send_notification(first_id, msg)

        _book_announced_mark(
            lk,
            item_id=first_id,
            title=g["base_title"],
            authors=g["authors"],
            year=g["year"],
        )
        logging.info(f"(Book poll) NEW book group: {g['authors']} ‚Äì {title_for_msg} ({g['year']})")



def _book_poll_loop():
    while True:
        try:
            wait_until_scan_idle("book poll")
            poll_recent_books_once()
        except Exception as ex:
            logging.warning(f"Book poll loop error: {ex}")
        time.sleep(BOOK_POLL_INTERVAL_SEC)

if BOOK_POLL_ENABLED:
    threading.Thread(target=_book_poll_loop, name="book-poll", daemon=True).start()
    logging.info(f"Book polling enabled every {BOOK_POLL_INTERVAL_SEC}s "
                 f"(page={BOOK_POLL_PAGE_SIZE}, max_total={BOOK_POLL_MAX_TOTAL}, grace={BOOK_POLL_GRACE_MIN}m)")

# --- –ì–†–£–ü–ü–ò–†–û–í–ö–ê –ß–ê–°–¢–ï–ô –ê–£–î–ò–û–ö–ù–ò–ì ---
_ROMAN_MAP = {"I":1,"V":5,"X":10,"L":50,"C":100,"D":500,"M":1000}

def _roman_to_int(s: str) -> int:
    s = s.upper()
    total = 0
    prev = 0
    for ch in reversed(s):
        val = _ROMAN_MAP.get(ch, 0)
        if val < prev:
            total -= val
        else:
            total += val
            prev = val
    return total

# –ø–∞—Ç—Ç–µ—Ä–Ω: ... "–ß–∞—Å—Ç—å 1", "Part II", "–¢–æ–º 3", "–ö–Ω–∏–≥–∞ 01", "Disc 2", "CD 3", "–°–µ—Ä–∏—è 4" –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
_PART_SUFFIX_RX = re.compile(r"""(?ix)
    ^\s*
    (?P<base>.*?)
    (?:[\s\.\-‚Äì‚Äî,:]*)?
    (?:
        (?P<label>—á–∞—Å—Ç(?:—å|–∏)|—Ç–æ–º|–∫–Ω–∏–≥–∞|part|disc|cd|—Å–µ—Ä–∏—è)
        \s*
        (?P<num>[IVXLCM]+|\d+)
    )
    \s*$
""")

def _strip_book_part_suffix(title: str) -> tuple[str, int|None, str|None]:
    m = _PART_SUFFIX_RX.match(title or "")
    if not m:
        return (title or "").strip(), None, None
    base = (m.group("base") or "").strip().rstrip(" .‚Äì‚Äî-,:")
    raw_label = (m.group("label") or "").lower()
    if "—á–∞—Å—Ç" in raw_label: label = "–ß–∞—Å—Ç—å"
    elif "—Ç–æ–º" in raw_label: label = "–¢–æ–º"
    elif "–∫–Ω–∏–≥–∞" in raw_label: label = "–ö–Ω–∏–≥–∞"
    elif "—Å–µ—Ä" in raw_label: label = "–°–µ—Ä–∏—è"
    else: label = "Part"
    num_s = (m.group("num") or "").strip().upper()
    num = _roman_to_int(num_s) if re.fullmatch(r"[IVXLCM]+", num_s) else (int(num_s) if num_s.isdigit() else None)
    return base, num, label

def _format_number_ranges(nums: list[int]) -> str:
    if not nums: return ""
    xs = sorted(set(int(n) for n in nums if isinstance(n, int)))
    if not xs: return ""
    ranges = []
    a = b = xs[0]
    for n in xs[1:]:
        if n == b + 1:
            b = n
        else:
            ranges.append((a, b))
            a = b = n
    ranges.append((a, b))
    parts = [f"{i}" if i==j else f"{i}-{j}" for i, j in ranges]
    return ", ".join(parts)

#–†–∞–±–æ—Ç–∞ —Å –º—É–∑—ã–∫–∞–ª—å–Ω—ã–º–∏ –≤–∏–¥–µ–æ
def _musicvideo_announced_get(logical_key: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""SELECT logical_key, announced_at, item_id, title, artist, year
                       FROM musicvideo_announced WHERE logical_key=?""", (logical_key,))
        row = cur.fetchone()
        if not row:
            return None
        return {"logical_key": row[0], "announced_at": row[1], "item_id": row[2],
                "title": row[3], "artist": row[4], "year": row[5]}
    except Exception as ex:
        logging.debug(f"_musicvideo_announced_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _musicvideo_announced_mark(logical_key: str, *, item_id: str | None,
                               title: str | None, artist: str | None, year: int | None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')
        cur.execute("""
            INSERT INTO musicvideo_announced (logical_key, announced_at, item_id, title, artist, year)
            VALUES (?, ?, ?, ?, ?, ?)
            ON CONFLICT(logical_key) DO UPDATE SET
              announced_at = excluded.announced_at,
              item_id      = COALESCE(excluded.item_id, musicvideo_announced.item_id),
              title        = COALESCE(excluded.title, musicvideo_announced.title),
              artist       = COALESCE(excluded.artist, musicvideo_announced.artist),
              year         = COALESCE(excluded.year, musicvideo_announced.year)
        """, (logical_key, nowz, item_id, title, artist, year))
        conn.commit()
    except Exception as ex:
        logging.debug(f"_musicvideo_announced_mark failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _musicvideo_logical_key(*, artist: str, title: str, year: int | None) -> str:
    a = re.sub(r"\s+", " ", (artist or "").strip().lower())
    t = re.sub(r"\s+", " ", (title  or "").strip().lower())
    return f"mvid:{a}‚Äì{t}:{year or ''}"

def poll_recent_musicvideos_once():
    """
    –ò—â–µ–º –Ω–æ–≤—ã–µ –∫–ª–∏–ø—ã (MusicVideo) –≤ Jellyfin –∏ —à–ª—ë–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è.
    –î–µ–¥—É–ø ‚Äî –≤ —Ç–∞–±–ª–∏—Ü–µ musicvideo_announced. Pre-DB cutoff ‚Äî baseline –≤ –ë–î.
    """
    page_size = MVID_POLL_PAGE_SIZE
    max_total = MVID_POLL_MAX_TOTAL  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    while True:
        current_limit = page_size if not max_total else max(0, max_total - fetched)
        if current_limit == 0:
            break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "MusicVideo",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                # –ü–æ–ª–µ–∑–Ω—ã–µ –ø–æ–ª—è –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è/–ª–æ–≥–∏–∫–∏:
                "Fields": "Artists,Album,ProviderIds,ProductionYear,Overview,DateCreated,RunTimeTicks"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            items = (r.json() or {}).get("Items") or []
        except Exception as ex:
            logging.warning(f"MusicVideo poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            try:
                item_id = it.get("Id")
                title = (it.get("Name") or "").strip()
                year = it.get("ProductionYear")
                overview = (it.get("Overview") or "").strip()

                # –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å
                artists = it.get("Artists") or []
                artist = (artists[0] if artists else "") or ""
                artist_clean = re.sub(r"\s+", " ", artist).strip()

                title_clean = re.sub(r"\s+", " ", title).strip()

                # –õ–æ–≥–∏—á–µ—Å–∫–∏–π –∫–ª—é—á
                logical_key = _musicvideo_logical_key(
                    artist=artist_clean,
                    title=title_clean,
                    year=year
                )

                # –£–∂–µ –æ–±—ä—è–≤–ª—è–ª–∏? ‚Äî –º–æ–ª—á–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if _musicvideo_announced_get(logical_key):
                    continue

                # –î–∞—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ
                created_iso = it.get("DateCreated")
                created_dt = None
                db_created_dt = None
                try:
                    created_dt = _parse_iso_dt(created_iso) if created_iso else None
                except Exception as ex:
                    logging.debug(f"MVID cutoff: item date parse failed for {item_id}: {ex}")
                try:
                    db_created_iso = _db_get_created_at_iso()
                    db_created_dt = _parse_iso_dt(db_created_iso)
                except Exception as ex:
                    logging.debug(f"MVID cutoff: DB date parse failed: {ex}")

                # Pre-DB cutoff ‚Üí baseline –≤ –ë–î (–Ω–µ —Å–ø–∞–º–∏–º)
                if db_created_dt and created_dt and (created_dt < db_created_dt):
                    _musicvideo_announced_mark(
                        logical_key,
                        item_id=item_id,
                        title=title_clean,
                        artist=artist_clean,
                        year=year
                    )
                    logging.debug(f"(MusicVideo poll) Pre-DB baseline set: {artist_clean} ‚Äì {title_clean} ({year})")
                    continue

                # GRACE (–µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)
                if MVID_POLL_GRACE_MIN and created_dt:
                    if (now_utc - created_dt).total_seconds() < MVID_POLL_GRACE_MIN * 60:
                        continue

                # –ê–ª—å–±–æ–º –∫–ª–∏–ø–∞ (–µ—Å–ª–∏ Jellyfin –æ—Ç–¥–∞–ª)
                album = (it.get("Album") or "").strip()

                # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                runtime = _format_runtime_from_ticks(it.get("RunTimeTicks")) if "RunTimeTicks" in it else None

                # –°–æ–æ–±—â–µ–Ω–∏–µ
                title_line = _format_title_with_year(title_clean, year)
                msg = (
                    f"*{t('new_musicvideo_header')}*\n\n"
                )
                if artist_clean:
                    msg += f"*{t('new_musicvideo_artist')}*\n{artist_clean}\n\n"
                msg += f"*{title_line}*\n\n"
                if album:
                    msg += f"*{t('new_musicvideo_album')}*\n{album}\n\n"
                if runtime:
                    msg += f"*{t('new_runtime')}*\n{runtime}\n\n"
                if overview:
                    msg += f"{overview}\n"

                send_notification(item_id, msg)

                _musicvideo_announced_mark(
                    logical_key,
                    item_id=item_id,
                    title=title_clean,
                    artist=artist_clean,
                    year=year
                )
                logging.info(f"(MusicVideo poll) NEW clip: {artist_clean} ‚Äì {title_clean} ({year})")
            except Exception as ex:
                logging.warning(f"MusicVideo poll: item {it.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        if max_total and fetched >= max_total:
            break
        if n < current_limit:
            break

    _meta_set('touched_mvids', '1')
    _maybe_send_onboarding_congrats()

def _musicvideo_poll_loop():
    while True:
        try:
            wait_until_scan_idle("musicvideo poll")
            poll_recent_musicvideos_once()
        except Exception as ex:
            logging.warning(f"MusicVideo poll loop error: {ex}")
        time.sleep(MVID_POLL_INTERVAL_SEC)

if MVID_POLL_ENABLED:
    threading.Thread(target=_musicvideo_poll_loop, name="mvid-poll", daemon=True).start()
    logging.info(f"MusicVideo polling enabled every {MVID_POLL_INTERVAL_SEC}s "
                 f"(page={MVID_POLL_PAGE_SIZE}, max_total={MVID_POLL_MAX_TOTAL}, grace={MVID_POLL_GRACE_MIN}m)")

#–û–ø–æ–≤–µ—â–µ–Ω–∏–µ –æ –≥–æ—Ç–æ–≤–Ω–æ–∞—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def _meta_get(key: str) -> str | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE, timeout=10)
        cur = conn.cursor()
        cur.execute("SELECT value FROM app_meta WHERE key=?", (key,))
        row = cur.fetchone()
        return row[0] if row else None
    except Exception as ex:
        logging.debug(f"_meta_get({key}) failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _meta_set(key: str, value: str):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE, timeout=10)
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO app_meta(key, value) VALUES (?, ?)
            ON CONFLICT(key) DO UPDATE SET value=excluded.value
        """, (key, value))
        conn.commit()
    except Exception as ex:
        logging.debug(f"_meta_set({key}) failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _maybe_send_onboarding_congrats():
    try:
        # —É–∂–µ —Å–ª–∞–ª–∏?
        if _meta_get('congrats_sent') == '1':
            return

        # –∫–∞–∫–∏–µ –æ–ø—Ä–æ—Å—á–∏–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã ‚Äî —Ç–∞–∫–∏—Ö –∏ –∂–¥—ë–º
        needed = []
        if 'MOVIE_POLL_ENABLED' in globals() and MOVIE_POLL_ENABLED:
            needed.append('movies')
        if 'SERIES_POLL_ENABLED' in globals() and SERIES_POLL_ENABLED:
            needed.append('series')
        if 'ALBUM_POLL_ENABLED' in globals() and ALBUM_POLL_ENABLED:
            needed.append('albums')
        if 'BOOK_POLL_ENABLED' in globals() and BOOK_POLL_ENABLED:
            needed.append('books')
        if 'MVID_POLL_ENABLED' in globals() and MVID_POLL_ENABLED:
            needed.append('mvids')

        # –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –≤–∫–ª—é—á–µ–Ω–æ ‚Äî –Ω–µ —à–ª—ë–º
        if not needed:
            return

        # –≤—Å–µ –ª–∏ ¬´–∫ —Å–µ–±–µ —Å—Ö–æ–¥–∏–ª–∏¬ª —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ä–∞–∑?
        for k in needed:
            if _meta_get(f'touched_{k}') != '1':
                return

        # –≤—Å—ë, –≥–æ—Ç–æ–≤–æ ‚Äî —à–ª—ë–º –∏ –ø–æ–º–µ—á–∞–µ–º
        send_notification("system", t("onboarding_congrats"))
        _meta_set('congrats_sent', '1')
        logging.info("Onboarding: congrats notification sent.")
    except Exception as ex:
        logging.warning(f"Onboarding congrats check failed: {ex}")

#–æ—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ jellyfin
def _jf_list_active_sessions(active_within_sec: int) -> list:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π Jellyfin –∑–∞ N —Å–µ–∫—É–Ω–¥."""
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ActiveWithinSeconds": str(active_within_sec)
        }
        r = requests.get(f"{JELLYFIN_BASE_URL}/Sessions", params=params, timeout=10)
        r.raise_for_status()
        return r.json() or []
    except Exception as ex:
        logging.warning(f"JF sessions fetch failed: {ex}")
        return []

def _jf_send_session_message(session_id: str, header: str, text: str, timeout_ms: int) -> bool:
    try:
        url = f"{JELLYFIN_BASE_URL}/Sessions/{session_id}/Message"
        headers = {"X-MediaBrowser-Token": JELLYFIN_API_KEY}
        payload = {"Header": header or "", "Text": text or ""}

        # –î–æ–±–∞–≤–ª—è–µ–º TimeoutMs —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —è–≤–Ω–æ —Ö–æ—Ç–∏–º ¬´toast¬ª
        # –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω —Ñ–æ—Ä—Å-–º–æ–¥–∞–ª–∫–∏ –∏–ª–∏ timeout_ms <= 0 ‚Äî –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –≤–æ–≤—Å–µ
        if not JELLYFIN_INAPP_FORCE_MODAL and (timeout_ms is not None) and (int(timeout_ms) > 0):
            payload["TimeoutMs"] = int(timeout_ms)

        r = requests.post(url, headers=headers, json=payload, timeout=8)
        if r.status_code not in (200, 204):
            logging.warning(f"JF message {session_id} failed {r.status_code}: {r.text[:200]}")
            return False
        return True
    except Exception as ex:
        logging.warning(f"JF session message error {session_id}: {ex}")
        return False

def send_jellyfin_inapp_message(message: str, title: str | None = None) -> bool:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–æ –í–°–ï –∞–∫—Ç–∏–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏ (–∑–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥)."""
    if not (JELLYFIN_INAPP_ENABLED and JELLYFIN_BASE_URL and JELLYFIN_API_KEY):
        return False
    header = (title or JELLYFIN_INAPP_TITLE or "Jellyfin")[:120]
    sessions = _jf_list_active_sessions(JELLYFIN_INAPP_ACTIVE_WITHIN_SEC)
    if not sessions:
        logging.info("Jellyfin in-app: –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π ‚Äî —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
        return False

    ok_any = False
    for s in sessions:
        sid = s.get("Id") or s.get("SessionId") or s.get("Id")
        if not sid:
            continue
        if _jf_send_session_message(sid, header, message, JELLYFIN_INAPP_TIMEOUT_MS):
            ok_any = True

    if ok_any:
        logging.info(f"Jellyfin in-app: –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ {len(sessions)} —Å–µ—Å—Å.")
    else:
        logging.warning("Jellyfin in-app: –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –¥–æ—Å—Ç–∞–≤–∫–∏ –Ω–µ—É—Å–ø–µ—à–Ω—ã")
    return ok_any

#–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ reddit
_reddit_oauth_cache = {"token": None, "exp": 0}

def _reddit_get_token() -> str | None:
    """
    –ü–æ–ª—É—á–∏—Ç—å (–∏ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å) bearer-—Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ password grant –¥–ª—è script-app.
    –ù—É–∂–µ–Ω —Å–∫–æ—É–ø 'submit'.
    """
    try:
        import time
        now = int(time.time())
        if _reddit_oauth_cache["token"] and now < _reddit_oauth_cache["exp"] - 20:
            return _reddit_oauth_cache["token"]

        if not all([REDDIT_APP_ID, REDDIT_APP_SECRET, REDDIT_USERNAME, REDDIT_PASSWORD]):
            return None

        data = {
            "grant_type": "password",
            "username": REDDIT_USERNAME,
            "password": REDDIT_PASSWORD,
        }
        # Basic-–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è client_id:client_secret + –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π User-Agent
        r = requests.post(
            "https://www.reddit.com/api/v1/access_token",
            data=data,
            auth=(REDDIT_APP_ID, REDDIT_APP_SECRET),
            headers={"User-Agent": REDDIT_USER_AGENT},
            timeout=12
        )
        r.raise_for_status()
        j = r.json()
        tok = j.get("access_token")
        exp = now + int(j.get("expires_in", 3600))
        if tok:
            _reddit_oauth_cache.update({"token": tok, "exp": exp})
        return tok
    except Exception as ex:
        logging.warning(f"Reddit OAuth failed: {ex}")
        return None


def send_reddit_post(title: str, body_markdown: str, external_image_url: str | None = None) -> bool:
    """
    –ü—É–±–ª–∏–∫—É–µ—Ç self-post –≤ Reddit. –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω external_image_url,
    —Å—Ç–∞–≤–∏–º –µ–≥–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–æ–π (–±–µ–∑ Markdown) ‚Äî Reddit –æ–±—ã—á–Ω–æ –ø–æ–∫–∞–∂–µ—Ç –ø—Ä–µ–≤—å—é.
    """
    try:
        if not (REDDIT_ENABLED and REDDIT_SUBREDDIT):
            return False

        token = _reddit_get_token()
        if not token:
            return False

        headers = {"Authorization": f"bearer {token}", "User-Agent": REDDIT_USER_AGENT}

        text = body_markdown or ""
        if external_image_url:
            url = external_image_url.strip()
            link_line = f"[Poster]({url})"
            # —á—Ç–æ–±—ã –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞—Ç—å, –µ—Å–ª–∏ —É–∂–µ –≤—Å—Ç–∞–≤–ª–µ–Ω–æ
            if not (text.startswith(link_line) or text.startswith(url)):
                text = link_line + ("\n\n" if text else "") + text

        data = {
            "sr": REDDIT_SUBREDDIT,
            "kind": "self",
            "title": (title or "")[:300],
            "text": text,
            "resubmit": "true",
            "sendreplies": "true" if REDDIT_SEND_REPLIES else "false",
            "spoiler": "true" if REDDIT_SPOILER else "false",
            "nsfw": "true" if REDDIT_NSFW else "false",
            "api_type": "json",
        }

        r = requests.post("https://oauth.reddit.com/api/submit", headers=headers, data=data, timeout=20)
        if r.status_code != 200:
            logging.warning(f"Reddit submit HTTP {r.status_code}: {r.text[:300]}")
            return False

        jr = r.json().get("json", {})
        errs = jr.get("errors") or []
        if errs:
            logging.warning(f"Reddit submit errors: {errs}")
            return False

        logging.info("Reddit post submitted successfully")
        return True

    except Exception as ex:
        logging.warning(f"Reddit submit failed: {ex}")
        return False

def send_reddit_link_post_with_comment(title: str, url: str, body_markdown: str | None = None) -> bool:
    """
    –î–µ–ª–∞–µ—Ç —Å—Å—ã–ª–æ—á–Ω—ã–π –ø–æ—Å—Ç (kind=link) —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º-URL.
    Reddit –æ—Ç—Ä–∏—Å—É–µ—Ç –ø—Ä–µ–≤—å—é/–∫–∞—Ä—Ç–∏–Ω–∫—É. –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å —Ç–µ–∫—Å—Ç–æ–º.
    """
    try:
        if not (REDDIT_ENABLED and REDDIT_SUBREDDIT and url):
            return False

        token = _reddit_get_token()
        if not token:
            return False

        headers = {"Authorization": f"bearer {token}", "User-Agent": REDDIT_USER_AGENT}

        submit_data = {
            "sr": REDDIT_SUBREDDIT,
            "kind": "link",
            "title": (title or "")[:300],
            "url": url.strip(),
            "resubmit": "true",
            "sendreplies": "true" if REDDIT_SEND_REPLIES else "false",
            "spoiler": "true" if REDDIT_SPOILER else "false",
            "nsfw": "true" if REDDIT_NSFW else "false",
            "api_type": "json",
        }
        r = requests.post("https://oauth.reddit.com/api/submit", headers=headers, data=submit_data, timeout=20)
        if r.status_code != 200:
            logging.warning(f"Reddit link submit HTTP {r.status_code}: {r.text[:300]}")
            return False

        jr = r.json().get("json", {})
        errs = jr.get("errors") or []
        if errs:
            logging.warning(f"Reddit link submit errors: {errs}")
            return False

        data = jr.get("data") or {}
        thing_id = data.get("name") or (f"t3_{data.get('id')}" if data.get('id') else None)

        if thing_id and body_markdown:
            cdata = {"thing_id": thing_id, "text": body_markdown, "api_type": "json"}
            cr = requests.post("https://oauth.reddit.com/api/comment", headers=headers, data=cdata, timeout=20)
            if cr.status_code != 200:
                logging.warning(f"Reddit comment HTTP {cr.status_code}: {cr.text[:300]}")
            else:
                ce = (cr.json().get("json") or {}).get("errors") or []
                if ce:
                    logging.warning(f"Reddit comment errors: {ce}")

        logging.info("Reddit link post submitted successfully")
        return True

    except Exception as ex:
        logging.warning(f"Reddit link submit failed: {ex}")
        return False

#–û—Ç–ø—Ä–∞–≤–∫–∞ –≤ synology chat
def _synochat_resp_ok(resp) -> tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Synology Chat —Ä–µ–∞–ª—å–Ω–æ –ø—Ä–∏–Ω—è–ª —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    if resp is None:
        return False, "no response"
    if resp.status_code != 200:
        return False, f"HTTP {resp.status_code}: {resp.text[:200]}"
    # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞–∑–æ–±—Ä–∞—Ç—å JSON
    try:
        j = resp.json()
        if isinstance(j, dict) and j.get("success") is True:
            return True, ""
        # –ò–Ω–æ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç {"success":false,"error":{...}}
        return False, f"API: {j}"
    except Exception:
        # –ë—ã–≤–∞—é—Ç ¬´–ø—Ä–æ—Å—Ç—ã–µ¬ª –æ—Ç–≤–µ—Ç—ã (—Ä–µ–¥–∫–æ)
        t = (resp.text or "").strip()
        if '"success":true' in t.lower() or t.upper() == "OK":
            return True, ""
        return False, f"Body: {t[:200]}"

def _synochat_resp_ok(resp):
    if resp is None:
        return False, "no response", None
    if resp.status_code != 200:
        return False, f"HTTP {resp.status_code}: {resp.text[:200]}", None
    try:
        j = resp.json()
        if isinstance(j, dict):
            if j.get("success") is True:
                return True, "", None
            # –∏–Ω–æ–≥–¥–∞: {"success":false,"error":{"code":...,"errors": "..."}}
            code = (j.get("error") or {}).get("code")
            return False, f"API: {j}", code
    except Exception:
        pass
    t = (resp.text or "").strip().lower()
    if '"success":true' in t or t == "ok":
        return True, "", None
    return False, f"Body: {resp.text[:200]}", None


def send_synology_chat_message(text: str, file_url: str | None = None) -> bool:
    """
    Synology Chat Incoming Webhook.
    1) –ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ–π payload: –µ—Å–ª–∏ text –ø—É—Å—Ç ‚Äî –¥–æ—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∏–∑ caption.
    2) –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ1: form (payload=<json>), ‚Ññ2: JSON body.
    3) –†–µ—Ç—Ä–∞–∏–º 117/411/429/5xx.
    """
    try:
        if not (SYNOCHAT_ENABLED and SYNOCHAT_WEBHOOK_URL):
            return False

        # verify: True / False / CA bundle
        verify_param = True
        if not SYNOCHAT_VERIFY_SSL:
            try:
                import urllib3
                from urllib3.exceptions import InsecureRequestWarning
                urllib3.disable_warnings(InsecureRequestWarning)
            except Exception:
                pass
            verify_param = False
        elif SYNOCHAT_CA_BUNDLE:
            verify_param = SYNOCHAT_CA_BUNDLE

        proxies = _notify_proxies_for(SYNOCHAT_WEBHOOK_URL)

        # --- –°—Ç—Ä–∞—Ö–æ–≤–∫–∞ –æ—Ç –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ---
        safe_text = (text or "").strip()
        if not safe_text:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å ¬´–∑–∞–≥–æ–ª–æ–≤–æ–∫ + –æ–ø–∏—Å–∞–Ω–∏–µ¬ª –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ caption-—Å—Ç–∏–ª—è
            # (–ø–µ—Ä–≤–∞—è –∂–∏—Ä–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî header, –≤—Ç–æ—Ä–∞—è ‚Äî title; –¥–∞–ª—å—à–µ overview)
            try:
                hdr, body = make_jf_inapp_payload_from_caption(text or "")
                safe_text = (body or hdr or "Notification").strip()
            except Exception:
                safe_text = "Notification"

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –∏ poster –Ω–µ –≤–∫–ª—é—á—ë–Ω ‚Äî –Ω–µ —à–ª—ë–º –≤–æ–≤—Å–µ
        if not safe_text and not file_url:
            logging.debug("Synology Chat: empty payload suppressed")
            return False

        payload = {"text": safe_text}
        if file_url:
            payload["file_url"] = file_url

        import time
        attempts = max(1, SYNOCHAT_RETRIES)
        delay = max(0.0, SYNOCHAT_RETRY_BASE_DELAY)

        for attempt in range(1, attempts + 1):
            # --- –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ1: form ---
            r1 = requests.post(
                SYNOCHAT_WEBHOOK_URL,
                data={"payload": json.dumps(payload, ensure_ascii=False)},
                timeout=SYNOCHAT_TIMEOUT_SEC,
                verify=verify_param,
                proxies=proxies,
            )
            ok, detail, code = _synochat_resp_ok(r1)
            if ok:
                logging.info("Synology Chat notification sent")
                return True

            # --- –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ2: JSON body ---
            r2 = requests.post(
                SYNOCHAT_WEBHOOK_URL,
                headers={"Content-Type": "application/json"},
                json=payload,
                timeout=SYNOCHAT_TIMEOUT_SEC,
                verify=verify_param,
                proxies=proxies,
            )
            ok2, detail2, code2 = _synochat_resp_ok(r2)
            if ok2:
                logging.info("Synology Chat notification sent (json)")
                return True

            # –†–µ—à–∞–µ–º, —Ä–µ—Ç—Ä–∞–∏—Ç—å –ª–∏
            retry_code = code2 if code2 is not None else code
            # 117 = busy/network; 411 = rate-limit "create post too fast"; 429/5xx —É–∂–µ –±—É–¥—É—Ç –∫–∞–∫ HTTP –≤ detail
            should_retry = (retry_code in (117, 411)) or ("HTTP 5" in str(detail) or "HTTP 429" in str(detail2))

            if not should_retry or attempt == attempts:
                logging.warning(f"Synology Chat failed: {detail} | {detail2}")
                return False

            logging.warning(f"Synology Chat temporary error (code={retry_code}), retry {attempt}/{attempts}...")
            time.sleep(delay)
            delay *= max(1.0, SYNOCHAT_RETRY_BACKOFF)

        return False

    except Exception as ex:
        logging.warning(f"Synology Chat error: {ex}")
        return False

#–û—Ç–ø—Ä–∞–≤–∫–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
def _host_matches(pattern: str, host: str) -> bool:
    p = pattern.lower().strip()
    h = (host or "").lower().strip()
    if p == h:
        return True
    if p.startswith("*.") and h.endswith(p[1:]):  # *.example.com
        return True
    # CIDR: 192.168.1.0/24
    try:
        if "/" in p:
            import ipaddress
            net = ipaddress.ip_network(p, strict=False)
            ip = ipaddress.ip_address(h)
            return ip in net
    except Exception:
        pass
    # –ü—Ä–æ—Å—Ç–∞—è –º–∞—Å–∫–∞: 192.168.1.*
    if p.endswith(".*") and h.startswith(p[:-1]):
        return True
    return False

def _is_private_host(host: str) -> bool:
    """True, –µ—Å–ª–∏ host ‚Äî –ø—Ä–∏–≤–∞—Ç–Ω—ã–π IP/localhost/–æ–¥–Ω–æ—Å–ª–æ–≤–Ω—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π —Ö–æ—Å—Ç."""
    try:
        ip = ipaddress.ip_address(host)
        return ip.is_private or ip.is_loopback or ip.is_link_local
    except ValueError:
        # –Ω–µ IP ‚Äî hostname
        if host in ("localhost",):
            return True
        # –æ–¥–Ω–æ—Å–ª–æ–≤–Ω—ã–µ –∏–º–µ–Ω–∞ —Ç–∏–ø–∞ 'nas' –æ–±—ã—á–Ω–æ –ª–æ–∫–∞–ª—å–Ω—ã–µ
        if "." not in host:
            return True
        # –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –∑–æ–Ω—ã
        if host.endswith((".local", ".home", ".lan")):
            return True
        return False

def _notify_proxies_for(url: str) -> dict | None:
    """
    –í–µ—Ä–Ω—ë—Ç dict –¥–ª—è requests.proxies –∏–ª–∏ None, –µ—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –Ω–µ –Ω—É–∂–µ–Ω.
    """
    if not NOTIFY_PROXY_URL:
        return None
    try:
        host = urlparse(url).hostname or ""
    except Exception:
        host = ""

    # Bypass: –ø—Ä–∏–≤–∞—Ç–Ω—ã–µ/–ª–æ–∫–∞–ª—å–Ω—ã–µ ‚Äî –µ—Å–ª–∏ –Ω–µ –≤–∫–ª—é—á–∏–ª–∏ —Ñ–æ—Ä—Å
    if not NOTIFY_PROXY_FOR_INTERNAL and _is_private_host(host):
        return None

    # Bypass: –ø–æ —Å–ø–∏—Å–∫—É –∏—Å–∫–ª—é—á–µ–Ω–∏–π
    for pat in NOTIFY_PROXY_NO:
        if _host_matches(pat, host):
            return None

    return {"http": NOTIFY_PROXY_URL, "https": NOTIFY_PROXY_URL}








@app.route("/webhook", methods=["POST"])
def announce_new_releases_from_jellyfin():
    try:
        payload = json.loads(request.data)
        item_type = payload.get("ItemType")
        tmdb_id = payload.get("Provider_tmdb")
        item_name = payload.get("Name")
        release_year = payload.get("Year")
        series_name = payload.get("SeriesName")
        season_epi = payload.get("EpisodeNumber00")
        season_num = payload.get("SeasonNumber00")

        if item_type == "Movie":
            movie_id = payload.get("ItemId")
            overview = payload.get("Overview")
            runtime = payload.get("RunTime")

            movie_name = item_name
            movie_name_cleaned = movie_name.replace(f" ({release_year})", "").strip()

            tmdb_id_payload = payload.get("Provider_tmdb") or payload.get("TmdbId")
            imdb_id_payload = payload.get("Provider_imdb") or payload.get("ImdbId")

            # --- –ù–û–í–û–ï: –µ—Å–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ quality-update –ø–æ —Å–∫–∞–Ω–µ—Ä—É/–≥–≤–∞—Ä–¥—É ‚Äî –≥–ª—É—à–∏–º –≤–µ–±—Ö—É–∫
            logical_key = _movie_logical_key(tmdb_id=tmdb_id_payload, imdb_id=imdb_id_payload,
                                             name=movie_name_cleaned, year=release_year)
            if was_quality_update_recent(logical_key):
                logging.info(
                    f"(Webhook/Movie) Suppressed 'new movie' due to recent quality update (logical_key={logical_key})")
                return "Suppressed: recent quality update"

            # 1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º –∞–ø–≥—Ä–µ–π–¥ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äî —ç—Ç–æ –¥–æ–ª–∂–Ω–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–∏–ª—å–º —É–∂–µ ¬´–±—ã–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω¬ª
            if maybe_notify_movie_quality_change(
                    item_id=movie_id,
                    movie_name_cleaned=movie_name_cleaned,
                    release_year=release_year,
                    tmdb_id=tmdb_id_payload,
                    imdb_id=imdb_id_payload,
                    overview=overview,
                    runtime=runtime
            ):
                return "Movie quality update sent"

            # 2) –ò–Ω–∞—á–µ ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–º —Ñ–∏–ª—å–º–µ (–∫–∞–∫ –±—ã–ª–æ)
            if not item_already_notified(item_type, item_name, release_year):
                trailer_url = safe_get_trailer_prefer_tmdb(f"{movie_name_cleaned} Trailer {release_year}",
                                context="webhook", subkind="movie", tmdb_id=tmdb_id)

                notification_message = (
                    f"*{t('new_movie_title')}*\n\n*{movie_name_cleaned}* *({release_year})*\n\n{overview}\n\n"
                    f"*{t('new_runtime')}*\n{runtime}"
                )

                if tmdb_id:
                    mdblist_type = item_type.lower()
                    ratings_text = safe_fetch_mdblist_ratings(mdblist_type, tmdb_id)
                    if ratings_text:
                        notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"

                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # --- Quality changes –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ –ù–û–í–û–ú —Ñ–∏–ª—å–º–µ ---
                try:
                    # —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                    new_q = _get_item_media_info_movie(movie_id)

                    # –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ä—ã–π —Å–ª–µ–ø–æ–∫ –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É (–µ—Å–ª–∏ —Ñ–∏–ª—å–º –∫–æ–≥–¥–∞-—Ç–æ –±—ã–ª)
                    logical_key = _movie_logical_key(
                        tmdb_id=tmdb_id_payload,
                        imdb_id=imdb_id_payload,
                        name=movie_name_cleaned,
                        year=release_year
                    )
                    old_q = None
                    try:
                        conn = sqlite3.connect(QUALITY_DB_FILE)
                        cur = conn.cursor()
                        cur.execute("""SELECT video_codec,
                                              video_bitrate,
                                              width,
                                              height,
                                              fps,
                                              bit_depth,
                                              dynamic_range,
                                              image_profiles,
                                              audio_codec,
                                              audio_bitrate,
                                              audio_channels,
                                              container,
                                              size_bytes,
                                              duration_sec
                                       FROM content_quality
                                       WHERE logical_key = ?""", (logical_key,))
                        row = cur.fetchone()
                        if row:
                            old_q = {
                                "video_codec": row[0], "video_bitrate": row[1], "width": row[2], "height": row[3],
                                "fps": row[4], "bit_depth": row[5], "dynamic_range": row[6],
                                "image_profiles": ([p.strip() for p in row[7].split(",")] if row[7] else None),
                                "audio_codec": row[8], "audio_bitrate": row[9], "audio_channels": row[10],
                                "container": row[11], "size_bytes": row[12], "duration_sec": row[13],
                            }
                    except Exception as ex:
                        logging.warning(f"Quality (new movie) old snapshot read failed: {ex}")
                    finally:
                        try:
                            conn.close()
                        except Exception:
                            pass

                    # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –±–ª–æ–∫:
                    delta_block = build_quality_changes_block(old_q,
                                                              new_q) if old_q else build_initial_quality_changes_block(
                        new_q)
                    if not delta_block:
                        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –µ—Å–ª–∏ –ø–æ—á–µ–º—É-—Ç–æ –±–ª–æ–∫ –ø—É—Å—Ç, –ø–æ–∫–∞–∂–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π
                        delta_block = build_initial_quality_changes_block(new_q)
                    notification_message += delta_block

                    # (–ø–æ –∂–µ–ª–∞–Ω–∏—é) —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫, –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à—ë–Ω —Ñ–ª–∞–≥–æ–º
                    if INCLUDE_AUDIO_TRACKS:
                        tracks_block = build_audio_tracks_block(new_q)
                        if tracks_block:
                            notification_message += tracks_block

                except Exception as ex:
                    logging.warning(f"Quality (new movie) block build failed: {ex}")
                # --- /Quality changes ---

                send_notification(movie_id, notification_message)
                mark_item_as_notified(item_type, item_name, release_year)
                logging.info(f"(Movie) {movie_name} {release_year} notification was sent.")
                return "Movie notification was sent"

        if item_type == "Season":
            # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–ª—é—á –¥–ª—è –∞–Ω—Ç–∏—Å–ø–∞–º–∞
            season = item_name  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "–°–µ–∑–æ–Ω 1"
            series_title_for_key = (series_name or "").strip()
            key_name = f"{series_title_for_key} {season}".strip()

            if not item_already_notified(item_type, key_name, release_year):
                season_id = payload.get("ItemId")
                season = item_name
                season_details = get_item_details(season_id)
                series_id = season_details["Items"][0].get("SeriesId")
                series_details = get_item_details(series_id)
                # Remove release_year from series_name if present
                series_name_cleaned = series_name.replace(f" ({release_year})", "").strip()

                # Get TMDb ID via external API
                tmdb_id = jellyfin_get_tmdb_id(series_id)
                trailer_url = safe_get_trailer_prefer_tmdb(f"{series_name_cleaned} Trailer {release_year}",
                                subkind="show", tmdb_id=tmdb_id, context="")

                # **–ù–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏**: –ø–æ–ª—É—á–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∞
                ratings_text = safe_fetch_mdblist_ratings("show", tmdb_id)
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–π—Ç–∏–Ω–≥–∏ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –Ω–∏—Ö
                ratings_section = f"{ratings_text}\n\n" if ratings_text else ""

                # Get series overview if season overview is empty
                overview_to_use = payload.get("Overview") if payload.get("Overview") else series_details["Items"][0].get(
                    "Overview")

                # —Å—á–∏—Ç–∞–µ–º ¬´—Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å / —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ¬ª –ø–æ —Å–µ–∑–æ–Ω—É (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ–π resilient-—Ö–µ–ª–ø–µ—Ä)
                present, total = jellyfin_get_season_counts_resilient(season_id)

                if total >= present and total > 0:
                    episodes_segment = f"\n\n{t('season_added_progress').format(added=present, total=total)}"
                elif present > 0:
                    episodes_segment = f"\n\n{t('season_added_count_only').format(added=present)}"
                else:
                    episodes_segment = ""

                notification_message = (
                    f"*{t('new_season_title')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n"
                    f"*{season}*{episodes_segment}\n\n{overview_to_use}")

                if ratings_text:
                    notification_message += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"

                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞ ‚Äî –µ—Å–ª–∏ –Ω–µ—Ç, —à–ª—ë–º —Å –ø–æ—Å—Ç–µ—Ä–æ–º —Å–µ—Ä–∏–∞–ª–∞
                if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                    send_notification(season_id, notification_message)
                else:
                    send_notification(series_id, notification_message)
                    logging.warning(
                        f"{series_name_cleaned} {season} image does not exist, falling back to series image")

                mark_item_as_notified(item_type, key_name, release_year)
                logging.info(f"(Season) {series_name_cleaned} {season} notification was sent")
                return "Season notification was sent"

        if item_type == "Episode":
            if not item_already_notified(item_type, item_name, release_year):
                item_id = payload.get("ItemId")
                file_details = get_item_details(item_id)
                season_id = file_details["Items"][0].get("SeasonId")
                episode_premiere_date = file_details["Items"][0].get("PremiereDate", "0000-00-00T").split("T")[0]
                season_details = get_item_details(season_id)
                series_id = season_details["Items"][0].get("SeriesId")
                season_date_created = season_details["Items"][0].get("DateCreated", "0000-00-00T").split("T")[0]
                epi_name = item_name
                overview = payload.get("Overview")

#                if not DEBUG_DISABLE_DATE_CHECKS:
                if not is_not_within_last_x_days(season_date_created, SEASON_ADDED_WITHIN_X_DAYS):
                    logging.info(f"(Episode) {series_name} Season {season_num} "
                                 f"was added within the last {SEASON_ADDED_WITHIN_X_DAYS} "
                                 f"days. Not sending notification.")
                    return (f"Season was added within the last {SEASON_ADDED_WITHIN_X_DAYS} "
                            f"days. Not sending notification.")

                if episode_premiere_date and is_within_last_x_days(episode_premiere_date,
                                                                   EPISODE_PREMIERED_WITHIN_X_DAYS):

                    notification_message = (
                        f"*{t('new_episode_title')}*\n\n*{t('new_release_date')}*: {episode_premiere_date}\n\n*{t('new_series')}*: {series_name} *S*"
                        f"{season_num}*E*{season_epi}\n*{t('new_episode_t')}*: {epi_name}\n\n{overview}\n\n"
                    )
                    # –ü–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞ –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –ø—Ä–æ–≤–µ—Ä–∏–º –∑–∞—Ä–∞–Ω–µ–µ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–π–¥—ë–º –Ω–∞ –ø–æ—Å—Ç–µ—Ä —Å–µ—Ä–∏–∞–ª–∞
                    if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                        send_notification(season_id, notification_message)
                    else:
                        send_notification(series_id, notification_message)
                        logging.warning(
                            f"(Episode) {series_name} season image does not exist, falling back to series image")

                    mark_item_as_notified(item_type, item_name, release_year)
                    logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} notification sent!")
                    return "Notification sent!"

                else:
                    logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} "
                                 f"was premiered more than {EPISODE_PREMIERED_WITHIN_X_DAYS} "
                                 f"days ago. Not sending notification.")
                    return (f"Episode was added more than {EPISODE_PREMIERED_WITHIN_X_DAYS} "
                            f"days ago. Not sending notification.")

        if item_type == "MusicAlbum":
            # —á–∏—Ç–∞–µ–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è/–∞–ª—å–±–æ–º –∑–∞—Ä–∞–Ω–µ–µ, —á—Ç–æ–±—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á
            album_name = payload.get("Name")
            artist = payload.get("Artist")
            key_name = f"{artist} ‚Äì {album_name}".strip()

            if not item_already_notified(item_type, key_name, release_year):
                album_id = payload.get("ItemId")
                album_name = payload.get("Name")
                artist = payload.get("Artist")
                year = payload.get("Year")
                overview = payload.get("Overview")
                runtime = payload.get("RunTime")
                musicbrainzalbum_id = payload.get("Provider_musicbrainzalbum")

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ MusicBrainz, –µ—Å–ª–∏ –µ—Å—Ç—å ID
                mb_link = f"https://musicbrainz.org/release/{musicbrainzalbum_id}" if musicbrainzalbum_id else ""

                # –®–∞–±–ª–æ–Ω —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                notification_message = (
                    f"*{t('new_album_title')}*\n\n"
                    f"*{artist}*\n\n"
                    f"*{album_name} ({year})*\n\n"
                    f"{overview and overview + '\n\n' or ''}"
                    f"*{t('new_runtime')}*\n{runtime}\n\n"
                    f"{f'[MusicBrainz]({mb_link})' if mb_link else ''}\n"
                )

                send_notification(album_id, notification_message)
                mark_item_as_notified(item_type, key_name, release_year)
                logging.info(f"(Album) {artist} ‚Äì {album_name} ({year}) notification sent.")
                return "Album notification was sent to telegram"

        if item_type == "Movie":
            logging.info(f"(Movie) {item_name} Notification Was Already Sent")
        elif item_type == "Season":
            logging.info(f"(Season) {series_name} {item_name} Notification Was Already Sent")
        elif item_type == "Episode":
            logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} Notification Was Already Sent")
        else:
            logging.error('Item type not supported')
        return "Item type not supported."

    # Handle specific HTTP errors
    except HTTPError as http_err:
        logging.error(f"HTTP error occurred: {http_err}")
        return str(http_err)

    # Handle generic exceptions
    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return f"Error: {str(e)}"


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
