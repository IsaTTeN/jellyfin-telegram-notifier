import logging
import os
import json
import requests
import tempfile
import re
import base64
import threading
import time
import markdown
import smtplib
from requests.exceptions import HTTPError
from flask import Flask, request
from dotenv import load_dotenv
from apprise import Apprise
from urllib.parse import quote
from email.message import EmailMessage
from email.utils import formatdate, make_msgid
from logging.handlers import TimedRotatingFileHandler
from datetime import datetime, timedelta, timezone
from collections import Counter, OrderedDict
import sqlite3
import hashlib

load_dotenv()
app = Flask(__name__)

# Set up logging
#log_directory = '/app/log'
log_directory = 'A:/git'
log_filename = os.path.join(log_directory, 'jellyfin_telegram-notifier.log')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Ensure the log directory exists
os.makedirs(log_directory, exist_ok=True)

# Create a handler for rotating log files daily
rotating_handler = TimedRotatingFileHandler(log_filename, when="midnight", interval=1, backupCount=7)
rotating_handler.setLevel(logging.INFO)
rotating_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))

# Add the rotating handler to the logger
logging.getLogger().addHandler(rotating_handler)

# Constants
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID", "")
GOTIFY_URL = os.environ.get("GOTIFY_URL", "").rstrip("/")
GOTIFY_TOKEN = os.environ.get("GOTIFY_TOKEN", "")
JELLYFIN_BASE_URL = os.environ["JELLYFIN_BASE_URL"].rstrip("/")
JELLYFIN_API_KEY = os.environ["JELLYFIN_API_KEY"]
YOUTUBE_API_KEY = os.environ.get("YOUTUBE_API_KEY", "")
MDBLIST_API_KEY = os.environ.get("MDBLIST_API_KEY", "")
IMGBB_API_KEY = os.environ.get("IMGBB_API_KEY", "")
DISCORD_WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL", "")
TMDB_API_KEY = os.environ.get("TMDB_API_KEY")
TMDB_LANGUAGE = os.getenv("TMDB_LANGUAGE", "en-US")  # –Ω–∞–ø—Ä. "ru-RU"
TMDB_SEARCH_URL = "https://api.themoviedb.org/3/search/tv"
TMDB_BASE = "https://api.themoviedb.org/3"
LANGUAGE = os.environ["LANGUAGE"]
EPISODE_PREMIERED_WITHIN_X_DAYS = int(os.environ["EPISODE_PREMIERED_WITHIN_X_DAYS"])
SEASON_ADDED_WITHIN_X_DAYS = int(os.environ["SEASON_ADDED_WITHIN_X_DAYS"])
SIGNAL_URL = os.environ.get("SIGNAL_URL", "").rstrip("/")
SIGNAL_NUMBER = os.environ.get("SIGNAL_NUMBER", "")
SIGNAL_RECIPIENTS = os.environ.get("SIGNAL_RECIPIENTS", "")
WHATSAPP_API_URL = os.environ.get("WHATSAPP_API_URL", "").rstrip("/")
WHATSAPP_NUMBER = os.environ.get("WHATSAPP_NUMBER", "")
WHATSAPP_JID = os.environ.get("WHATSAPP_JID", "")
WHATSAPP_GROUP_JID = os.environ.get("WHATSAPP_GROUP_JID", "")
WHATSAPP_API_USERNAME = os.environ.get("WHATSAPP_API_USERNAME", "")
WHATSAPP_API_PWD = os.environ.get("WHATSAPP_API_PWD", "")
MATRIX_URL = os.environ.get("MATRIX_URL", "").rstrip("/")
MATRIX_ACCESS_TOKEN = os.environ.get("MATRIX_ACCESS_TOKEN", "")
MATRIX_ROOM_ID = os.environ.get("MATRIX_ROOM_ID", "")
SMTP_SUBJECT = "–ù–æ–≤—ã–π —Ä–µ–ª–∏–∑ –≤ Jellyfin"
SMTP_HOST = os.environ.get("SMTP_HOST", "")
SMTP_PORT = int(os.environ.get("SMTP_PORT", "587"))
SMTP_USER = os.environ.get("SMTP_USER", "")
SMTP_PASS = os.environ.get("SMTP_PASS", "")
SMTP_FROM = os.environ.get("SMTP_FROM", "")
SMTP_TO   = os.environ.get("SMTP_TO", "")  # —Å–ø–∏—Å–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é/–ø—Ä–æ–±–µ–ª
SMTP_USE_TLS = os.environ.get("SMTP_USE_TLS", "1") not in ("0", "", "false", "False")   # –¥–ª—è STARTTLS (587)
SMTP_USE_SSL = os.environ.get("SMTP_USE_SSL", "0") in ("1", "true", "True")   # –¥–ª—è SMTPS (465); –µ—Å–ª–∏ 1, —Ç–æ TLS –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º
SLACK_BOT_TOKEN = os.environ.get("SLACK_BOT_TOKEN", "")
SLACK_CHANNEL_ID = os.environ.get("SLACK_CHANNEL_ID", "")   # ID –∫–∞–Ω–∞–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä C0123456789
#–≤—ã–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
DISABLE_DEDUP = os.getenv("NOTIFIER_DISABLE_DEDUP", "1").lower() in ("1", "true", "yes")
#–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ñ–∏–ª—å–º–æ–≤
MOVIE_POLL_ENABLED = os.getenv("MOVIE_POLL_ENABLED", "1").lower() in ("1", "true", "yes")
MOVIE_POLL_INTERVAL_SEC = int(os.getenv("MOVIE_POLL_INTERVAL_SEC", "80"))   # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
MOVIE_POLL_GRACE_MIN = int(os.getenv("MOVIE_POLL_GRACE_MIN", "45"))  # –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å —Ñ–∏–ª—å–º—ã, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –º–∏–Ω—É—Ç
MOVIE_POLL_PAGE_SIZE = int(os.getenv("MOVIE_POLL_PAGE_SIZE", "500"))  # —Å–∫–æ–ª—å–∫–æ –±—Ä–∞—Ç—å –∑–∞ 1 –∑–∞–ø—Ä–æ—Å
MOVIE_POLL_MAX_TOTAL = int(os.getenv("MOVIE_POLL_MAX_TOTAL", "0"))    # 0 = –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –æ–±—â–µ–µ —á–∏—Å–ª–æ
# GC –ë–î –∫–∞—á–µ—Å—Ç–≤–∞
QUALITY_GC_ENABLED = os.getenv("QUALITY_GC_ENABLED", "1").lower() in ("1","true","yes","on")
QUALITY_GC_INTERVAL_HOURS = int(os.getenv("QUALITY_GC_INTERVAL_HOURS", "24"))   # –∫–∞–∫ —á–∞—Å—Ç–æ —á–∏—Å—Ç–∏—Ç—å
QUALITY_GC_GRACE_DAYS = int(os.getenv("QUALITY_GC_GRACE_DAYS", "1"))            # –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å –∑–∞–ø–∏—Å–∏ –º–æ–ª–æ–∂–µ N –¥–Ω–µ–π
QUALITY_GC_PAGE_SIZE = int(os.getenv("QUALITY_GC_PAGE_SIZE", "500"))            # —Å–∫–æ–ª—å–∫–æ —Ñ–∏–ª—å–º–æ–≤ –∑–∞ —Ä–∞–∑ —Ç—è–Ω—É—Ç—å –∏–∑ Jellyfin
# –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ–¥–Ω–æ—Ä–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ –ë–î –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
FORCE_QUALITY_GC_ON_START = os.getenv("FORCE_QUALITY_GC_ON_START", "0").lower() in ("1","true","yes","on")
# –ù–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ grace-—Å—Ä–æ–∫–∞ –∏–º–µ–Ω–Ω–æ –¥–ª—è —Ñ–æ—Ä—Å-–∑–∞–ø—É—Å–∫–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0 = —É–¥–∞–ª—è—Ç—å —Å—Ä–∞–∑—É)
FORCE_QUALITY_GC_GRACE_DAYS = os.getenv("FORCE_QUALITY_GC_GRACE_DAYS")
# –°–∂–∞—Ç—å –ë–î –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
FORCE_QUALITY_GC_VACUUM = os.getenv("FORCE_QUALITY_GC_VACUUM", "0").lower() in ("1","true","yes","on")
#–≤—ã–∫–ª—é—á–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–≤—É–∫–æ–≤—ã—Ö –¥–æ—Ä–æ–∂–∫–∞—Ö
INCLUDE_AUDIO_TRACKS = os.getenv("INCLUDE_AUDIO_TRACKS", "1").lower() in ("1", "true", "yes", "on")
#–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–µ webhook –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª–¥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN = int(os.getenv("SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN", "60"))  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 60 –º–∏–Ω—É—Ç
# –û–ø—Ä–æ—Å —Å–µ—Ä–∏–∞–ª–æ–≤ (–ø–æ –Ω–æ–≤—ã–º/–∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º —ç–ø–∏–∑–æ–¥–∞–º)
SERIES_POLL_ENABLED = os.getenv("SERIES_POLL_ENABLED", "1").lower() in ("1","true","yes","on")
SERIES_POLL_INTERVAL_SEC = int(os.getenv("SERIES_POLL_INTERVAL_SEC", "80"))  # –ø–µ—Ä–∏–æ–¥, —Å–µ–∫
SERIES_POLL_PAGE_SIZE = int(os.getenv("SERIES_POLL_PAGE_SIZE", "500"))
SERIES_POLL_MAX_TOTAL = int(os.getenv("SERIES_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
SERIES_POLL_GRACE_MIN = int(os.getenv("SERIES_POLL_GRACE_MIN", "0"))  # —Å–≤–µ–∂–∏–µ —ç–ø–∏–∑–æ–¥—ã –æ—Ç–¥–∞—ë–º –Ω–∞ –æ—Ç–∫—É–ø –≤–µ–±—Ö—É–∫—É
# –ü–æ—Å—ã–ª–∞—Ç—å –ª–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø—Ä–∏ –ü–ï–†–í–û–ú –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ —Å–µ–∑–æ–Ω–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ—Ç)
SERIES_POLL_INITIAL_ANNOUNCE = os.getenv("SERIES_POLL_INITIAL_ANNOUNCE", "0").lower() in ("1","true","yes","on")
# –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–π–º–µ—Ä—ã –æ—Ç–ø—Ä–∞–≤–∫–∏ –Ω–∞ –≤—Ä–µ–º—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ Jellyfin
NOTIFY_BLOCK_DURING_SCAN = os.getenv("NOTIFY_BLOCK_DURING_SCAN", "1").lower() in ("1","true","yes","on")
SCAN_RECHECK_DELAY_SEC = int(os.getenv("SCAN_RECHECK_DELAY_SEC", "5"))   # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏
MAX_SCAN_WAIT_MIN = int(os.getenv("MAX_SCAN_WAIT_MIN", "0"))             # 0 = –∂–¥–∞—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ
# –ö–∞–∫–∏–µ –∏–º–µ–Ω–∞ –∑–∞–¥–∞—á —Å—á–∏—Ç–∞—Ç—å ¬´—Å–∫–∞–Ω–æ–º¬ª (–Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
SCAN_TASK_NAME_MATCH = [s.strip() for s in os.getenv(
    "SCAN_TASK_NAME_MATCH",
    "scan,library,metadata,refresh"
).lower().split(",") if s.strip()]
EXTERNAL_CACHE_ENABLED = os.getenv("EXTERNAL_CACHE_ENABLED", "1").lower() in ("1","true","yes","on")
TRAILER_CACHE_TTL_DAYS = int(os.getenv("TRAILER_CACHE_TTL_DAYS", "30"))
RATINGS_CACHE_TTL_DAYS = int(os.getenv("RATINGS_CACHE_TTL_DAYS", "14"))
# –ü—Ä–µ–¥–µ–ª—ã –¥–ª—è –±–ª–æ–∫–∞ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫ —É —Å–µ–∑–æ–Ω–æ–≤
SEASON_AUDIO_TRACKS_MAX = int(os.getenv("SEASON_AUDIO_TRACKS_MAX", "12"))   # –º–∞–∫—Å–∏–º—É–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ—Ä–æ–∂–µ–∫
SEASON_AUDIO_SCAN_LIMIT = int(os.getenv("SEASON_AUDIO_SCAN_LIMIT", "50"))   # –º–∞–∫—Å–∏–º—É–º —Å–µ—Ä–∏–π –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (present)
#–î–ª—è whatsapp –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –æ—Ç–ø—Ä–∞–≤–∫–∏
WHATSAPP_IMAGE_RETRY_ATTEMPTS = int(os.getenv("WHATSAPP_IMAGE_RETRY_ATTEMPTS", "3"))
WHATSAPP_IMAGE_RETRY_DELAY_SEC = int(os.getenv("WHATSAPP_IMAGE_RETRY_DELAY_SEC", "2"))
# --- Episode/Season quality polling (–ø–æ —Å–µ—Ä–∏—è–º -> —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –Ω–∞ —Å–µ–∑–æ–Ω) ---
EP_QUALITY_POLL_ENABLED = (os.getenv("EP_QUALITY_POLL_ENABLED", "1").lower() in ("1","true","yes","on"))
EP_QUALITY_POLL_INTERVAL_SEC = int(os.getenv("EP_QUALITY_POLL_INTERVAL_SEC", "90"))
EP_QUALITY_POLL_PAGE_SIZE = int(os.getenv("EP_QUALITY_POLL_PAGE_SIZE", "500"))
EP_QUALITY_POLL_MAX_TOTAL = int(os.getenv("EP_QUALITY_POLL_MAX_TOTAL", "0"))  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
# –î–ª—è "—Å–≤–µ–∂–∏—Ö" —ç–ø–∏–∑–æ–¥–æ–≤ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SERIES_POLL_GRACE_MIN


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
imgbb_upload_done = threading.Event()   # –°–∏–≥–Ω–∞–ª –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∑–∞–≥—Ä—É–∑–∫–∏
uploaded_image_url = None               # –ó–¥–µ—Å—å —Ö—Ä–∞–Ω–∏—Ç—Å—è —Å—Å—ã–ª–∫–∞ –ø–æ—Å–ª–µ —É–¥–∞—á–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
# Gotify –±–æ–ª—å—à–µ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ APPRISE_URLS –≤–æ–æ–±—â–µ!
APPRISE_OTHER_URLS = os.environ.get("APPRISE_OTHER_URLS", "")
APPRISE_URLS = APPRISE_OTHER_URLS.strip()

apobj = Apprise()
for url in APPRISE_URLS.split():
    apobj.add(url)

# Path for the JSON file to store notified items
#notified_items_file = '/app/data/notified_items.json'
notified_items_file = 'A:/git/notified_items.json'

# === SQLite –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è Movie –Ω–∞ –ø–µ—Ä–≤–æ–º —ç—Ç–∞–ø–µ) ===
QUALITY_DB_FILE = os.path.join(os.path.dirname(notified_items_file), "media_quality.db")
os.makedirs(os.path.dirname(QUALITY_DB_FILE), exist_ok=True)

def _utcnow_iso() -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç –≤ UTC –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO 8601 c 'Z' –Ω–∞ –∫–æ–Ω—Ü–µ,
    –±–µ–∑ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä: 2025-08-31T19:45:00Z).
    """
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')

def _init_quality_db():
    conn = sqlite3.connect(QUALITY_DB_FILE)
    try:
        cur = conn.cursor()
        # —Å–Ω–∏–º–æ–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É ItemId (–∏—Å—Ç–æ—Ä–∏—è)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS media_quality (
            item_id TEXT PRIMARY KEY,
            movie_name TEXT,
            year INTEGER,
            video_codec TEXT,
            video_bitrate INTEGER,
            width INTEGER,
            height INTEGER,
            fps REAL,
            bit_depth INTEGER,
            dynamic_range TEXT,
            audio_codec TEXT,
            audio_bitrate INTEGER,
            audio_channels INTEGER,
            container TEXT,
            size_bytes INTEGER,
            duration_sec REAL,
            signature TEXT,
            date_seen TEXT
        )""")
        # "–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è" –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É (tmdb/imdb –∏–ª–∏ name+year)
        cur.execute("""
        CREATE TABLE IF NOT EXISTS content_quality (
            logical_key TEXT PRIMARY KEY,
            last_item_id TEXT,
            movie_name TEXT,
            year INTEGER,
            video_codec TEXT,
            video_bitrate INTEGER,
            width INTEGER,
            height INTEGER,
            fps REAL,
            bit_depth INTEGER,
            dynamic_range TEXT,
            audio_codec TEXT,
            audio_bitrate INTEGER,
            audio_channels INTEGER,
            container TEXT,
            size_bytes INTEGER,
            duration_sec REAL,
            signature TEXT,
            date_seen TEXT
        )""")
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS recent_quality_updates
                    (
                        logical_key
                        TEXT
                        PRIMARY
                        KEY,
                        notified_at
                        TEXT,
                        item_id
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS season_progress
                    (
                        season_id
                        TEXT
                        PRIMARY
                        KEY,
                        series_id
                        TEXT,
                        series_name
                        TEXT,
                        season_number
                        INTEGER,
                        release_year
                        INTEGER,
                        present
                        INTEGER
                        DEFAULT
                        0, -- —Å–∫–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –µ—Å—Ç—å —Å–µ—Ä–∏–π –Ω–∞ –¥–∏—Å–∫–µ
                        total
                        INTEGER
                        DEFAULT
                        0, -- —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ —Å–µ—Ä–∏–π (present + missing)
                        last_notified_present
                        INTEGER
                        DEFAULT
                        0, -- –¥–æ –∫–∞–∫–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è —É–∂–µ —Å–æ–æ–±—â–∞–ª–∏
                        updated_at
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS external_cache
                    (
                        cache_key
                        TEXT
                        PRIMARY
                        KEY,  -- —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á (—Å–º. –Ω–∏–∂–µ)
                        kind
                        TEXT
                        NOT
                        NULL, -- 'trailer' | 'ratings'
                        subkind
                        TEXT, -- 'movie' | 'show' (–¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤/—Ç—Ä–µ–π–ª–µ—Ä–æ–≤)
                        value
                        TEXT, -- –¥–ª—è —Ç—Ä–µ–π–ª–µ—Ä–∞: URL; –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–æ–≤: –≥–æ—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
                        updated_at
                        TEXT  -- ISO8601 UTC, –∫–æ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–ª–∏
                    )
                    """)
        # –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è/–ë–î
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS app_meta
                    (
                        key
                        TEXT
                        PRIMARY
                        KEY,
                        value
                        TEXT
                    )
                    """)
        cur.execute("""
                    CREATE TABLE IF NOT EXISTS season_quality
                    (
                        season_id
                        TEXT
                        PRIMARY
                        KEY,
                        series_id
                        TEXT,
                        series_name
                        TEXT,
                        season_number
                        INTEGER,
                        release_year
                        INTEGER,
                        signature
                        TEXT, -- –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–Ω–∏–º–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º —ç–ø–∏–∑–æ–¥–∞–º
                        updated_at
                        TEXT  -- ISO
                    )""")
        # –ú–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–∏–º episode_count, –µ—Å–ª–∏ —Å—Ç–æ–ª–±—Ü–∞ –Ω–µ—Ç
        cur.execute("PRAGMA table_info(season_quality)")
        cols = {r[1] for r in cur.fetchall()}
        if "episode_count" not in cols:
            cur.execute("ALTER TABLE season_quality ADD COLUMN episode_count INTEGER")
        # –µ—Å–ª–∏ –Ω–µ—Ç —à—Ç–∞–º–ø–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î ‚Äî –ø—Ä–æ—Å—Ç–∞–≤–∏–º —Å–µ–π—á–∞—Å
        cur.execute("SELECT value FROM app_meta WHERE key='db_created_at'")
        row = cur.fetchone()
        if not row:
            cur.execute("INSERT INTO app_meta(key,value) VALUES('db_created_at', ?)", (_utcnow_iso(),))
        # --- –ú—è–≥–∫–∞—è –º–∏–≥—Ä–∞—Ü–∏—è: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É image_profiles, –µ—Å–ª–∏ –µ—ë –µ—â—ë –Ω–µ—Ç
        try:
            cur.execute("ALTER TABLE media_quality ADD COLUMN image_profiles TEXT")
        except Exception:
            pass
        try:
            cur.execute("ALTER TABLE content_quality ADD COLUMN image_profiles TEXT")
        except Exception:
            pass
        conn.commit()
    finally:
        conn.close()

_init_quality_db()

# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø–∞–ø–∫–∞ /app/data —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
os.makedirs(os.path.dirname(notified_items_file), exist_ok=True)

# Function to load notified items from the JSON file
def load_notified_items():
    # –ï—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å ‚Äî —á–∏—Ç–∞–µ–º
    if os.path.exists(notified_items_file):
        with open(notified_items_file, 'r', encoding='utf-8') as file:
            return json.load(file)
    # –ò–Ω–∞—á–µ ‚Äî —Å–æ–∑–¥–∞—ë–º –ø—É—Å—Ç–æ–π JSON –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
    with open(notified_items_file, 'w', encoding='utf-8') as file:
        json.dump({}, file, ensure_ascii=False, indent=2)
    return {}

# Function to save notified items to the JSON file
def save_notified_items(notified_items_to_save):
    with open(notified_items_file, 'w', encoding='utf-8') as file:
        json.dump(notified_items_to_save, file, ensure_ascii=False, indent=2)


notified_items = load_notified_items()

# 2. –°–ª–æ–≤–∞—Ä—å –ø–µ—Ä–µ–≤–æ–¥–æ–≤
MESSAGES = {
    "en": {
        "new_movie_title": "üçøNew Movie Addedüçø",
        "new_season_title": "üì∫New Season Addedüì∫",
        "new_episode_title": "üì∫New Episode Addedüì∫",
        "new_album_title": "üéµNew Album Addedüéµ",
        "new_runtime": "üïíRuntimeüïí",
        "new_ratings_movie": "‚≠êRatings movie‚≠ê",
        "new_ratings_show": "‚≠êRatings show‚≠ê",
        "new_trailer": "Trailer",
        "new_release_date": "Release Date",
        "new_series": "Series",
        "new_episode_t": "Episode Title",
        "audio_tracks": "Audio tracks",
        "image_profiles": "Image profiles",
        "quality_updated": "üîºQuality updateüîº",
        "season_added_progress": "Added {added} of {total} episodes",
        "season_added_count_only": "Added {added} episodes",
    },
    "ru": {
        "new_movie_title": "üçø–ù–æ–≤—ã–π —Ñ–∏–ª—å–º –¥–æ–±–∞–≤–ª–µ–Ωüçø",
        "new_season_title": "üì∫–ù–æ–≤—ã–π —Å–µ–∑–æ–Ω –¥–æ–±–∞–≤–ª–µ–Ωüì∫",
        "new_episode_title": "üì∫–ù–æ–≤—ã–π —ç–ø–∏–∑–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ωüì∫",
        "new_album_title": "üéµ–ù–æ–≤—ã–π –∞–ª—å–±–æ–º –¥–æ–±–∞–≤–ª–µ–Ωüéµ",
        "new_runtime": "üïí–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—åüïí",
        "new_ratings_movie": "‚≠ê–†–µ–π—Ç–∏–Ω–≥–∏ —Ñ–∏–ª—å–º–∞‚≠ê",
        "new_ratings_show": "‚≠ê–†–µ–π—Ç–∏–Ω–≥–∏ —Å–µ—Ä–∏–∞–ª–∞‚≠ê",
        "new_trailer": "–¢—Ä–µ–π–ª–µ—Ä",
        "new_release_date": "–î–∞—Ç–∞ –≤—ã—Ö–æ–¥–∞",
        "new_series": "–°–µ—Ä–∏–∞–ª",
        "new_episode_t": "–ù–∞–∑–≤–∞–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∞",
        "audio_tracks": "–ê—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏",
        "image_profiles": "–ü—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "quality_updated": "üîº–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞üîº",
        "season_added_progress": "–î–æ–±–∞–≤–ª–µ–Ω–æ {added} –∏–∑ {total} —Å–µ—Ä–∏–π",
        "season_added_count_only": "–î–æ–±–∞–≤–ª–µ–Ω–æ {added} —Å–µ—Ä–∏–π",
    }
}
#–í—ã–±–∏—Ä–∞–µ–º —Ä–∞–±–æ—á–∏–π —è–∑—ã–∫: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–Ω—ã–π –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ MESSAGES ‚Äî —Å—Ç–∞–≤–∏–º en
LANG = LANGUAGE if LANGUAGE in MESSAGES else "en"

def t(key: str) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –ø–æ –∫–ª—é—á—É –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —è–∑—ã–∫–∞ LANG.
    –ï—Å–ª–∏ –∫–ª—é—á –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî –ø–∞–¥–∞–µ—Ç KeyError, —á—Ç–æ–±—ã –≤—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–≤–æ–¥–∞.
    """
    return MESSAGES[LANG][key]

#–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
def _task_name_matches(name: str | None) -> bool:
    if not name:
        return False
    n = name.lower()
    return any(seg in n for seg in SCAN_TASK_NAME_MATCH)

def is_jellyfin_scanning() -> tuple[bool, str | None]:
    """
    –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å, –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ª–∏ —Å–µ–π—á–∞—Å —Å–∫–∞–Ω/—Ä–µ—Ñ—Ä–µ—à –º–µ–¥–∏–∞—Ç–µ–∫–∏/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ Jellyfin.
    1) /emby/ScheduledTasks/Running (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
    2) /emby/ScheduledTasks (–∏—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è Running/Executing/IsRunning)
    –í–æ–∑–≤—Ä–∞—Ç: (True/False, –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ)
    """
    headers = {'accept': 'application/json'}
    params = {'api_key': JELLYFIN_API_KEY}

    # 1) —Ç–µ–∫—É—â–∏–µ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã–µ –∑–∞–¥–∞—á–∏
    try:
        url = f"{JELLYFIN_BASE_URL}/emby/ScheduledTasks/Running"
        r = requests.get(url, headers=headers, params=params, timeout=6)
        if r.status_code == 200:
            data = r.json() or []
            for t in data:
                name = t.get("Name") or t.get("Key") or ""
                state = t.get("State") or ""
                prog = t.get("CurrentProgressPercentage") or t.get("Progress") or t.get("PercentComplete")
                if _task_name_matches(name):
                    desc = f"{name} {prog}%" if prog is not None else name
                    return True, desc
    except Exception:
        pass

    # 2) –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á
    try:
        url = f"{JELLYFIN_BASE_URL}/emby/ScheduledTasks"
        r = requests.get(url, headers=headers, params=params, timeout=8)
        if r.status_code == 200:
            data = r.json() or []
            for t in data:
                name = t.get("Name") or t.get("Key") or ""
                state = (t.get("State") or "").lower()
                is_running = bool(t.get("IsRunning")) or state in ("running", "executing", "inprogress")
                if is_running and _task_name_matches(name):
                    prog = t.get("CurrentProgressPercentage") or t.get("Progress") or t.get("PercentComplete")
                    desc = f"{name} {prog}%" if prog is not None else name
                    return True, desc
    except Exception:
        pass

    return False, None

def wait_until_scan_idle(reason: str = ""):
    """
    –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω NOTIFY_BLOCK_DURING_SCAN ‚Äî –∂–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–∫–∞–Ω–∞ Jellyfin.
    MAX_SCAN_WAIT_MIN=0 => –∂–¥—ë–º –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ.
    """
    if not NOTIFY_BLOCK_DURING_SCAN:
        return
    start = time.time()
    first_log = True
    while True:
        running, detail = is_jellyfin_scanning()
        if not running:
            if not first_log:
                logging.info("Jellyfin scan finished, resume timers.")
            return
        if first_log:
            logging.info(f"Timers paused: Jellyfin is scanning ({detail or 'library task running'})"
                         + (f" [reason: {reason}]" if reason else ""))
            first_log = False
        if MAX_SCAN_WAIT_MIN and (time.time() - start) > MAX_SCAN_WAIT_MIN * 60:
            logging.warning("Max wait for scan reached; resuming timers anyway.")
            return
        time.sleep(max(SCAN_RECHECK_DELAY_SEC, 1))

def _movie_poll_loop():
    while True:
        try:
            wait_until_scan_idle("movie poll")
            poll_recent_movies_once()
        except Exception as ex:
            logging.warning(f"Movie poll loop error: {ex}")
        time.sleep(MOVIE_POLL_INTERVAL_SEC)

def _series_poll_loop():
    while True:
        try:
            wait_until_scan_idle("series poll")
            poll_recent_episodes_once()
        except Exception as ex:
            logging.warning(f"Series poll loop error: {ex}")
        time.sleep(SERIES_POLL_INTERVAL_SEC)

def _wa_get_jid_from_env():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç JID –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    –ï—Å–ª–∏ –∑–∞–¥–∞–Ω–∞ –≥—Ä—É–ø–ø–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≥—Ä—É–ø–ø—É.
    –ò–Ω–∞—á–µ –ª–∏—á–Ω—ã–π —á–∞—Ç –∏–∑ WHATSAPP_JID –∏–ª–∏ WHATSAPP_NUMBER.
    """
    group_jid = WHATSAPP_GROUP_JID.strip()
    if group_jid:
        if not group_jid.endswith("@g.us"):
            # –¥–æ–ø—É—Å—Ç–∏–º, –ø–µ—Ä–µ–¥–∞–ª–∏ —Ç–æ–ª—å–∫–æ id –±–µ–∑ @g.us
            group_jid = re.sub(r"[^\w\-]", "", group_jid) + "@g.us"
        return group_jid

    # –õ–∏—á–Ω—ã–π
    raw = (WHATSAPP_JID or WHATSAPP_NUMBER).strip()
    if not raw:
        return None
    if raw.endswith("@s.whatsapp.net"):
        return raw
    # –æ—á–∏—â–∞–µ–º –¥–æ —Ü–∏—Ñ—Ä –∏ –¥–æ–±–∞–≤–ª—è–µ–º –¥–æ–º–µ–Ω
    local = re.sub(r"\D", "", raw)
    return f"{local}@s.whatsapp.net" if local else None

def jellyfin_get_tmdb_id(item_id: str) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç TMDB ID –¥–ª—è –ª—é–±–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ Jellyfin –ø–æ –µ–≥–æ Id.
    –ß–∏—Ç–∞–µ—Ç Items?Ids=...&Fields=ProviderIds –∏ –±–µ—Ä—ë—Ç –Ω—É–∂–Ω—ã–π –∫–ª—é—á –∏–∑ ProviderIds.
    """
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "Ids": item_id,
            "Fields": "ProviderIds"
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=8)
        r.raise_for_status()
        items = (r.json() or {}).get("Items") or []
        if not items:
            return None
        prov = items[0].get("ProviderIds") or {}
        # —Ä–∞–∑–Ω—ã–µ —Å–µ—Ä–≤–µ—Ä–∞/–≤–µ—Ä—Å–∏–∏ –º–æ–≥—É—Ç –∑–≤–∞—Ç—å –∫–ª—é—á –ø–æ-—Ä–∞–∑–Ω–æ–º—É ‚Äî —É—á—Ç—ë–º –≤–∞—Ä–∏–∞–Ω—Ç—ã
        return prov.get("Tmdb") or prov.get("TmdbId") or prov.get("TMDB") or None
    except Exception as ex:
        logging.warning(f"Failed to read ProviderIds for {item_id}: {ex}")
        return None


def fetch_mdblist_ratings(content_type: str, tmdb_id: str) -> str:
    """
    –ó–∞–ø—Ä–æ—Å –∫ https://api.mdblist.com/tmdb/{type}/{tmdbId}
    –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Ä–µ–π—Ç–∏–Ω–≥–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –≤–∏–¥–∞:
      "- IMDb: 7.8\n- Rotten Tomatoes: 84%\n‚Ä¶"
    –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø—Ä–∏ –æ—à–∏–±–∫–µ/–æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–∞–Ω–Ω—ã—Ö.
    """
    url = f"https://api.mdblist.com/tmdb/{content_type}/{tmdb_id}?apikey={MDBLIST_API_KEY}"
    try:
        resp = requests.get(url, timeout=10)
        resp.raise_for_status()
        data = resp.json()
        ratings = data.get("ratings")
        if not isinstance(ratings, list):
            return ""

        lines = []
        for r in ratings:
            source = r.get("source")
            value = r.get("value")
            if source is None or value is None:
                continue
            lines.append(f"- {source}: {value}")

        return "\n".join(lines)
    except requests.RequestException as e:
        app.logger.warning(f"MDblist API error for {content_type}/{tmdb_id}: {e}")
        return ""

def upload_image_to_imgbb(image_bytes):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ imgbb.com (–¥–æ 3 –ø–æ–ø—ã—Ç–æ–∫) –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏.
    """
    global uploaded_image_url
    uploaded_image_url = None
    imgbb_upload_done.clear()  # –°–±—Ä–æ—Å —Å–æ–±—ã—Ç–∏—è

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞ API
    if not IMGBB_API_KEY:
        logging.debug("IMGBB_API_KEY –Ω–µ –∑–∞–¥–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –Ω–∞ imgbb.")
        imgbb_upload_done.set()  # –°–∏–≥–Ω–∞–ª –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ (–ø—Ä–æ–ø—É—Å–∫ –∑–∞–≥—Ä—É–∑–∫–∏)
        return None

    url = "https://api.imgbb.com/1/upload"
    payload = {
        "key": IMGBB_API_KEY,
        "image": base64.b64encode(image_bytes).decode('utf-8')
    }

    for attempt in range(1, 4):
        try:
            logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb #{attempt}")
            response = requests.post(url, data=payload, timeout=20)
            response.raise_for_status()
            data = response.json()
            uploaded_image_url = data['data']['url']
            logging.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞ imgbb: {uploaded_image_url}")
            break
        except Exception as ex:
            logging.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ imgbb (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {ex}")
            if attempt < 3:
                time.sleep(2)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

    imgbb_upload_done.set()  # –°–∏–≥–Ω–∞–ª, —á—Ç–æ –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (—É—Å–ø–µ—à–Ω–æ –∏–ª–∏ –Ω–µ—Ç)
    return uploaded_image_url

def wait_for_imgbb_upload():
    """
    –ë–ª–æ–∫–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    imgbb_upload_done.wait()
    return uploaded_image_url


def get_jellyfin_image_and_upload_imgbb(photo_id):
    """
    –°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ–≥–æ –Ω–∞ imgbb, –≤–æ–∑–≤—Ä–∞—â–∞—è –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É.
    """
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    try:
        resp = requests.get(jellyfin_image_url)
        resp.raise_for_status()
        return upload_image_to_imgbb(resp.content)
    except Exception as ex:
        logging.warning(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∏–∑ Jellyfin: {ex}")
        return None

def send_discord_message(photo_id, message, title="Jellyfin", uploaded_url=None):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ Discord —á–µ—Ä–µ–∑ Webhook.
    –ö–∞—Ä—Ç–∏–Ω–∫—É –±–µ—Ä—ë–º –ù–ê–ü–†–Ø–ú–£–Æ –∏–∑ Jellyfin –∏ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª.
    Embed —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –Ω–µ—ë —á–µ—Ä–µ–∑ attachment://filename.
    """
    if not DISCORD_WEBHOOK_URL:
        logging.warning("DISCORD_WEBHOOK_URL not set, skipping Discord notification.")
        return None

    # 1) —Ç—è–Ω–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    image_bytes = None
    filename = "poster.jpg"
    mimetype = "image/jpeg"
    try:
        r = requests.get(jellyfin_image_url, timeout=30)
        r.raise_for_status()
        image_bytes = r.content
        ct = r.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
        if "png" in ct:
            filename, mimetype = "poster.png", "image/png"
        elif "webp" in ct:
            filename, mimetype = "poster.webp", "image/webp"
    except Exception as ex:
        logging.warning(f"Discord: failed to fetch image from Jellyfin: {ex}")

    # 2) –≥–æ—Ç–æ–≤–∏–º payload
    payload = {
        "username": title,
        "content": message
    }

    # –µ—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∞ ‚Äî –¥–æ–±–∞–≤–∏–º embed, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ attachment
    if image_bytes:
        payload["embeds"] = [{
            "image": {"url": f"attachment://{filename}"}
        }]

    try:
        if image_bytes:
            # multipart: payload_json + —Ñ–∞–π–ª
            files = {
                "file": (filename, image_bytes, mimetype)
            }
            resp = requests.post(
                DISCORD_WEBHOOK_URL,
                data={"payload_json": json.dumps(payload, ensure_ascii=False)},
                files=files,
                timeout=30
            )
        else:
            # –±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ–±—ã—á–Ω—ã–π JSON
            resp = requests.post(DISCORD_WEBHOOK_URL, json=payload, timeout=30)

        resp.raise_for_status()
        logging.info("Discord notification sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Error sending to Discord: {ex}")
        return None

def clean_markdown_for_apprise(text):
    """
    –£–ø—Ä–æ—â–∞–µ—Ç markdown-–ø–æ–¥–æ–±–Ω—ã–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –¥–ª—è plain text –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç —Å—Å—ã–ª–∫–∏ –∫ –µ–¥–∏–Ω–æ–º—É –≤–∏–¥—É:
    - [—Ç–µ–∫—Å—Ç](url) -> url
    - –£–±–∏—Ä–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–æ–¥—Ä—è–¥ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ url
    - –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å 'üé• <–ø–µ—Ä–µ–≤–æ–¥ new_trailer>:' –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —Å—Å—ã–ª–∫–æ–π (–±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
    - –û—á–∏—â–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º —Å—Ç—Ä–æ–∫
    """
    if not text:
        return text

    # 0) –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –º–µ—Ç–∫—É –¥–ª—è "–¢—Ä–µ–π–ª–µ—Ä"
    try:
        trailer_label = t("new_trailer")
    except Exception:
        trailer_label = MESSAGES.get(LANG, {}).get("new_trailer", "Trailer")
    if not trailer_label:
        trailer_label = "Trailer"
    # 1) [—Ç–µ–∫—Å—Ç](url) -> url
    text = re.sub(r'\[([^\]]+)\]\((https?://[^\s)]+)\)', r'\2', text)

    # 2) –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL
    text = re.sub(r'(https?://\S+)(\s*\1)+', r'\1', text)

    # 3) –°–Ω–∞—á–∞–ª–∞ —É–±–∏—Ä–∞–µ–º —É–∂–µ –ø—Ä–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã,
    #    –∑–∞—Ç–µ–º –¥–æ–±–∞–≤–∏–º –∏—Ö –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–Ω–æ
    prefix_pattern = rf'üé•\s*{re.escape(trailer_label)}[:]?\s*'
    text = re.sub(rf'{prefix_pattern}(https?://\S+)', r'\1', text)

    # 4) –ü—Ä–µ—Ñ–∏–∫—Å—É–µ–º –¢–û–õ–¨–ö–û –Ω–µ-musicbrainz —Å—Å—ã–ª–∫–∏ (—á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫)
    def _prefix_non_mb(m):
        url = m.group(1)
        if re.search(r'https?://(?:[^/\s)]+\.)*musicbrainz\.org(?=[/\s)]|$)', url, re.IGNORECASE):
            return url
        return f'üé• {trailer_label}: {url}'

    text = re.sub(r'(https?://\S+)', _prefix_non_mb, text)
    # 5) –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º —Å—Ç—Ä–æ–∫ (—Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã)
    text = '\n'.join(line.strip() for line in text.split('\n'))

    # –£–±—Ä–∞—Ç—å *–∂–∏—Ä–Ω—ã–π* –∏ _–∫—É—Ä—Å–∏–≤_
    text = re.sub(r'(\*|_){1,3}(.+?)\1{1,3}', r'\2', text)

    return text

def sanitize_whatsapp_text(text: str) -> str:
    if not text:
        return text

    # –ë–µ—Ä—ë–º —è–∑—ã–∫ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    lang = os.environ.get("LANGUAGE", "en")
    trailer_label = MESSAGES.get(lang, {}).get("new_trailer")

    # 1) –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º [–ª—é–±–æ–π —Ç–µ–∫—Å—Ç](https://...) –≤ –ø—Ä–æ—Å—Ç–æ https://...
    text = re.sub(r'\[([^\]]+)\]\((https?://[^\)]+)\)', r'\2', text)

    # 2) –£–±–∏—Ä–∞–µ–º –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –æ–¥–Ω–æ–≥–æ –∏ —Ç–æ–≥–æ –∂–µ URL
    text = re.sub(r'(https?://\S+)(\s*\1)+', r'\1', text)


    # 3) –°–Ω–æ—Å–∏–º —É–∂–µ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã (–Ω–∞ –≤—Å—è–∫–∏–π)
    prefix_re = rf'üé•\s*{re.escape(trailer_label)}:?[\s]*'
    text = re.sub(rf'{prefix_re}(https?://\S+)', r'\1', text)

    # 4) –ü—Ä–µ—Ñ–∏–∫—Å—É–µ–º –¢–û–õ–¨–ö–û –Ω–µ-musicbrainz —Å—Å—ã–ª–∫–∏ (—á–µ—Ä–µ–∑ –∫–æ–ª–±—ç–∫)
    def _prefix_non_mb(m):
        url = m.group(1)
        if re.search(r'https?://(?:[^/\s)]+\.)*musicbrainz\.org(?=[/\s)]|$)', url, re.IGNORECASE):
            return url
        return f'üé• {trailer_label} {url}'

    text = re.sub(r'(https?://\S+)', _prefix_non_mb, text)

    # 5) –ß–∏—Å—Ç–∏–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'[ \t]+', ' ', text).strip()

    return text

def send_email_with_image_jellyfin(photo_id: str, subject: str, body_markdown: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email —Å:
      - text/plain (plain-–≤–µ—Ä—Å–∏—è —Ç–µ–∫—Å—Ç–∞)
      - text/html (Markdown ‚Üí HTML)
      - inline-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –∏–∑ Jellyfin (—á–µ—Ä–µ–∑ CID)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True/False.
    """
    if not (SMTP_HOST and SMTP_FROM and SMTP_TO):
        logging.debug("Email disabled or misconfigured; skip.")
        return False

    # plain-–≤–µ—Ä—Å–∏—è (–±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à –æ—á–∏—Å—Ç–∏—Ç–µ–ª—å
    body_plain = clean_markdown_for_apprise(body_markdown or "")

    # HTML-–≤–µ—Ä—Å–∏—è ‚Äî —Ä–µ–Ω–¥–µ—Ä–∏–º –∏–∑ Markdown
    # extensions –¥–ª—è –±–æ–ª–µ–µ –ø—Ä–∏—è—Ç–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤/–ø–µ—Ä–µ–Ω–æ—Å–æ–≤
    body_html_rendered = markdown.markdown(
        body_markdown or "",
        extensions=["extra", "sane_lists", "nl2br"]
    )

    # –¢—è–Ω–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ Jellyfin (—Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏)
    img_bytes = None
    img_subtype = "jpeg"
    try:
        img_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        # subtype –ø–æ–¥–±–µ—Ä—ë–º –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ (–µ—Å–ª–∏ –µ—Å—Ç—å headers –≤ —Ä–µ—Ç—Ä–∞–µ ‚Äî –º–æ–∂–Ω–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤–º–µ—Å—Ç–µ)
        # –∑–¥–µ—Å—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º jpeg; –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    except Exception as ex:
        logging.warning(f"Email: failed to fetch Jellyfin image: {ex}")

    msg = EmailMessage()
    msg["Subject"] = subject or SMTP_SUBJECT
    msg["From"]    = SMTP_FROM
    recipients = [x.strip() for x in re.split(r"[,\s]+", SMTP_TO) if x.strip()]
    msg["To"]     = ", ".join(recipients)
    msg["Date"]   = formatdate(localtime=True)

    # 1) text/plain
    msg.set_content(body_plain or "")

    # 2) text/html (+ inline image –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏)
    if img_bytes:
        cid = make_msgid()  # –≤–∏–¥–∞ <...@domain>
        html_part = f"""\
<html>
  <body>
    <div>{body_html_rendered}</div>
    <p><img src="cid:{cid[1:-1]}" alt="poster"></p>
  </body>
</html>"""
        msg.add_alternative(html_part, subtype="html")
        try:
            # –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∫ HTML-—á–∞—Å—Ç–∏ –∫–∞–∫ related
            msg.get_payload()[1].add_related(img_bytes, maintype="image", subtype=img_subtype, cid=cid)
        except Exception as ex:
            logging.warning(f"Email: cannot embed inline image (fallback as attachment): {ex}")
            msg.add_attachment(img_bytes, maintype="image", subtype=img_subtype, filename="poster.jpg")
    else:
        # –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –ø—Ä–æ—Å—Ç–æ HTML –±–µ–∑ —Ç–µ–≥–∞ <img>
        msg.add_alternative(f"<html><body>{body_html_rendered}</body></html>", subtype="html")

    # –û—Ç–ø—Ä–∞–≤–∫–∞
    try:
        if SMTP_USE_SSL or SMTP_PORT == 465:
            with smtplib.SMTP_SSL(SMTP_HOST, SMTP_PORT, timeout=30) as s:
                if SMTP_USER:
                    s.login(SMTP_USER, SMTP_PASS)
                s.send_message(msg)
        else:
            with smtplib.SMTP(SMTP_HOST, SMTP_PORT, timeout=30) as s:
                if SMTP_USE_TLS:
                    s.starttls()
                if SMTP_USER:
                    s.login(SMTP_USER, SMTP_PASS)
                s.send_message(msg)
        logging.info("Email notification (Markdown->HTML) sent successfully")
        return True
    except Exception as ex:
        logging.warning(f"Email send failed: {ex}")
        return False

def _slack_try_join_channel(channel_id: str) -> bool:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –±–æ—Ç–∞ –≤ PUBLIC-–∫–∞–Ω–∞–ª (—Ç—Ä–µ–±—É–µ—Ç scope channels:join).
    –î–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç ‚Äî –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é /invite –≤ Slack.
    """
    if not (SLACK_BOT_TOKEN and channel_id):
        return False
    try:
        resp = requests.post(
            "https://slack.com/api/conversations.join",
            headers={
                "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
                "Content-Type": "application/json; charset=utf-8",
            },
            json={"channel": channel_id},
            timeout=15,
        )
        data = resp.json()
        if not data.get("ok"):
            logging.debug(f"Slack join failed/ignored: {data.get('error')}")
            return False
        return True
    except Exception as ex:
        logging.debug(f"Slack join error: {ex}")
        return False

def send_slack_text_only(message_markdown: str) -> bool:
    """
    –§–æ–ª–ª–±—ç–∫ –Ω–∞ —á–∞—Ç –±–µ–∑ —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç chat.postMessage.
    """
    if not (SLACK_BOT_TOKEN and SLACK_CHANNEL_ID):
        logging.debug("Slack disabled/misconfigured; skip text.")
        return False

    url = "https://slack.com/api/chat.postMessage"
    # Slack –ø–æ–Ω–∏–º–∞–µ—Ç mrkdwn (–Ω–µ —Å–æ–≤—Å–µ–º Markdown). –ú–æ–∂–Ω–æ —Å–ª–µ–≥–∫–∞ ¬´–æ—á–∏—Å—Ç–∏—Ç—å¬ª —Ç–µ–∫—Å—Ç:
    text_plain = sanitize_whatsapp_text(message_markdown) or ""

    headers = {
        "Authorization": f"Bearer {SLACK_BOT_TOKEN}",
        "Content-Type": "application/json; charset=utf-8",
    }
    payload = {
        "channel": SLACK_CHANNEL_ID,
        "text": text_plain,
        "mrkdwn": True,
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        if not data.get("ok"):
            logging.warning(f"Slack chat.postMessage error: {data}")
            return False
        logging.info("Slack text message sent successfully")
        return True
    except Exception as ex:
        logging.warning(f"Slack text send failed: {ex}")
        return False


def send_slack_message_with_image_from_jellyfin(photo_id: str, caption_markdown: str) -> bool:
    """
    Slack: –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –ø–æ –Ω–æ–≤–æ–º—É –ø–æ—Ç–æ–∫—É:
      1) files.getUploadURLExternal (–ø–æ–ª—É—á–∞–µ–º upload_url –∏ file_id)
      2) POST –±–∞–π—Ç–æ–≤ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞ upload_url
      3) files.completeUploadExternal (channel_id + initial_comment)
    –§–æ–ª–ª–±—ç–∫: –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ chat.postMessage.
    """
    if not (SLACK_BOT_TOKEN and SLACK_CHANNEL_ID):
        logging.debug("Slack disabled/misconfigured; skip.")
        return False

    # 1) –¥–æ—Å—Ç–∞—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ Jellyfin
    img_bytes = None
    filename = "poster.jpg"
    mimetype = "image/jpeg"
    try:
        if "_fetch_jellyfin_primary" in globals():
            b, mt, fn = _fetch_jellyfin_primary(photo_id)
            img_bytes, mimetype, filename = b, mt, fn
        else:
            jf_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
            r = requests.get(jf_url, timeout=30)
            r.raise_for_status()
            img_bytes = r.content
            ct = r.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
            if "png" in ct:
                filename, mimetype = "poster.png", "image/png"
            elif "webp" in ct:
                filename, mimetype = "poster.webp", "image/webp"
    except Exception as ex:
        logging.warning(f"Slack: failed to fetch image from Jellyfin: {ex}")

    if not img_bytes:
        # –Ω–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî –æ—Ç–ø—Ä–∞–≤–∏–º —Ç–µ–∫—Å—Ç
        return send_slack_text_only(caption_markdown)

    # 2) files.getUploadURLExternal
    auth_h = {"Authorization": f"Bearer {SLACK_BOT_TOKEN}"}
    try:
        resp = requests.post(
            "https://slack.com/api/files.getUploadURLExternal",
            headers=auth_h,
            data={"filename": filename, "length": str(len(img_bytes))},
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        if not data.get("ok"):
            logging.warning(f"Slack getUploadURLExternal error: {data}")
            return send_slack_text_only(caption_markdown)
        upload_url = data["upload_url"]
        file_id    = data["file_id"]
    except Exception as ex:
        logging.warning(f"Slack getUploadURLExternal failed: {ex}")
        return send_slack_text_only(caption_markdown)

    # 3) POST —Ñ–∞–π–ª–∞ –Ω–∞ upload_url
    try:
        # –º–æ–∂–Ω–æ —Å—ã—Ä—ã–º–∏ –±–∞–π—Ç–∞–º–∏:
        up_headers = {"Content-Type": mimetype}
        up = requests.post(upload_url, data=img_bytes, headers=up_headers, timeout=60)
        # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ: multipart (–∏–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–∏ –ø—Ä–æ–∫—Å–∏):
        # up = requests.post(upload_url, files={"filename": (filename, img_bytes, mimetype)}, timeout=60)
        if up.status_code != 200:
            logging.warning(f"Slack upload_url returned {up.status_code}: {up.text[:200]}")
            return send_slack_text_only(caption_markdown)
    except Exception as ex:
        logging.warning(f"Slack raw upload failed: {ex}")
        return send_slack_text_only(caption_markdown)

    # 4) files.completeUploadExternal (—à–∞—Ä–∏–º —Ñ–∞–π–ª –≤ –∫–∞–Ω–∞–ª + –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π)
    def _complete_upload():
        comp_payload = {
            "files": [{"id": file_id, "title": filename}],
            "channel_id": SLACK_CHANNEL_ID,
            "initial_comment": sanitize_whatsapp_text(caption_markdown) or "",
        }
        return requests.post(
            "https://slack.com/api/files.completeUploadExternal",
            headers={**auth_h, "Content-Type": "application/json; charset=utf-8"},
            json=comp_payload,
            timeout=30,
        )

    # –ø–æ–ø—ã—Ç–∫–∞ –∑–∞—Ä–∞–Ω–µ–µ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è (–Ω–∞ —Å–ª—É—á–∞–π –ø—É–±–ª–∏—á–Ω–æ–≥–æ –∫–∞–Ω–∞–ª–∞)
    _slack_try_join_channel(SLACK_CHANNEL_ID)

    try:
        comp = _complete_upload()
        comp.raise_for_status()
        comp_data = comp.json()
        if not comp_data.get("ok"):
            if comp_data.get("error") == "not_in_channel":
                # –ø—Ä–æ–±—É–µ–º –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑
                if _slack_try_join_channel(SLACK_CHANNEL_ID):
                    comp = _complete_upload()
                    comp.raise_for_status()
                    comp_data = comp.json()
                    if comp_data.get("ok"):
                        logging.info("Slack image sent successfully (after join).")
                        return True
                logging.warning("Slack: bot is not in the channel. Invite the app (/invite @Bot) and retry.")
            else:
                logging.warning(f"Slack completeUploadExternal error: {comp_data}")
            return send_slack_text_only(caption_markdown)

        logging.info("Slack image (external upload flow) sent successfully")
        return True

    except Exception as ex:
        logging.warning(f"Slack completeUploadExternal failed: {ex}")
        return send_slack_text_only(caption_markdown)

def send_notification(photo_id, caption):
    uploaded_url = get_jellyfin_image_and_upload_imgbb(photo_id)
    """
    1. –í—Å–µ–≥–¥–∞ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ Telegram –Ω–∞–ø—Ä—è–º—É—é (send_telegram_photo).
    2. –ù–µ–∑–∞–≤–∏—Å–∏–º–æ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ Gotify (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω).
    3. –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã ‚Äî —á–µ—Ä–µ–∑ Apprise.
    """
    # –¢–µ–∫—Å—Ç –±–µ–∑ Markdown (–ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è plain-—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞, –≤ —Ç.—á. WhatsApp)
#    caption_plain = clean_markdown_for_apprise(caption)
    if TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID:
        tg_response = send_telegram_photo(photo_id, caption)
        if tg_response and tg_response.ok:
            logging.info("Notification sent via Telegram")
        else:
            # –§–û–õ–ë–≠–ö: —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –¥–≤–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (—Ñ–æ—Ç–æ -> —Ç–µ–∫—Å—Ç)
            logging.warning("Telegram (photo+caption) failed; trying split: photo-only then text‚Ä¶")
            ok_photo = send_telegram_photo_only(photo_id)
            ok_text  = send_telegram_text(caption)
            if ok_photo and ok_text:
                logging.info("Telegram split (photo then text) sent successfully")
            else:
                logging.warning("Telegram split fallback failed")
#    tg_GOTIFY = send_gotify_message(photo_id, caption)

    # Gotify: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞–Ω—ã
#    gotify_message = clean_markdown_for_apprise(caption)
#    gotify_response = None
    if GOTIFY_URL and GOTIFY_TOKEN:
        gotify_response = send_gotify_message(photo_id, caption, uploaded_url=uploaded_url)
        if gotify_response and gotify_response.ok:
            logging.info("Notification sent via Gotify")
        else:
            logging.warning("Notification failed via Gotify")

    # ======= –î–û–ë–ê–í–õ–ï–ù–û –î–õ–Ø DISCORD =======
    if DISCORD_WEBHOOK_URL:
        discord_response = send_discord_message(photo_id, caption, uploaded_url=uploaded_url)
        if discord_response and discord_response.ok:
            logging.info("Notification sent via Discord")
        else:
            logging.warning("Notification failed via Discord")
    # =====================================
    # ======= SLACK: —Ñ–∞–π–ª-–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–º =======
    try:
        if SLACK_BOT_TOKEN and SLACK_CHANNEL_ID:
            ok = send_slack_message_with_image_from_jellyfin(photo_id, caption)
            if ok:
                logging.info("Notification sent via Slack")
            else:
                logging.warning("Notification failed via Slack")
        else:
            logging.debug("Slack disabled or not configured; skip.")
    except Exception as sl_ex:
        logging.warning(f"Slack send failed: {sl_ex}")
    # ======================================================
    # ======= MATRIX (REST): –°–ù–ê–ß–ê–õ–ê –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin, –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç =======
    try:
        if MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID:
            ok = send_matrix_image_then_text_from_jellyfin(photo_id, caption)
            if ok:
                logging.info("Notification sent via Matrix (REST, image from Jellyfin then text)")
            else:
                logging.warning("Matrix (REST, Jellyfin): image+text flow failed; trying text-only fallback")
                send_matrix_text_rest(caption)
        else:
            logging.debug("Matrix disabled or not configured; skip.")
    except Exception as m_ex:
        logging.warning(f"Matrix send failed: {m_ex}")
    # ========================================================================
    # --- –û–¢–ü–†–ê–í–ö–ê –í SIGNAL ---
    # Plain text –¥–ª—è Signal (–±–µ–∑ Markdown)
    if SIGNAL_URL and SIGNAL_NUMBER:
        signal_resp = send_signal_message_with_image(
            photo_id,
            clean_markdown_for_apprise(caption),
            SIGNAL_NUMBER,
            SIGNAL_RECIPIENTS
        )
        if signal_resp and signal_resp.ok:
            logging.info("Notification sent via Signal")
        else:
            logging.warning("Notification failed via Signal")
    # --------------------------

    # ======= EMAIL: –ø–∏—Å—å–º–æ —Å inline-–∫–∞—Ä—Ç–∏–Ω–∫–æ–π –∏–∑ Jellyfin =======
    try:
        email_ok = send_email_with_image_jellyfin(photo_id, subject=SMTP_SUBJECT, body_markdown=caption)
        if email_ok:
            logging.info("Notification sent via Email")
        else:
            logging.warning("Notification failed via Email")
    except Exception as em_ex:
        logging.warning(f"Email send failed: {em_ex}")

    # ======= WHATSAPP: —Å–Ω–∞—á–∞–ª–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∞ —Å –ø–æ–¥–ø–∏—Å—å—é (—Å —Ä–µ—Ç—Ä–∞—è–º–∏), –ø—Ä–∏ –ø—Ä–æ–≤–∞–ª–µ ‚Äî —Ç–µ–∫—Å—Ç =======
    try:
        wa_jid = _wa_get_jid_from_env()
        if WHATSAPP_API_URL and wa_jid:
            ok_img = send_whatsapp_image_with_retries(
                caption=caption,
                phone_jid=wa_jid,
                image_url=uploaded_url
            )
            if not ok_img:
                logging.warning("WhatsApp image failed after retries; sending text-only fallback")
                send_whatsapp_text_via_rest(caption, phone_jid=wa_jid)
        else:
            logging.debug("WhatsApp disabled or no JID; skip WhatsApp send.")
    except Exception as wa_ex:
        logging.warning(f"WhatsApp send block failed: {wa_ex}")

    other_services = [url for url in APPRISE_URLS.split() if url]  # —É–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    if other_services:
        apprise_obj = Apprise()
        for url in other_services:
            apprise_obj.add(url)

        # –ì–æ—Ç–æ–≤–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ (–µ—Å–ª–∏ —Ñ–æ—Ç–æ –µ—Å—Ç—å)

    base_photo_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    attach_param = None
    try:
        image_response = requests.get(base_photo_url)
        if image_response.ok:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
                tmp.write(image_response.content)
                tmp_path = tmp.name
            attach_param = tmp_path
        else:
            attach_param = None
    except Exception as ex:
        logging.warning(f"Cannot download image: {ex}")
        attach_param = None

    caption_plain = clean_markdown_for_apprise(caption)
    result = apobj.notify(
        body=caption_plain,
        title="",
        attach=attach_param
    )

    if attach_param and os.path.exists(attach_param):
        try:
            os.remove(attach_param)
        except Exception as ex:
            logging.warning(f"Cannot remove temp image: {ex}")

    if result:
        logging.info("Notification sent via Apprise")
    else:
        logging.warning("Notification failed via Apprise")
    return None
def _fetch_jellyfin_image_with_retries(photo_id: str, attempts: int = 3, timeout: int = 10, delay: float = 1.5):
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è —Å–∫–∞—á–∞—Ç—å Primary-–ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç bytes –∏–ª–∏ None.
    """
    url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    last_err = None
    for i in range(1, attempts + 1):
        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ)
            head = requests.head(url, timeout=timeout)
            if head.ok:
                resp = requests.get(url, timeout=timeout)
                resp.raise_for_status()
                return resp.content
            else:
                last_err = f"HTTP {head.status_code}"
        except Exception as ex:
            last_err = ex
        logging.warning(f"Jellyfin image try {i}/{attempts} failed: {last_err}")
        if i < attempts:
            time.sleep(delay)
    return None

def send_telegram_photo(photo_id, caption):
    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º caption –¥–æ 1024 —Å–∏–º–≤–æ–ª–æ–≤
    #    if caption and len(caption) > 1024:
    #        caption = caption[:1023] + "..."  # –¥–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–æ–µ—Ç–æ—á–∏–µ, –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∞–µ–º

#        base_photo_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images"
#        primary_photo_url = f"{base_photo_url}/Primary"

        # Download the image from the jellyfin
#        image_response = requests.get(primary_photo_url)

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏
        image_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        if not image_bytes:
            logging.warning("Telegram: Jellyfin image unavailable after retries")
            return None

        # Upload the image to the Telegram bot
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
        data = {
            "chat_id": TELEGRAM_CHAT_ID,
            "caption": caption,
            "parse_mode": "Markdown"
        }

        files = {'photo': ('photo.jpg', image_bytes, 'image/jpeg')}
        response = requests.post(url, data=data, files=files, timeout=30)
        logging.info("Telegram notification sent successfully")
        return response

    except Exception as ex:
        logging.warning(f"Error sending to Telegram: {ex}")
        return None

def send_telegram_photo_only(photo_id):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ñ–æ—Ç–æ (–±–µ–∑ caption) –≤ Telegram.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    try:
        image_bytes = _fetch_jellyfin_image_with_retries(photo_id, attempts=3, timeout=10, delay=1.5)
        if not image_bytes:
            logging.warning("Telegram(photo-only): Jellyfin image unavailable after retries")
            return None

        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendPhoto"
        data = {"chat_id": TELEGRAM_CHAT_ID}
        files = {'photo': ('photo.jpg', image_bytes, 'image/jpeg')}
        resp = requests.post(url, data=data, files=files, timeout=30)
        resp.raise_for_status()
        logging.info("Telegram photo-only sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Telegram photo-only failed: {ex}")
        return None


def send_telegram_text(message: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤ Telegram.
    –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Markdown, –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–∞–¥–∞–µ–º –≤ plain-text (–æ—á–∏—â–µ–Ω–Ω—ã–π).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    if not (TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID):
        return None

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ1: Markdown
        resp = requests.post(url, data={
            "chat_id": TELEGRAM_CHAT_ID,
            "text": message,
            "parse_mode": "Markdown"
        }, timeout=30)
        if resp.ok:
            logging.info("Telegram text sent (Markdown)")
            return resp

        # –ï—Å–ª–∏ –Ω–µ ok ‚Äî –ø—Ä–æ–±—É–µ–º plain
        logging.warning(f"Telegram text markdown failed: {resp.status_code} {resp.text}")
        raise HTTPError(response=resp)

    except Exception as md_ex:
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ2: plain (–æ—á–∏—â–∞–µ–º markdown, —Å—Å—ã–ª–∫–∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–æ—Å—Ç–æ–º—É –≤–∏–¥—É)
            plain = clean_markdown_for_apprise(message) or message
            resp2 = requests.post(url, data={
                "chat_id": TELEGRAM_CHAT_ID,
                "text": plain
            }, timeout=30)
            resp2.raise_for_status()
            logging.info("Telegram text sent (plain fallback)")
            return resp2
        except Exception as ex2:
            logging.warning(f"Telegram text send failed: {ex2}")
            return None

def send_matrix_text_rest(message_markdown: str):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç –≤ Matrix —á–µ—Ä–µ–∑ REST (v3).
    1) –ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π PUT –ø–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏.
    2) –ï—Å–ª–∏ –ø—Ä–æ–∫—Å–∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç PUT (405) ‚Äî –¥–µ–ª–∞–µ—Ç POST —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ —Ç–æ—Ç –∂–µ –ø—É—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç response –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, –∏–Ω–∞—á–µ None.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID):
        logging.debug("Matrix not configured; skip.")
        return None

    try:
        # room_id –≤–∏–¥–∞ "!MNddurK...:example.org" –Ω—É–∂–Ω–æ URL-—ç–Ω–∫–æ–¥–∏—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é
        room_enc = quote(MATRIX_ROOM_ID, safe="")
        base = f"{MATRIX_URL.rstrip('/')}/_matrix/client/v3/rooms/{room_enc}/send/m.room.message"

        headers = {
            "Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}",
            "Content-Type": "application/json",
        }

        # –ß–∏—Å—Ç–∏–º Markdown –¥–ª—è plain-—Ç–µ–∫—Å—Ç–∞ (Matrix –∫–ª–∏–µ–Ω—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–æ–∫–∞–∂—É—Ç)
        body_plain = clean_markdown_for_apprise(message_markdown) or ""
        payload = {"msgtype": "m.text", "body": body_plain}

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π txnId (–≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö)
        txn_id = f"{int(time.time() * 1000)}txt"
        url = f"{base}/{txn_id}"

        # 1) –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å: PUT (—Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—è)
        try:
            resp = requests.put(url, headers=headers, json=payload, timeout=30)
            resp.raise_for_status()
            logging.info("Matrix text sent successfully via PUT v3")
            return resp
        except requests.exceptions.HTTPError as e:
            status = getattr(e.response, "status_code", None)
            if status == 405:
                # 2) –§–æ–ª–ª–±—ç–∫: POST —Ç–µ–º –∂–µ —É—Ä–ª–æ–º (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ reverse-proxy —Ä–µ–∂—É—Ç PUT)
                logging.warning("Matrix PUT blocked (405). Trying POST fallback‚Ä¶")
                resp2 = requests.post(url, headers=headers, json=payload, timeout=30)
                resp2.raise_for_status()
                logging.info("Matrix text sent successfully via POST fallback")
                return resp2
            else:
                logging.warning(f"Matrix text send failed via PUT: {e}")
                return None

    except Exception as ex:
        logging.warning(f"Matrix text send failed: {ex}")
        return None

def matrix_upload_image_rest(image_bytes: bytes, filename: str, mimetype: str = "image/jpeg") -> str | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ Matrix content repo –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç mxc:// URI.
    –ü—Ä–æ–±—É–µ–º v3, –ø—Ä–∏ 404/405/501 ‚Äî —Ñ–æ–ª–ª–±—ç–∫ –Ω–∞ r0.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN):
        logging.debug("Matrix not configured for media upload; skip.")
        return None

    headers = {"Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}", "Content-Type": mimetype}
    base = MATRIX_URL.rstrip("/")
    url_v3 = f"{base}/_matrix/media/v3/upload?filename={quote(filename)}"

    try:
        r = requests.post(url_v3, headers=headers, data=image_bytes, timeout=30)
        r.raise_for_status()
        return r.json().get("content_uri")
    except requests.exceptions.HTTPError as e:
        code = getattr(e.response, "status_code", None)
        if code in (404, 405, 501):
            logging.warning(f"media/v3/upload returned {code}, trying r0‚Ä¶")
            try:
                url_r0 = f"{base}/_matrix/media/r0/upload?filename={quote(filename)}"
                r2 = requests.post(url_r0, headers=headers, data=image_bytes, timeout=30)
                r2.raise_for_status()
                return r2.json().get("content_uri")
            except Exception as ex2:
                logging.warning(f"Matrix r0 upload failed: {ex2}")
                return None
        logging.warning(f"Matrix v3 upload failed: {e}")
        return None
    except Exception as ex:
        logging.warning(f"Matrix upload failed: {ex}")
        return None


def _matrix_send_event_rest(room_id: str, event_type: str, content: dict):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–±—ã—Ç–∏–µ –≤ –∫–æ–º–Ω–∞—Ç—É:
      PUT /_matrix/client/v3/rooms/{roomId}/send/{eventType}/{txnId}
    –ü—Ä–∏ 405 ‚Äî POST –Ω–∞ —Ç–æ—Ç –∂–µ –ø—É—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –∏–ª–∏ None.
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and room_id):
        return None

    room_enc = quote(room_id, safe="")
    base = f"{MATRIX_URL.rstrip('/')}/_matrix/client/v3/rooms/{room_enc}/send/{event_type}"
    txn_id = f"{int(time.time()*1000)}evt"
    url = f"{base}/{txn_id}"
    headers = {"Authorization": f"Bearer {MATRIX_ACCESS_TOKEN}", "Content-Type": "application/json"}

    try:
        resp = requests.put(url, headers=headers, json=content, timeout=30)
        resp.raise_for_status()
        return resp
    except requests.exceptions.HTTPError as e:
        if getattr(e.response, "status_code", None) == 405:
            logging.warning("PUT blocked (405). Trying POST fallback‚Ä¶")
            try:
                resp2 = requests.post(url, headers=headers, json=content, timeout=30)
                resp2.raise_for_status()
                return resp2
            except Exception as ex2:
                logging.warning(f"Matrix POST fallback failed: {ex2}")
                return None
        logging.warning(f"Matrix send event failed via PUT: {e}")
        return None
    except Exception as ex:
        logging.warning(f"Matrix send event failed: {ex}")
        return None

def _fetch_jellyfin_primary(photo_id: str):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (bytes, mimetype, filename) –¥–ª—è Primary-–ø–æ—Å—Ç–µ—Ä–∞ –∏–∑ Jellyfin.
    """
    url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    resp = requests.get(url, timeout=30)
    resp.raise_for_status()
    mimetype = resp.headers.get("Content-Type", "image/jpeg").split(";")[0].strip().lower()
    ext = ".jpg"
    if "png" in mimetype:
        ext = ".png"
    elif "webp" in mimetype:
        ext = ".webp"
    filename = f"poster{ext}"
    return resp.content, mimetype, filename


def send_matrix_image_then_text_from_jellyfin(photo_id: str, caption_markdown: str) -> bool:
    """
    1) –¢—è–Ω–µ–º –ø–æ—Å—Ç–µ—Ä –∏–∑ Jellyfin
    2) –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Matrix (media repo) -> mxc://
    3) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º m.image (body = –∏–º—è —Ñ–∞–π–ª–∞)
    4) –û—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç (m.text)
    """
    if not (MATRIX_URL and MATRIX_ACCESS_TOKEN and MATRIX_ROOM_ID):
        logging.debug("Matrix not configured; skip.")
        return False

    # 1) –∫–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ Jellyfin
    try:
        img_bytes, mimetype, filename = _fetch_jellyfin_primary(photo_id)
    except Exception as ex:
        logging.warning(f"Matrix(JF): cannot fetch image from Jellyfin: {ex}")
        # —Ö–æ—Ç—è –±—ã —Ç–µ–∫—Å—Ç –æ—Ç–ø—Ä–∞–≤–∏–º
        resp_txt = send_matrix_text_rest(caption_markdown)
        return bool(resp_txt and resp_txt.ok)

    # 2) upload -> mxc://
    mxc_uri = matrix_upload_image_rest(img_bytes, filename, mimetype)
    if not mxc_uri:
        logging.warning("Matrix(JF): media upload failed; sending text only.")
        resp_txt = send_matrix_text_rest(caption_markdown)
        return bool(resp_txt and resp_txt.ok)

    # 3) m.image (–í–ê–ñ–ù–û: body ‚Äî –∏–º—è —Ñ–∞–π–ª–∞)
    content_img = {
        "msgtype": "m.image",
        "body": filename,
        "url": mxc_uri,
        "info": {
            "mimetype": mimetype,
            "size": len(img_bytes),
        },
    }
    resp_img = _matrix_send_event_rest(MATRIX_ROOM_ID, "m.room.message", content_img)
    img_ok = bool(resp_img and resp_img.ok)

    # 4) –∑–∞—Ç–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º
    resp_txt = send_matrix_text_rest(caption_markdown)
    txt_ok = bool(resp_txt and resp_txt.ok)

    if img_ok and txt_ok:
        logging.info("Matrix(JF): image then text sent successfully.")
    else:
        logging.warning("Matrix(JF): image+text flow partially/fully failed.")
    return img_ok and txt_ok

def send_gotify_message(photo_id, message, title="Jellyfin", priority=5, uploaded_url=None):
    img_url = wait_for_imgbb_upload()
    if not img_url:
        logging.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –≤ Gotify.")
        return
    """
    –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞–ø—Ä—è–º—É—é –≤ Gotify.
    """
    if not GOTIFY_URL or not GOTIFY_TOKEN:
        logging.warning("GOTIFY_URL or GOTIFY_TOKEN not set, skipping Gotify notification.")
        return None

    if uploaded_url is None:
        uploaded_url = get_jellyfin_image_and_upload_imgbb(photo_id)
    if uploaded_url:
        message = f"![Poster]({uploaded_url})\n\n{message}"
        big_image_url = uploaded_url
    else:
        big_image_url = None

    gotify_url = GOTIFY_URL.rstrip('/')
    url = f"{gotify_url}/message?token={GOTIFY_TOKEN}"

    data = {
        "title": title,
        "message": message,
        "priority": priority,
        "extras": {
            "client::display": {"contentType": "text/markdown"}
        }
    }
    if big_image_url:
        data["extras"]["client::notification"] = {"bigImageUrl": big_image_url}
    headers = {"X-Gotify-Format": "markdown"}

    try:
        response = requests.post(url, json=data, headers=headers)
        response.raise_for_status()
        logging.info("Gotify notification sent successfully")
        return response
    except Exception as ex:
        logging.warning(f"Error sending to Gotify: {ex}")
        return None

def send_signal_message_with_image(photo_id, message, SIGNAL_NUMBER, SIGNAL_RECIPIENTS, api_url=SIGNAL_URL):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin –≤ Signal —á–µ—Ä–µ–∑ base64_attachments.
    """
    # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ Jellyfin
    jellyfin_image_url = f"{JELLYFIN_BASE_URL}/Items/{photo_id}/Images/Primary"
    try:
        image_resp = requests.get(jellyfin_image_url)
        image_resp.raise_for_status()
        image_bytes = image_resp.content
        # –ö–æ–¥–∏—Ä—É–µ–º –≤ base64
        image_b64 = base64.b64encode(image_bytes).decode("utf-8")

        data = {
            "message": message,
            "number": SIGNAL_NUMBER,
            "recipients": SIGNAL_RECIPIENTS if isinstance(SIGNAL_RECIPIENTS, list) else [SIGNAL_RECIPIENTS],
            "base64_attachments": [image_b64],
        }

        resp = requests.post(api_url, json=data)
        resp.raise_for_status()
        logging.info("Signal image message sent successfully")
        return resp
    except Exception as ex:
        logging.warning(f"Error sending Signal image message: {ex}")
        return None


def send_whatsapp_image_via_rest(
    caption: str,
    phone_jid: str = None,
    image_url: str = None,
    view_once: bool = False,
    compress: bool = False,
    duration: int = 0,
    is_forwarded: bool = False,
):
    img_url = wait_for_imgbb_upload()
    if not img_url:
        logging.warning("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –≤ WhatsApp.")
        return
    if not WHATSAPP_API_URL:
        logging.warning("WHATSAPP_API_URL not set, skipping WhatsApp image.")
        return None

    phone_jid = phone_jid or _wa_get_jid_from_env()
    if not phone_jid:
        logging.warning("WhatsApp JID is empty, skip sending image.")
        return None

    url = f"{WHATSAPP_API_URL.rstrip('/')}/send/image"
    auth = (WHATSAPP_API_USERNAME, WHATSAPP_API_PWD)

    form = {
        "phone": phone_jid,
        "caption": sanitize_whatsapp_text(caption or ""),
        "view_once": str(bool(view_once)).lower(),
        "compress": str(bool(compress)).lower(),
        "duration": str(int(duration)),
        "is_forwarded": str(bool(is_forwarded)).lower(),
    }

    files = None
    jellyfin_used = False

    if image_url:
        form["image_url"] = image_url
    else:
        logging.warning("WhatsApp image: image_url –Ω–µ –∑–∞–¥–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—Ç–ø—Ä–∞–≤–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return None

    try:
        resp = requests.post(url, data=form, files=files, auth=auth, timeout=30)
        resp.raise_for_status()
        logging.info("WhatsApp image sent successfully")
        return resp
    except requests.exceptions.RequestException as e:
        logging.warning(f"Error sending WhatsApp image: {e}")
        return None

def send_whatsapp_text_via_rest(message: str, phone_jid: str | None = None):
    """
    –®–ª—ë—Ç –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç. –°–Ω–∞—á–∞–ª–∞ /send/text, –ø—Ä–∏ 404 ‚Äî /send/message.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç response –∏–ª–∏ None.
    """
    if not WHATSAPP_API_URL:
        logging.debug("WhatsApp API URL not set; skip text.")
        return None

    phone_jid = phone_jid or _wa_get_jid_from_env()
    if not phone_jid:
        logging.debug("WhatsApp JID empty; skip text.")
        return None

    base = WHATSAPP_API_URL.rstrip("/")
    url_text = f"{base}/send/text"
    url_msg  = f"{base}/send/message"
    auth = (WHATSAPP_API_USERNAME, WHATSAPP_API_PWD) if (WHATSAPP_API_USERNAME or WHATSAPP_API_PWD) else None

    form = {
        "phone": phone_jid,
        "message": sanitize_whatsapp_text(message or "")
    }

    try:
        r = requests.post(url_text, data=form, auth=auth, timeout=20)
        if r.status_code == 404:
            r = requests.post(url_msg, data=form, auth=auth, timeout=20)
        r.raise_for_status()
        logging.info("WhatsApp text sent successfully")
        return r
    except Exception as ex:
        logging.warning(f"WhatsApp text send failed: {ex}")
        return None

def send_whatsapp_image_with_retries(
    caption: str,
    phone_jid: str | None,
    image_url: str | None = None
) -> bool:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –ø–æ–¥–ø–∏—Å—å—é –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑.
    True –ø—Ä–∏ —É—Å–ø–µ—Ö–µ, False –µ—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å.
    """
    attempts = max(1, WHATSAPP_IMAGE_RETRY_ATTEMPTS)
    delay = max(0, WHATSAPP_IMAGE_RETRY_DELAY_SEC)

    for i in range(1, attempts + 1):
        try:
            resp = send_whatsapp_image_via_rest(
                caption=caption,
                phone_jid=phone_jid,
                image_url=image_url
            )
            ok = (resp is not None) and (getattr(resp, "ok", True))
            if ok:
                logging.info(f"WhatsApp image sent on attempt {i}")
                return True
            else:
                logging.warning(f"WhatsApp image attempt {i} failed (no/negative response)")
        except Exception as ex:
            logging.warning(f"WhatsApp image attempt {i} exception: {ex}")
        if i < attempts:
            time.sleep(delay)
    return False


def get_item_details(item_id):
    headers = {'accept': 'application/json', }
    params = {'api_key': JELLYFIN_API_KEY, }
    url = f"{JELLYFIN_BASE_URL}/emby/Items?Recursive=true&Fields=DateCreated, Overview&Ids={item_id}"
    response = requests.get(url, headers=headers, params=params)
    response.raise_for_status()  # Check if request was successful
    return response.json()


def is_within_last_x_days(date_str, x):
    days_ago = datetime.now() - timedelta(days=x)
    return date_str >= days_ago.isoformat()


def is_not_within_last_x_days(date_str, x):
    days_ago = datetime.now() - timedelta(days=x)
    return date_str < days_ago.isoformat()


def get_youtube_trailer_url(query):
    base_search_url = "https://www.googleapis.com/youtube/v3/search"
    if not YOUTUBE_API_KEY:
        return None
    api_key = YOUTUBE_API_KEY

    params = {
        'part': 'snippet',
        'q': query,
        'type': 'video',
        'key': api_key
    }

    response = requests.get(base_search_url, params=params)
    response.raise_for_status()  # Check for HTTP errors before processing the data
    response_data = response.json()
    video_id = response_data.get("items", [{}])[0].get('id', {}).get('videoId')

    return f"https://www.youtube.com/watch?v={video_id}" if video_id else "Video not found!"


def item_already_notified(item_type, item_name, release_year):
    # –í —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –≤—Å–µ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –µ—â—ë –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏
    if DISABLE_DEDUP:
        logging.debug("Dedup is disabled: treating as NOT notified.")
        return False

    key = f"{item_type}:{item_name}:{release_year}"
    return notified_items.get(key) is True


def mark_item_as_notified(item_type, item_name, release_year, max_items=100):
    # –í —Ä–µ–∂–∏–º–µ —Ç–µ—Å—Ç–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–∏—à–µ–º –≤ —Ñ–∞–π–ª
    if DISABLE_DEDUP:
        logging.debug("Dedup is disabled: NOT recording notified key.")
        return

    key = f"{item_type}:{item_name}:{release_year}"
    notified_items[key] = True

    # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä ¬´–ø–∞–º—è—Ç–∏¬ª
    if len(notified_items) > max_items:
        # –µ—Å–ª–∏ —É–∂–µ —Ö—Ä–∞–Ω–∏—Ç–µ timestamp ‚Äî —É–¥–∞–ª—è–π—Ç–µ —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π; –∏–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ pop –ø–µ—Ä–≤–æ–≥–æ
        notified_items.pop(next(iter(notified_items)))
    save_notified_items(notified_items)

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –≤–∏–¥–µ–æ

def _get_item_media_info_movie(item_id: str) -> dict:
    """
    –¢—è–Ω–µ–º MediaSources/MediaStreams –¥–ª—è —Ñ–∏–ª—å–º–∞ –∏ —É–ø–ª–æ—â–∞–µ–º –≤ dict.
    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º:
      - —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫: audio_tracks + –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
      - –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: image_profiles (['DV','HDR10',...]) –∏ image_profile_str ("DV, HDR10")
    """
    try:
        headers = {'accept': 'application/json'}
        params = {'api_key': JELLYFIN_API_KEY}
        url = f"{JELLYFIN_BASE_URL}/emby/Items?Ids={item_id}&Fields=MediaSources,RunTimeTicks"
        r = requests.get(url, headers=headers, params=params, timeout=12)
        r.raise_for_status()
        data = r.json()
        item = (data.get("Items") or [{}])[0]
        sources = item.get("MediaSources") or []
        if not sources:
            return {}
        src = sources[0]

        container = src.get("Container")
        overall_bitrate = src.get("Bitrate")
        size_bytes = src.get("Size")
        duration_ticks = src.get("RunTimeTicks") or item.get("RunTimeTicks")
        duration_sec = duration_ticks / 10_000_000 if duration_ticks else None

        vcodec = None; vbitrate = None; width = None; height = None; dyn = None; vdepth = None; fps = None
        acodec = None; abitrate = None; channels = None

        audio_tracks = []
        image_profiles = None  # NEW

        for s in (src.get("MediaStreams") or []):
            stype = s.get("Type")
            if stype == "Video" and vcodec is None:
                # ... –≤–∞—à –∫–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ–ª–µ–π ...
                try:
                    image_profiles = _detect_image_profiles_from_fields(s)
                except Exception:
                    image_profiles = None
                # >>> –§–û–õ–ë–≠–ö
                if not image_profiles:
                    image_profiles = ["SDR"]
                # <<<
                vcodec = s.get("Codec")
                vbitrate = s.get("BitRate") or s.get("bitrate") or overall_bitrate
                width = s.get("Width"); height = s.get("Height")
                fps = s.get("AverageFrameRate") or s.get("RealFrameRate")
                vdepth = s.get("BitDepth") or s.get("VideoBitDepth")
                dyn = s.get("ColorTransfer") or s.get("VideoRange") or s.get("ColorPrimaries")
                if isinstance(dyn, str):
                    u = dyn.upper()
                    dyn = "HDR" if ("PQ" in u or "HLG" in u or "HDR" in u or "BT2020" in u) else "SDR"

                # NEW: –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (DV / HDR10+ / HDR10 / HLG / HDR / SDR)
                try:
                    image_profiles = _detect_image_profiles_from_fields(s)
                except Exception:
                    image_profiles = None

            elif stype == "Audio":
                # –æ—Å–Ω–æ–≤–Ω–æ–π –∞—É–¥–∏–æ-—Å–Ω–∏–º–æ–∫ (–¥–ª—è —Å–≤–æ–¥–∫–∏)
                if acodec is None:
                    acodec = s.get("Codec")
                    abitrate = s.get("BitRate") or s.get("bitrate")
                    channels = s.get("Channels")
                # —á–∏—Ç–∞–µ–º ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ¬ª –∏–º—è –¥–æ—Ä–æ–∂–∫–∏
                label = s.get("DisplayTitle") or s.get("Title")
                if not label:
                    lang = s.get("Language")
                    codec = s.get("Codec")
                    ch = s.get("Channels")
                    layout = s.get("ChannelLayout")
                    parts = []
                    if lang:   parts.append(str(lang).upper())
                    if codec:  parts.append(str(codec).upper())
                    if ch:     parts.append(f"{ch}ch")
                    if layout: parts.append(layout)
                    label = " ".join(parts) or "Audio"
                audio_tracks.append(label)

        approx_kbps = None
        if (not vbitrate) and size_bytes and duration_sec and duration_sec > 0:
            approx_kbps = int((size_bytes * 8) / duration_sec / 1000)

        return {
            "video_codec": vcodec,
            "video_bitrate": vbitrate,
            "approx_video_kbps": approx_kbps,
            "width": width,
            "height": height,
            "fps": fps,
            "bit_depth": vdepth,
            "dynamic_range": dyn or "SDR",
            "audio_codec": acodec,
            "audio_bitrate": abitrate,
            "audio_channels": channels,
            "container": container,
            "size_bytes": size_bytes,
            "duration_sec": duration_sec,
            # –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏
            "audio_tracks": audio_tracks,
            "audio_track_count": len(audio_tracks),
            # NEW: –ø—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Ñ–æ–ª–±—ç–∫–æ–º
            "image_profiles": image_profiles or ["SDR"],
            "image_profile_str": ", ".join(image_profiles or ["SDR"]),
        }
    except Exception as ex:
        logging.warning(f"Media info fetch failed for movie {item_id}: {ex}")
        return {}

def build_audio_tracks_block(q: dict) -> str:
    tracks = (q or {}).get("audio_tracks") or []
    if not tracks:
        return ""
    header = t("audio_tracks")
    lines = "\n".join(f"- {name}" for name in tracks)
    return f"\n\n*{header} ({len(tracks)})*\n{lines}"

def _quality_signature(q: dict) -> str:
    """
    –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π –∫–ª—é—á –∫–∞—á–µ—Å—Ç–≤–∞: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–µ–∞–ª—å–Ω–æ–π –∑–∞–º–µ–Ω–µ —Ñ–∞–π–ª–∞.
    """
    def part(x): return "-" if x in (None, "", 0) else str(x)
    vbr = q.get("video_bitrate") or q.get("approx_video_kbps")
    return "|".join([
        part(q.get("video_codec")),
        f"{part(q.get('width'))}x{part(q.get('height'))}",
        part(vbr),
        part(q.get("dynamic_range")),
        part(q.get("bit_depth")),
        part(q.get("fps")),
        part(q.get("audio_codec")),
        part(q.get("audio_channels")),
        part(q.get("audio_bitrate")),
        part(q.get("container")),
        part(q.get("size_bytes")),
    ])

def _quality_is_substantial(q: dict | None) -> bool:
    """False, –µ—Å–ª–∏ ¬´–ø—É—Å—Ç–æ–π¬ª —Å–Ω–∏–º–æ–∫ (Jellyfin –µ—â—ë –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª –ø–æ—Ç–æ–∫–∏)."""
    if not q: return False
    return any([
        q.get("video_codec"),
        (q.get("width") and q.get("height")),
        q.get("audio_codec"),
        q.get("container"),
        q.get("size_bytes"),
    ])

def _fmt_mbps(q: dict) -> str:
    vbr = q.get("video_bitrate")
    if vbr:
        try: return f"{int(vbr)/1000:.1f} Mbps"
        except: return f"{vbr} kbps"
    kbps = q.get("approx_video_kbps")
    return f"{kbps/1000:.1f} Mbps (‚âà)" if kbps else "-"

def _movie_logical_key(*, tmdb_id: str | None, imdb_id: str | None, name: str, year: int | None) -> str:
    if tmdb_id: return f"movie:tmdb:{tmdb_id}"
    if imdb_id: return f"movie:imdb:{imdb_id}"
    # —Ñ–æ–ª–±—ç–∫: name+year –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
    key_name = re.sub(r"\s+", " ", (name or "").strip().lower())
    return f"movie:nameyear:{key_name}:{year or ''}"

def store_quality_snapshot_movie(*, item_id: str, name: str, year: int | None,
                                 tmdb_id: str | None, imdb_id: str | None) -> dict:
    """
    1) –¢—è–Ω–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∏–∑ Jellyfin
    2) Upsert –≤ media_quality (–ø–æ ItemId)
    3) –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ upsert –≤ content_quality (–ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É)
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–ª–∞–≥–∏: logical_inserted, logical_changed, old_quality, new_quality
    """
    q = _get_item_media_info_movie(item_id)
    sig = _quality_signature(q)
    now = datetime.now().isoformat(timespec='seconds')

    profiles_str = (q.get("image_profile_str") or
                    ",".join(_profiles_from_q(q)))  # "DV,HDR10" –∏–ª–∏ "SDR"

    result = {
        "logical_inserted": False,
        "logical_changed": False,
        "old_quality": None,
        "new_quality": q,
        "old_signature": None,
        "new_signature": sig,
        "logical_key": None
    }

    logical_key = _movie_logical_key(tmdb_id=tmdb_id, imdb_id=imdb_id, name=name, year=year)
    result["logical_key"] = logical_key

    conn = sqlite3.connect(QUALITY_DB_FILE)
    try:
        cur = conn.cursor()
        # --- media_quality –ø–æ ItemId
        cur.execute("SELECT signature FROM media_quality WHERE item_id=?", (item_id,))
        if cur.fetchone() is None:
            cur.execute("""INSERT INTO media_quality
                           (item_id, movie_name, year, video_codec, video_bitrate, width, height, fps, bit_depth,
                            dynamic_range,
                            audio_codec, audio_bitrate, audio_channels, container, size_bytes, duration_sec, signature,
                            date_seen, image_profiles)
                           VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                        (item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                         q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                         q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                         q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now, profiles_str)
                        )
        else:
            cur.execute("""UPDATE media_quality
                           SET movie_name=?,
                               year=?,
                               video_codec=?,
                               video_bitrate=?,
                               width=?,
                               height=?,
                               fps=?,
                               bit_depth=?,
                               dynamic_range=?,
                               audio_codec=?,
                               audio_bitrate=?,
                               audio_channels=?,
                               container=?,
                               size_bytes=?,
                               duration_sec=?,
                               signature=?,
                               date_seen=?,
                               image_profiles=?
                           WHERE item_id = ?""",
                        (name, year, q.get("video_codec"), q.get("video_bitrate"),
                         q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                         q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                         q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now, profiles_str,
                         item_id)
                        )

        # --- content_quality –ø–æ logical_key
        cur.execute("""SELECT signature,
                              last_item_id,
                              video_codec,
                              video_bitrate,
                              width,
                              height,
                              fps,
                              bit_depth,
                              dynamic_range,
                              image_profiles,
                              audio_codec,
                              audio_bitrate,
                              audio_channels,
                              container,
                              size_bytes,
                              duration_sec
                       FROM content_quality
                       WHERE logical_key = ?""", (logical_key,))
        row = cur.fetchone()
        if row is None:
            if _quality_is_substantial(q):
                cur.execute("""INSERT INTO content_quality
                               (logical_key, last_item_id, movie_name, year, video_codec, video_bitrate, width, height,
                                fps, bit_depth,
                                dynamic_range, image_profiles, audio_codec, audio_bitrate, audio_channels, container,
                                size_bytes, duration_sec, signature, date_seen)
                               VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                            (logical_key, item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                             q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                             profiles_str, q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                             q.get("container"), q.get("size_bytes"), q.get("duration_sec"), sig, now)
                            )
                result["logical_inserted"] = True
        else:
            old_sig, old_item_id = row[0], row[1]
            old_q = {
                "video_codec": row[2], "video_bitrate": row[3], "width": row[4], "height": row[5],
                "fps": row[6], "bit_depth": row[7], "dynamic_range": row[8],
                "image_profiles": ([p.strip() for p in row[9].split(",")] if row[9] else None),
                "audio_codec": row[10], "audio_bitrate": row[11], "audio_channels": row[12],
                "container": row[13], "size_bytes": row[14], "duration_sec": row[15]
            }
            result["old_signature"] = old_sig
            result["old_quality"] = old_q

            if old_sig != sig and _quality_is_substantial(old_q) and _quality_is_substantial(q):
                result["logical_changed"] = True
                cur.execute("""UPDATE content_quality
                               SET last_item_id=?,
                                   movie_name=?,
                                   year=?,
                                   video_codec=?,
                                   video_bitrate=?,
                                   width=?,
                                   height=?,
                                   fps=?,
                                   bit_depth=?,
                                   dynamic_range=?,
                                   image_profiles=?,
                                   audio_codec=?,
                                   audio_bitrate=?,
                                   audio_channels=?,
                                   container=?,
                                   size_bytes=?,
                                   duration_sec=?,
                                   signature=?,
                                   date_seen=?
                               WHERE logical_key = ?""",
                            (item_id, name, year, q.get("video_codec"), q.get("video_bitrate"),
                             q.get("width"), q.get("height"), q.get("fps"), q.get("bit_depth"), q.get("dynamic_range"),
                             profiles_str, q.get("audio_codec"), q.get("audio_bitrate"), q.get("audio_channels"),
                             q.get("container"), q.get("size_bytes"), q.get("duration_sec"),
                             sig, now, logical_key)
                            )
        conn.commit()
    finally:
        conn.close()
    return result

def _labels():
    if LANG == "ru":
        return {
            "changes": "–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞",
            "resolution": "–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ",
            "video_codec": "–í–∏–¥–µ–æ-–∫–æ–¥–µ–∫",
            "bitrate": "–ë–∏—Ç—Ä–µ–π—Ç (–≤–∏–¥–µ–æ)",
            "dynamic_range": "–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω",
            "audio": "–ê—É–¥–∏–æ",
            "container": "–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä",
            "fps": "–ö–∞–¥—Ä–æ–≤–∞—è —á–∞—Å—Ç–æ—Ç–∞",
            "bit_depth": "–ë–∏—Ç–æ–≤–∞—è –≥–ª—É–±–∏–Ω–∞",
        }
    return {
        "changes": "Quality changes",
        "resolution": "Resolution",
        "video_codec": "Video codec",
        "bitrate": "Bitrate (video)",
        "dynamic_range": "Dynamic range",
        "audio": "Audio",
        "container": "Container",
        "fps": "Frame rate",
        "bit_depth": "Bit depth",
    }

def build_quality_changes_block(old_q: dict, new_q: dict) -> str:
    L = _labels()
    lines = []

    def arrow(a, b):
        return f"{a} ‚Üí {b}"

    # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ
    # --- Resolution (—Å —è—Ä–ª—ã–∫–∞–º–∏) ---
    res_old = _res_display_from_q(old_q)
    res_new = _res_display_from_q(new_q)
    if res_old != res_new:
        lines.append(f"- {L['resolution']}: {arrow(res_old, res_new)}")

    # –í–∏–¥–µ–æ-–∫–æ–¥–µ–∫
    vc_old = (old_q.get("video_codec") or "-").upper()
    vc_new = (new_q.get("video_codec") or "-").upper()
    if vc_old != vc_new:
        lines.append(f"- {L['video_codec']}: {arrow(vc_old, vc_new)}")

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω (SDR/HDR –∏ —Ç.–ø.)
    dr_old = old_q.get("dynamic_range") or "-"
    dr_new = new_q.get("dynamic_range") or "-"
    if dr_old != dr_new:
        lines.append(f"- {L['dynamic_range']}: {arrow(dr_old, dr_new)}")

    # –ü—Ä–æ—Ñ–∏–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (SDR/HDR/HDR10/HDR10+/DV/HLG)
    old_profiles = ", ".join(_profiles_from_q(old_q))
    new_profiles = ", ".join(_profiles_from_q(new_q))
    if old_profiles != new_profiles:
        lines.append(f"- {t('image_profiles')}: {old_profiles} ‚Üí {new_profiles}")
    logging.debug(f"Quality delta profiles: old='{old_profiles}' new='{new_profiles}'")
    if not lines:
        return ""
    return f"\n\n*{L['changes']}*\n" + "\n".join(lines)

def build_initial_quality_changes_block(new_q: dict) -> str:
    """
    –ë–ª–æ–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –ù–û–í–û–ì–û —Ñ–∏–ª—å–º–∞ –±–µ–∑ —Å—Ç—Ä–µ–ª–æ–∫ –∏ –±–µ–∑ 'Dynamic range'.
    –ü–æ–∫–∞–∑—ã–≤–∞–µ–º: Resolution, Video codec, Image profiles.
    """
    L = _labels()
    lines = []

    # Resolution
    # Resolution -> —è—Ä–ª—ã–∫ (–∏–ª–∏ WxH –ø—Ä–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º)
    res_new = _res_display_from_q(new_q)
    if res_new != "-":
        lines.append(f"- {L['resolution']}: {res_new}")

    # Video codec
    vc_new = (new_q.get("video_codec") or "-").upper()
    if vc_new != "-":
        lines.append(f"- {L['video_codec']}: {vc_new}")

    # Image profiles (SDR/HDR/HDR10/HDR10+/DV/HLG)
    profiles = ", ".join(_profiles_from_q(new_q))
    lines.append(f"- {t('image_profiles')}: {profiles}")

    if not lines:
        return ""
    return f"\n\n*{L['changes']}*\n" + "\n".join(lines)



def maybe_notify_movie_quality_change(*, item_id: str, movie_name_cleaned: str, release_year: int | None,
                                      tmdb_id: str | None, imdb_id: str | None,
                                      overview: str | None, runtime: str | None) -> bool:
    """
    –ï—Å–ª–∏ –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–∏–ª—å–º–∞ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å (–ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É) ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    —Ç–µ–º –∂–µ —à–∞–±–ª–æ–Ω–æ–º, —á—Ç–æ –∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞, + –±–ª–æ–∫ '–ò–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏ (–æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ 'New Movie' —Å–ª–∞—Ç—å –Ω–µ –Ω–∞–¥–æ).
    """
    res = store_quality_snapshot_movie(
        item_id=item_id, name=movie_name_cleaned, year=release_year,
        tmdb_id=tmdb_id, imdb_id=imdb_id
    )
    if not res.get("logical_changed"):
        return False

    old_q = res.get("old_quality")
    new_q = res.get("new_quality")
    # –ï—Å–ª–∏ —Å—Ç–∞—Ä—ã–π —Å–Ω–∏–º–æ–∫ ¬´–ø—É—Å—Ç–æ–π¬ª ‚Äî —ç—Ç–æ –ø–µ—Ä–≤—ã–π –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å –Ω–æ–≤–æ–≥–æ —Ñ–∏–ª—å–º–∞; —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ —ç—Ç–æ –ù–ï –∞–ø–≥—Ä–µ–π–¥.
    if not _quality_is_substantial(old_q):
        logging.info("(Movie guard) Old quality is empty -> treat as NEW content, not a quality update.")
        return False

    # –°–æ–±–∏—Ä–∞–µ–º ¬´–∫–∞–∫ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏¬ª
    notification_message = (
        f"*{t('quality_updated')}*\n\n*{movie_name_cleaned}* *({release_year})*\n\n{overview or ''}\n\n"
        f"*{t('new_runtime')}*\n{runtime or ''}"
    )

    # —Ä–µ–π—Ç–∏–Ω–≥–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å tmdb_id)
    if tmdb_id:
        ratings_text = safe_fetch_mdblist_ratings("movie", tmdb_id)
        if ratings_text:
            notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"

    # —Ç—Ä–µ–π–ª–µ—Ä
    trailer_url = safe_get_trailer_prefer_tmdb(f"{movie_name_cleaned} Trailer {release_year}",
                                context="webhook", subkind="movie", tmdb_id=tmdb_id)
    if trailer_url:
        notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

    # –¥–æ–±–∞–≤–∏–º –±–ª–æ–∫ ¬´—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å¬ª
    # –¥–æ–±–∞–≤–∏–º –±–ª–æ–∫ ¬´—á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å¬ª
    delta = build_quality_changes_block(old_q, new_q)
    if delta:
        notification_message += delta

    # –î–û–ë–ê–í–¨ –£–°–õ–û–í–ò–ï:
    if INCLUDE_AUDIO_TRACKS:
        tracks_block = build_audio_tracks_block(new_q)
        if tracks_block:
            notification_message += tracks_block

    send_notification(item_id, notification_message)
    touch_quality_update_marker(res.get("logical_key") or _movie_logical_key(
        tmdb_id=tmdb_id, imdb_id=imdb_id, name=movie_name_cleaned, year=release_year
    ), item_id=item_id)
    logging.info(f"(Movie) Quality update sent for {movie_name_cleaned} ({release_year}); logical_key={res.get('logical_key')}")
    return True

def _format_runtime_from_ticks(runtime_ticks) -> str:
    if not runtime_ticks:
        return ""
    try:
        total_sec = int(runtime_ticks) // 10_000_000
        h = total_sec // 3600
        m = (total_sec % 3600) // 60
        if h > 0:
            return f"{h}h {m}m"
        return f"{m}m"
    except Exception:
        return ""
def poll_recent_movies_once():
    """
    –ü–∞–≥–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ç—è–Ω–µ–º —Ñ–∏–ª—å–º—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∞–ø–≥—Ä–µ–π–¥—ã –∫–∞—á–µ—Å—Ç–≤–∞.
    –ù–æ–≤—ã–µ (–æ—á–µ–Ω—å —Å–≤–µ–∂–∏–µ) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –∏—Ö –æ–±—ä—è–≤–∏—Ç –≤–µ–±—Ö—É–∫.
    """
    page_size = MOVIE_POLL_PAGE_SIZE
    # —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å: –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Å—Ç–∞—Ä—ã–π MOVIE_POLL_LIMIT –∏ MAX_TOTAL == 0, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –ø—Ä–µ–¥–µ–ª
    max_total = MOVIE_POLL_MAX_TOTAL  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è

    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    while True:
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        current_limit = page_size
        if max_total and (max_total - fetched) < page_size:
            current_limit = max_total - fetched
            if current_limit <= 0:
                break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                # DateCreated –Ω—É–∂–µ–Ω –¥–ª—è –≥—Ä–µ–π—Å-—Ñ–∏–ª—å—Ç—Ä–∞ (—á—Ç–æ–±—ã –≤–µ–±—Ö—É–∫ –æ–±—ä—è–≤–ª—è–ª ¬´–Ω–æ–≤—ã–µ¬ª)
                "Fields": "MediaSources,RunTimeTicks,ProviderIds,ProductionYear,Overview,DateCreated"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Movie poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            try:
                # --- –≥—Ä–µ–π—Å: —Å–≤–µ–∂–∏–µ –Ω–æ–≤–∏–Ω–∫–∏ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º (–ø—É—Å—Ç—å –≤–µ–±—Ö—É–∫ –ø–æ—à–ª—ë—Ç 'New Movie Added')
                created_iso = it.get("DateCreated")
                created_dt = _parse_iso_utc(created_iso)
                if created_dt and (now_utc - created_dt) < timedelta(minutes=MOVIE_POLL_GRACE_MIN):
                    logging.debug(f"Movie poll: skip fresh item (created {created_dt.isoformat()}): {it.get('Name')}")
                    continue
                # -------------------------------------------------------------

                item_id = it.get("Id")
                name = it.get("Name") or ""
                year = it.get("ProductionYear")
                prov = it.get("ProviderIds") or {}
                tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
                imdb_id = prov.get("Imdb") or prov.get("ImdbId")

                # –ò–º—è –±–µ–∑ –≥–æ–¥–∞ –≤ —Å–∫–æ–±–∫–∞—Ö (–∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ)
                name_clean = name.replace(f" ({year})", "").strip()

                # Overview/Runtime –¥–ª—è —Ç–µ–∫—Å—Ç–∞
                overview = it.get("Overview") or ""
                runtime_str = _format_runtime_from_ticks(it.get("RunTimeTicks"))

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –∞–ø–¥–µ–π—Ç—ã –∫–∞—á–µ—Å—Ç–≤–∞ (–Ω–µ ¬´–Ω–æ–≤—ã–π —Ñ–∏–ª—å–º¬ª)
                sent = maybe_notify_movie_quality_change(
                    item_id=item_id,
                    movie_name_cleaned=name_clean,
                    release_year=year,
                    tmdb_id=tmdb_id,
                    imdb_id=imdb_id,
                    overview=overview,
                    runtime=runtime_str
                )
                if sent:
                    # –∑–∞–ø–∏—Å—å –≤ –ë–î —É–∂–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∞; –ø–æ–≤—Ç–æ—Ä–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º –ø—Ä–æ—Ö–æ–¥–µ –Ω–µ –±—É–¥–µ—Ç
                    continue
            except Exception as ex:
                logging.warning(f"Movie poll: item {it.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        logging.debug(f"Movie poll: page fetched {n} items (total {fetched})")

        # –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ–ø–æ–ª–Ω–∞—è ‚Äî –¥–∞–ª—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–µ—Ç
        if n < current_limit:
            break

        # –º—è–≥–∫–æ–µ –¥—ã—Ö–∞–Ω–∏–µ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏ (–Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        time.sleep(0.1)

def _detect_image_profiles_from_fields(s: dict) -> list[str]:
    """
    –î–µ—Ç–µ–∫—Ç DV / HDR10+ / HDR10 / HLG / HDR / SDR –ø–æ –ø–æ–ª—è–º –≤–∏–¥–µ–æ-–ø–æ—Ç–æ–∫–∞.
    –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º ['SDR'].
    """
    txt_parts = []
    for k in ("ColorTransfer","VideoRange","VideoRangeType","ColorPrimaries","ColorSpace",
              "Profile","Hdr","Hdr10Plus","DolbyVision","DoVi","VideoDoViProfile"):
        v = s.get(k)
        if isinstance(v, bool):
            v = "1" if v else "0"
        if v is not None:
            txt_parts.append(str(v))
    txt = " ".join(txt_parts).upper()

    prof = []
    def add(tag):
        if tag not in prof:
            prof.append(tag)

    if "DOLBY VISION" in txt or "DOVI" in txt or "VIDEO DOVIPROFILE" in txt or re.search(r"\bDV\b", txt or ""):
        add("DV")
    if "HDR10+" in txt or "HDR10PLUS" in txt or "HDR10 PLUS" in txt:
        add("HDR10+")
    if "HDR10" in txt:
        add("HDR10")
    if "HLG" in txt:
        add("HLG")
    if ("HDR" in txt or "PQ" in txt or "BT2020" in txt) and not any(p in prof for p in ("DV","HDR10+","HDR10","HLG")):
        add("HDR")
    if not prof:
        add("SDR")

    order = {"DV":0,"HDR10+":1,"HDR10":2,"HLG":3,"HDR":4,"SDR":5}
    prof.sort(key=lambda x: order.get(x, 99))
    return prof

def _profiles_from_q(q: dict | None) -> list[str]:
    order = {"DV": 0, "HDR10+": 1, "HDR10": 2, "HLG": 3, "HDR": 4, "SDR": 5}
    if not q:
        return ["SDR"]

    profs = (q.get("image_profiles") or [])
    if not profs:
        dr = (q.get("dynamic_range") or "").upper()
        if "DV" in dr or "DOLBY" in dr:
            profs = ["DV"]
        elif "HDR10+" in dr:
            profs = ["HDR10+"]
        elif "HDR10" in dr:
            profs = ["HDR10"]
        elif "HLG" in dr:
            profs = ["HLG"]
        elif "HDR" in dr:
            profs = ["HDR"]
        else:
            profs = ["SDR"]

    # ‚Üê –≤–æ—Ç —ç—Ç–∏ –¥–≤–µ —Å—Ç—Ä–æ–∫–∏ –∫–ª—é—á–µ–≤—ã–µ:
    profs = [str(p).strip().upper() for p in profs if str(p).strip()]
    profs = list(dict.fromkeys(profs))

    profs.sort(key=lambda p: order.get(p, 99))
    return profs

def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')

def _iso_to_dt(s: str | None) -> datetime | None:
    if not s: return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00'))
    except Exception:
        return None

def touch_quality_update_marker(logical_key: str, item_id: str | None = None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""INSERT INTO recent_quality_updates (logical_key, notified_at, item_id)
                       VALUES (?, ?, ?)
                       ON CONFLICT(logical_key) DO UPDATE SET
                         notified_at=excluded.notified_at,
                         item_id=excluded.item_id
                    """, (logical_key, _now_utc_iso(), item_id))
        conn.commit()
    except Exception as ex:
        logging.warning(f"touch_quality_update_marker failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def was_quality_update_recent(logical_key: str) -> bool:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT notified_at FROM recent_quality_updates WHERE logical_key=?", (logical_key,))
        row = cur.fetchone()
    except Exception as ex:
        logging.warning(f"was_quality_update_recent check failed: {ex}")
        return False
    finally:
        try: conn.close()
        except: pass

    if not row:
        return False
    ts = _iso_to_dt(row[0])
    if not ts:
        return False
    return (datetime.now(timezone.utc) - ts) < timedelta(minutes=SUPPRESS_WEBHOOK_AFTER_QUALITY_UPDATE_MIN)

def _parse_iso_utc(s: str | None):
    if not s:
        return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00')).astimezone(timezone.utc)
    except Exception:
        return None


def _movie_poll_loop():
    while True:
        try:
            poll_recent_movies_once()
        except Exception as ex:
            logging.warning(f"Movie poll loop error: {ex}")
        time.sleep(MOVIE_POLL_INTERVAL_SEC)

if MOVIE_POLL_ENABLED:
    threading.Thread(target=_movie_poll_loop, name="movie-poll", daemon=True).start()
    logging.info(f"Movie quality polling enabled every {MOVIE_POLL_INTERVAL_SEC}s (limit={MOVIE_POLL_MAX_TOTAL})")

def _resolution_label(width: int | None, height: int | None) -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —è—Ä–ª—ã–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è (8K, 5K, 4K (UltraHD), 1440p, 1080p, 720p, 576p, 480p, 360p, 240p).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—ã—Å–æ—Ç—É –∫–∞–¥—Ä–∞ —Å –¥–æ–ø—É—Å–∫–æ–º (~8%) –Ω–∞ ¬´–Ω–µ–∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–µ¬ª –∑–Ω–∞—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2026 ‚âà 2160).
    –ï—Å–ª–∏ –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –Ω–∏ –≤ –æ–¥–∏–Ω –¥–∏–∞–ø–∞–∑–æ–Ω ‚Äî –≤–µ—Ä–Ω—ë—Ç None.
    """
    if not height:
        return None

    # (target_height, label)
    targets = [
        (4320, "8K"),
        (2880, "5K"),
        (2160, "4K (UltraHD)"),
        (1440, "1440p"),
        (1080, "1080p"),
        (720,  "720p"),
        (576,  "576p"),
        (480,  "480p"),
        (360,  "360p"),
        (240,  "240p"),
    ]
    for h, label in targets:
        tol = max(int(h * 0.08), 12)  # ~8% –∏–ª–∏ –º–∏–Ω–∏–º—É–º 12px
        if abs(height - h) <= tol:
            return label
    return None

def _res_display_from_q(q: dict | None) -> str:
    """
    –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:
    - –µ—Å–ª–∏ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —è—Ä–ª—ã–∫ 8K/4K/... -> –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ
    - –∏–Ω–∞—á–µ –≤–µ—Ä–Ω—É—Ç—å 'WxH'
    - –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç -> '-'
    """
    if not q:
        return "-"
    w, h = q.get("width"), q.get("height")
    if not (w and h):
        return "-"
    label = _resolution_label(w, h)
    return label or f"{w}x{h}"

#–û—á–∏—Å—Ç–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def _now_utc_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace("+00:00", "Z")

def _iso_to_dt(s: str | None) -> datetime | None:
    if not s: return None
    try: return datetime.fromisoformat(s.replace("Z","+00:00")).astimezone(timezone.utc)
    except Exception: return None

def _collect_current_movie_keys_and_ids() -> tuple[set[str], set[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (set –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–π, set ItemId) –¥–ª—è –í–°–ï–• —Ñ–∏–ª—å–º–æ–≤ –≤ Jellyfin.
    –ö–ª—é—á —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ _movie_logical_key(...) –ø–æ ProviderIds/Tmdb/Imdb -> name+year.
    """
    current_keys: set[str] = set()
    current_ids: set[str] = set()

    start = 0
    page_size = QUALITY_GC_PAGE_SIZE

    while True:
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateCreated",
                "SortOrder": "Descending",
                "Limit": str(page_size),
                "StartIndex": str(start),
                "Fields": "ProviderIds,ProductionYear"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Quality GC: failed to list movies page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            item_id = it.get("Id")
            name = it.get("Name") or ""
            year = it.get("ProductionYear")
            prov = it.get("ProviderIds") or {}
            tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
            imdb_id = prov.get("Imdb") or prov.get("ImdbId")
            # –∏–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ "(year)"
            name_clean = name.replace(f" ({year})", "").strip()

            key = _movie_logical_key(
                tmdb_id=tmdb_id,
                imdb_id=imdb_id,
                name=name_clean,
                year=year
            )
            current_keys.add(key)
            if item_id:
                current_ids.add(item_id)

        n = len(items)
        start += n
        if n < page_size:
            break

    return current_keys, current_ids

def _collect_current_movie_keys_and_ids() -> tuple[set[str], set[str]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (set –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–ª—é—á–µ–π, set ItemId) –¥–ª—è –í–°–ï–• —Ñ–∏–ª—å–º–æ–≤ –≤ Jellyfin.
    –ö–ª—é—á —Å—Ç—Ä–æ–∏–º —á–µ—Ä–µ–∑ _movie_logical_key(...) –ø–æ ProviderIds/Tmdb/Imdb -> name+year.
    """
    current_keys: set[str] = set()
    current_ids: set[str] = set()

    start = 0
    page_size = QUALITY_GC_PAGE_SIZE

    while True:
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Movie",
                "Recursive": "true",
                "SortBy": "DateCreated",
                "SortOrder": "Descending",
                "Limit": str(page_size),
                "StartIndex": str(start),
                "Fields": "ProviderIds,ProductionYear"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Quality GC: failed to list movies page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            item_id = it.get("Id")
            name = it.get("Name") or ""
            year = it.get("ProductionYear")
            prov = it.get("ProviderIds") or {}
            tmdb_id = prov.get("Tmdb") or prov.get("TmdbId")
            imdb_id = prov.get("Imdb") or prov.get("ImdbId")
            # –∏–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ "(year)"
            name_clean = name.replace(f" ({year})", "").strip()

            key = _movie_logical_key(
                tmdb_id=tmdb_id,
                imdb_id=imdb_id,
                name=name_clean,
                year=year
            )
            current_keys.add(key)
            if item_id:
                current_ids.add(item_id)

        n = len(items)
        start += n
        if n < page_size:
            break

    return current_keys, current_ids

def gc_quality_db_once():
    """
    –£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏:
      - content_quality: –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–∏, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ last seen —Å—Ç–∞—Ä—à–µ GRACE
      - media_quality: item_id, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –∏ last seen —Å—Ç–∞—Ä—à–µ GRACE
      - recent_quality_updates: –º–∞—Ä–∫–µ—Ä—ã –ø–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–º –∫–ª—é—á–∞–º
    """
    try:
        current_keys, current_ids = _collect_current_movie_keys_and_ids()
        cutoff = datetime.now(timezone.utc) - timedelta(days=QUALITY_GC_GRACE_DAYS)

        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()

        # --- content_quality
        cur.execute("SELECT logical_key, date_seen FROM content_quality")
        rows = cur.fetchall()
        to_del_keys = []
        for logical_key, date_seen in rows:
            if logical_key in current_keys:
                continue
            dt = _iso_to_dt(date_seen)
            if (dt is None) or (dt < cutoff):
                to_del_keys.append(logical_key)

        if to_del_keys:
            for key in to_del_keys:
                cur.execute("DELETE FROM content_quality WHERE logical_key=?", (key,))
            logging.info(f"Quality GC: removed {len(to_del_keys)} content_quality rows")

        # --- media_quality
        cur.execute("SELECT item_id, date_seen FROM media_quality")
        rows = cur.fetchall()
        to_del_ids = []
        for item_id, date_seen in rows:
            if item_id in current_ids:
                continue
            dt = _iso_to_dt(date_seen)
            if (dt is None) or (dt < cutoff):
                to_del_ids.append(item_id)

        if to_del_ids:
            for iid in to_del_ids:
                cur.execute("DELETE FROM media_quality WHERE item_id=?", (iid,))
            logging.info(f"Quality GC: removed {len(to_del_ids)} media_quality rows")

        # --- recent_quality_updates (–º–∞—Ä–∫–µ—Ä—ã –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –≤–µ–±—Ö—É–∫–∞)
        if to_del_keys:
            for key in to_del_keys:
                cur.execute("DELETE FROM recent_quality_updates WHERE logical_key=?", (key,))

        conn.commit()

        # –ø–æ –∂–µ–ª–∞–Ω–∏—é –º–æ–∂–Ω–æ –∏–Ω–æ–≥–¥–∞ –¥–µ–ª–∞—Ç—å VACUUM (—Ä–µ–¥–∫–æ)
        # cur.execute("VACUUM")  # –µ—Å–ª–∏ –±–∞–∑–∞ –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç—å –≤–∞–∂–Ω–∞

    except Exception as ex:
        logging.warning(f"Quality GC error: {ex}")
    finally:
        try:
            conn.close()
        except Exception:
            pass

_init_quality_db()

# --- –§–æ—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ (–æ–¥–Ω–æ—Ä–∞–∑–æ–≤–æ) ---
if FORCE_QUALITY_GC_ON_START:
    old_grace = QUALITY_GC_GRACE_DAYS
    try:
        # –ï—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ —è–≤–Ω–æ ‚Äî —á–∏—Å—Ç–∏–º –±–µ–∑ ¬´–≥—Ä–µ–π—Å–∞¬ª (—Å—Ä–∞–∑—É)
        QUALITY_GC_GRACE_DAYS = int(FORCE_QUALITY_GC_GRACE_DAYS) if FORCE_QUALITY_GC_GRACE_DAYS is not None else 0
    except Exception:
        logging.warning(f"FORCE_QUALITY_GC_GRACE_DAYS is not an int: {FORCE_QUALITY_GC_GRACE_DAYS}")
        QUALITY_GC_GRACE_DAYS = 0

    logging.info(f"Quality DB GC (startup forced): grace={QUALITY_GC_GRACE_DAYS}d, vacuum={FORCE_QUALITY_GC_VACUUM}")
    try:
        gc_quality_db_once()  # —É–¥–∞–ª–∏—Ç –∑–∞–ø–∏—Å–∏ –ø–æ —Ñ–∏–ª—å–º–∞–º, –∫–æ—Ç–æ—Ä—ã—Ö —É–∂–µ –Ω–µ—Ç –≤ Jellyfin
        if FORCE_QUALITY_GC_VACUUM:
            try:
                conn = sqlite3.connect(QUALITY_DB_FILE)
                conn.execute("VACUUM")
                conn.close()
                logging.info("Quality DB GC (startup) VACUUM done.")
            except Exception as ex:
                logging.warning(f"Quality DB GC (startup) VACUUM failed: {ex}")
    finally:
        # –≤–µ—Ä–Ω—ë–º –æ–±—ã—á–Ω—ã–π grace –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–∏
        QUALITY_GC_GRACE_DAYS = old_grace

#–†–∞–±–æ—Ç–∞ —è youtube –∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–º

# --- SAFE trailer & ratings helpers ---
_youtube_forbid_until = 0.0
_trailer_cache = {}   # –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å
_ratings_cache = {}   # –Ω–∞ –ø—Ä–æ—Ü–µ—Å—Å

def safe_get_trailer(query: str, *, context: str = "", subkind: str | None = None, tmdb_id: str | None = None) -> str | None:
    """
    –ò—â–µ–º —Ç—Ä–µ–π–ª–µ—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ + –∫—ç—à–∏—Ä—É–µ–º –≤ –ë–î.
    –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫—ç—à–∞ –±–µ—Ä—ë–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É: tmdb_id ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π query.
    subkind: 'movie' | 'show' (–¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ TTL/–∞–Ω–∞–ª–∏—Ç–∏–∫–∏; –∫ –∫–ª—é—á—É –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
    """
    # –ø—Ä–∞–≤–∏–ª–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è
    try:
        if os.getenv("TRAILER_FETCH_ENABLED", "1").lower() not in ("1","true","yes","on"):
            return None
        if os.getenv("DISABLE_TRAILER_IN_POLLS", "1").lower() in ("1","true","yes","on") and context == "series_poll":
            return None
    except Exception:
        pass

    # –∫–ª—é—á –∫—ç—à–∞
    identity = tmdb_id or query.strip()
    # 1) —á–∏—Ç–∞–µ–º –∫—ç—à
    cached_val, cached_at = _extcache_read("trailer", subkind, identity)
    if _is_fresh(cached_at, TRAILER_CACHE_TTL_DAYS) and cached_val:
        return cached_val

    # 2) –Ω–µ —Å–≤–µ–∂–∏–π ‚Äî –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑ —Å–µ—Ç–∏ (—Å 403-–ø—Ä–µ–¥–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–µ–º)
    try:
        # –ª–æ–∫–∞–ª—å–Ω—ã–π ¬´—Å—Ç–æ–ø¬ª –ø–æ 403
        import time as _t
        forbid_until = globals().get("_youtube_forbid_until", 0.0)
        if _t.time() < forbid_until:
            return cached_val or None

        url = get_youtube_trailer_url(query)  # —Ç–≤–æ—è –∏—Å—Ö–æ–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
        if url:
            _extcache_write("trailer", subkind, identity, url)
            return url
        # –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–µ—Ä–Ω—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ç–µ–∫—Å—Ç
        return cached_val or None

    except requests.HTTPError as ex:
        resp = getattr(ex, "response", None)
        if getattr(resp, "status_code", None) == 403:
            # –ø—Ä–∏ 403 ‚Äî —Å—Ç–∞–≤–∏–º ¬´—Ñ–æ—Ä–±–∏–¥¬ª –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
            import time as _t
            suspend_min = int(os.getenv("TRAILER_FORBID_SUSPEND_MIN", "60"))
            globals()["_youtube_forbid_until"] = _t.time() + suspend_min * 60
            logging.warning(f"YouTube 403; suspend {suspend_min} min; use cache if any")
            return cached_val or None
        logging.warning(f"YouTube HTTP error: {ex}")
        return cached_val or None
    except Exception as ex:
        logging.warning(f"YouTube trailer fetch failed: {ex}")
        return cached_val or None

def safe_fetch_mdblist_ratings(kind: str, tmdb_id: str | None) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç —Ä–µ–π—Ç–∏–Ω–≥–æ–≤. –°–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –∫—ç—à –∏–∑ –ë–î, –µ—Å–ª–∏ –æ–Ω —Å–≤–µ–∂–∏–π.
    –ï—Å–ª–∏ –∫—ç—à –ø—Ä–æ—Å—Ä–æ—á–µ–Ω ‚Äî –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å; –ø—Ä–∏ –æ—à–∏–±–∫–µ –æ—Ç–¥–∞—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ.
    kind: 'movie' | 'show'
    """
    if not tmdb_id:
        return ""
    # 1) —á–∏—Ç–∞–µ–º –∫—ç—à
    cached_val, cached_at = _extcache_read("ratings", kind, tmdb_id)
    if _is_fresh(cached_at, RATINGS_CACHE_TTL_DAYS) and cached_val:
        return cached_val

    # 2) –ø—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å –∏–∑ —Å–µ—Ç–∏
    fresh = ""
    try:
        fresh = fetch_mdblist_ratings(kind, tmdb_id) or ""
    except Exception as ex:
        logging.warning(f"MDblist ratings fetch failed: {ex}")

    if fresh:
        _extcache_write("ratings", kind, tmdb_id, fresh)
        return fresh

    # 3) –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å ‚Äî –≤–µ—Ä–Ω—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ (–Ω–µ –ª–æ–º–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è)
    return cached_val or ""

#–†–∞–±–æ—Ç–∞ —Å —Å–µ–∑–æ–Ω–Ω—ã–º–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º–∏
def jellyfin_count_present_episodes_in_season(season_id: str) -> int | None:
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ParentId": season_id,
            "IncludeItemTypes": "Episode",
            "Recursive": "false",
            "LocationTypes": "FileSystem",
            "IsMissing": "false",
            "Limit": "1",
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json() or {}
        cnt = data.get("TotalRecordCount")
        return int(cnt) if isinstance(cnt, int) else len(data.get("Items") or [])
    except requests.HTTPError as ex:
        status = getattr(getattr(ex, "response", None), "status_code", None)
        if status in (400, 404):
            # —Å–∏–≥–Ω–∞–ª ¬´—Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω¬ª
            return -1
        logging.warning(f"Failed to count PRESENT episodes for season {season_id}: {ex}")
        return None
    except Exception as ex:
        logging.warning(f"Failed to count PRESENT episodes for season {season_id}: {ex}")
        return None

def jellyfin_count_missing_episodes_in_season(season_id: str) -> int | None:
    try:
        params = {
            "api_key": JELLYFIN_API_KEY,
            "ParentId": season_id,
            "IncludeItemTypes": "Episode",
            "Recursive": "false",
            "IsMissing": "true",
            "IsUnaired": "false",
            "IsVirtualUnaired": "false",
            "LocationTypes": "Virtual",
            "Limit": "1",
        }
        url = f"{JELLYFIN_BASE_URL}/emby/Items"
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        data = r.json() or {}
        cnt = data.get("TotalRecordCount")
        return int(cnt) if isinstance(cnt, int) else len(data.get("Items") or [])
    except requests.HTTPError as ex:
        status = getattr(getattr(ex, "response", None), "status_code", None)
        if status in (400, 404):
            # —Å–∏–≥–Ω–∞–ª ¬´—Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω¬ª
            return -1
        logging.warning(f"Failed to count MISSING episodes for season {season_id}: {ex}")
        return None
    except Exception as ex:
        logging.warning(f"Failed to count MISSING episodes for season {season_id}: {ex}")
        return None

def jellyfin_get_season_counts_resilient(season_id: str) -> tuple[int, int] | tuple[int, int, bool]:
    attempts = max(int(os.getenv("SEASON_EP_COUNT_RETRY_ATTEMPTS", "5")), 1)
    delay = max(int(os.getenv("SEASON_EP_COUNT_RETRY_DELAY_SEC", "3")), 0)

    present, total = 0, 0
    for i in range(1, attempts + 1):
        p = jellyfin_count_present_episodes_in_season(season_id)
        if p == -1:
            # —Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω ‚Äî —á–∏—Å—Ç–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º
            _sp_delete(season_id)
            logging.info(f"Season {season_id} removed from Jellyfin ‚Äî purged from DB.")
            return (-1, -1)  # —Å–∏–≥–Ω–∞–ª –Ω–∞–≤–µ—Ä—Ö

        m = jellyfin_count_missing_episodes_in_season(season_id)
        if m == -1:
            _sp_delete(season_id)
            logging.info(f"Season {season_id} removed from Jellyfin ‚Äî purged from DB.")
            return (-1, -1)

        if isinstance(p, int):
            present = p
        if isinstance(m, int):
            total = present + m
        else:
            total = present

        if total > 0 and (present > 0 or i == attempts):
            if i > 1:
                logging.debug(f"Season counts after {i} attempts: present={present}, total={total}")
            break
        time.sleep(delay)

    return (present, total)

def poll_recent_episodes_once():
    """
    –ò—â–µ–º —Å–≤–µ–∂–∏–µ —ç–ø–∏–∑–æ–¥—ã –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ, –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å–µ–∑–æ–Ω—É –∏ —à–ª—ë–º –û–î–ù–û —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ ¬´–ù–æ–≤—ã–π —Å–µ–∑–æ–Ω: –¥–æ–±–∞–≤–ª–µ–Ω–æ N –∏–∑ M¬ª.
    –°–≤–µ–∂–∏–µ (–º–æ–ª–æ–∂–µ SERIES_POLL_GRACE_MIN) –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –ø—É—Å—Ç—å –∏—Ö –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –≤–µ–±—Ö—É–∫.
    """
    page_size = SERIES_POLL_PAGE_SIZE
    max_total = SERIES_POLL_MAX_TOTAL or 0  # 0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)

    processed_seasons: set[str] = set()

    while True:
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø—Ä–∏ max_total
        current_limit = page_size if (not max_total or (max_total - fetched) >= page_size) else (max_total - fetched)
        if current_limit <= 0:
            break

        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Episode",
                "Recursive": "true",
                "SortBy": "DateCreated,DateModified",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                "Fields": "ParentId,SeriesId,SeasonName,DateCreated,ProductionYear,Overview"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"Series poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        # —Å–≥—Ä—É–ø–ø–∏—Ä—É–µ–º —ç–ø–∏–∑–æ–¥—ã –ø–æ —Å–µ–∑–æ–Ω—É
        for ep in items:
            try:
                season_id = ep.get("ParentId") or ep.get("SeasonId")
                if not season_id or season_id in processed_seasons:
                    continue

                # –≥—Ä–µ–π—Å: –µ—Å–ª–∏ —ç–ø–∏–∑–æ–¥ —Å–æ–≤—Å–µ–º —Å–≤–µ–∂–∏–π ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–µ–∑–æ–Ω, –ø—É—Å—Ç—å –≤–µ–±—Ö—É–∫ –æ–±—ä—è–≤–∏—Ç
                created_iso = ep.get("DateCreated")
                created_dt = _parse_iso_utc(created_iso) if ' _parse_iso_utc' in globals() else None
                if created_dt and (now_utc - created_dt) < timedelta(minutes=SERIES_POLL_GRACE_MIN):
                    logging.debug(f"Series poll: skip fresh season (ep created {created_dt.isoformat()}) season={season_id}")
                    continue

                # –ø–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ —Å–µ–∑–æ–Ω–∞/—Å–µ—Ä–∏–∞–ª–∞
                season_details = get_item_details(season_id)
                s_item = (season_details.get("Items") or [{}])[0]
                series_id = s_item.get("SeriesId")
                season_name = s_item.get("Name") or ep.get("SeasonName") or "Season"
                release_year = s_item.get("ProductionYear") or ep.get("ProductionYear")

                series_details = get_item_details(series_id) if series_id else {"Items": [{}]}
                series_item = (series_details.get("Items") or [{}])[0]
                series_name = series_item.get("Name") or ""
                overview_to_use = s_item.get("Overview") or series_item.get("Overview") or ""

                # –∞–Ω—Ç–∏—Å–ø–∞–º-–∫–ª—é—á, –∫–∞–∫ –≤ –≤–µ–±—Ö—É–∫–µ
                series_name_cleaned = series_name.replace(f" ({release_year})", "").strip()
                key_name = f"{series_name_cleaned} {season_name}".strip()

                if item_already_notified("Season", key_name, release_year):
                    processed_seasons.add(season_id)
                    continue

                # —Å—á–∏—Ç–∞–µ–º ¬´—Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å / —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ¬ª –ø–æ —Å–µ–∑–æ–Ω—É (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ–π resilient-—Ö–µ–ª–ø–µ—Ä)
                # –≤ poll_recent_episodes_once(), –ø—Ä—è–º–æ –ø–µ—Ä–µ–¥ –ø–æ–¥—Å—á—ë—Ç–æ–º present/total:
                wait_until_scan_idle("season counts build")
                present, total = jellyfin_get_season_counts_resilient(season_id)
                # —Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                if isinstance(present, int) and isinstance(total, int) and present == -1 and total == -1:
                    processed_seasons.add(season_id)
                    continue

                # --- –°—Ä–µ–∑ –ø–æ –¥–∞—Ç–µ —Å–æ–∑–¥–∞–Ω–∏—è –ë–î: baseline —Ç–æ–ª—å–∫–æ –û–î–ò–ù –†–ê–ó, –µ—Å–ª–∏ —Å–µ–∑–æ–Ω–∞ –µ—â—ë –Ω–µ—Ç –≤ –ë–î ---
                row_existing = _sp_get(season_id)
                if row_existing is None:
                    try:
                        db_created_iso = _db_get_created_at_iso()
                        db_created_dt = _parse_iso_dt(db_created_iso)

                        # DateCreated —É —Å–µ–∑–æ–Ω–∞ –±–µ—Ä—ë–º –∏–∑ —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ s_item; –µ—Å–ª–∏ –≤–¥—Ä—É–≥ –Ω–µ—Ç ‚Äî –¥—ë—Ä–Ω–µ–º –¥–µ—Ç–∞–ª–∏
                        season_created_iso = s_item.get("DateCreated")
                        if not season_created_iso:
                            s_det_fallback = get_item_details(season_id)
                            season_created_iso = ((s_det_fallback.get("Items") or [{}])[0]).get("DateCreated")
                        season_created_dt = _parse_iso_dt(season_created_iso)

                        if db_created_dt and season_created_dt and (season_created_dt < db_created_dt):
                            # –°–µ–∑–æ–Ω –±—ã–ª –î–û —Å–æ–∑–¥–∞–Ω–∏—è –ë–î ‚Äî –ø–∏—à–µ–º baseline –∏ –ù–ï —à–ª—ë–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
                            _sp_upsert(
                                season_id,
                                present=present, total=total,
                                series_id=series_id,
                                season_number=int(s_item.get("IndexNumber")) if s_item.get(
                                    "IndexNumber") is not None else None,
                                series_name=series_name_cleaned,
                                release_year=release_year,
                                mark_notified=True  # baseline: —Å—Ä–∞–∑—É —Å—á–∏—Ç–∞–µ–º ¬´–æ–±—ä—è–≤–ª–µ–Ω–Ω—ã–º¬ª
                            )
                            logging.info(
                                f"(Series poll) Season pre-DB cutoff baseline: {series_name_cleaned} {season_name} ‚Äî {present}/{total}")
                            processed_seasons.add(season_id)
                            continue
                    except Exception as ex:
                        logging.warning(f"Season cutoff check failed for {season_id}: {ex}")
                # --- –∫–æ–Ω–µ—Ü —Å—Ä–µ–∑–∞ ---

                # 1) —Å–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–Ω–∞–±–ª—é–¥–µ–Ω–∏–µ¬ª (–±–µ–∑ mark_notified) ‚Äî —á—Ç–æ–±—ã –∏–º–µ—Ç—å –±–∞–∑—É –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–∞
                _sp_upsert(
                    season_id,
                    present=present, total=total,
                    series_id=series_id,
                    season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                    series_name=series_name_cleaned,
                    release_year=release_year,
                    mark_notified=False
                )

                # 2) —Ä–µ—à–∞–µ–º, –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –ª–∏: —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ present –≤—ã—Ä–æ—Å —Å–æ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–æ—à–ª–æ–≥–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                if not _sp_should_notify(season_id, present):
                    processed_seasons.add(season_id)
                    continue
                # –º—ã —Ä–µ—à–∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å: —Å—Ä–∞–∑—É ¬´–∑–∞–∫—Ä—ã–≤–∞–µ–º¬ª —Å–µ–∑–æ–Ω –Ω–∞ —ç—Ç–æ—Ç –ø—Ä–æ–≥–æ–Ω,
                # —á—Ç–æ–±—ã —Å–ª–µ–¥—É—é—â–∏–µ —ç–ø–∏–∑–æ–¥—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–ª–∏ –≤–Ω–µ—à–Ω–∏–µ –≤—ã–∑–æ–≤—ã
                processed_seasons.add(season_id)

                # —Ä–µ–π—Ç–∏–Ω–≥–∏/—Ç—Ä–µ–π–ª–µ—Ä (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                tmdb_id = jellyfin_get_tmdb_id(series_id) if 'jellyfin_get_tmdb_id' in globals() else None
                trailer_url = safe_get_trailer_prefer_tmdb(f"{series_name_cleaned} Trailer {release_year}",
                                subkind="show", tmdb_id=tmdb_id, context="")

                # 3) —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                notification_message = (
                    f"*{t('new_season_title')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n"
                    f"*{season_name}*"
                )
                if total >= present and total > 0:
                    notification_message += f"\n\n{t('season_added_progress').format(added=present, total=total)}"
                elif present > 0:
                    notification_message += f"\n\n{t('season_added_count_only').format(added=present)}"
                if overview_to_use:
                    notification_message += f"\n\n{overview_to_use}"
                if tmdb_id:
                    ratings_text = safe_fetch_mdblist_ratings("show", tmdb_id)
                    if ratings_text:
                        notification_message += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"
                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                if INCLUDE_AUDIO_TRACKS:
                    tracks_block = build_audio_tracks_block_for_season(season_id)
                    if tracks_block:
                        notification_message += tracks_block

                # 4) –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏ —Ñ–∏–∫—Å–∏—Ä—É–µ–º ¬´–¥–æ –∫—É–¥–∞ —Å–æ–æ–±—â–∏–ª–∏¬ª
                if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                    send_notification(season_id, notification_message)
                else:
                    send_notification(series_id, notification_message)
                    logging.warning(
                        f"(Series poll) {series_name_cleaned} {season_name} image missing; using series image")

                # –ø–æ–º–µ—á–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å: —Ç–µ–ø–µ—Ä—å last_notified_present = present
                _sp_upsert(
                    season_id,
                    present=present, total=total,
                    series_id=series_id,
                    season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                    series_name=series_name_cleaned,
                    release_year=release_year,
                    mark_notified=True
                )

                logging.info(
                    f"(Series poll) Season announced: {series_name_cleaned} {season_name} ‚Äî {present} / {total}")
                processed_seasons.add(season_id)

            except Exception as ex:
                logging.warning(f"Series poll: season from ep {ep.get('Id')} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        logging.debug(f"Series poll: page fetched {n} episodes (total {fetched})")
        if n < current_limit:
            break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

def _series_poll_loop():
    while True:
        try:
            poll_recent_episodes_once()
        except Exception as ex:
            logging.warning(f"Series poll loop error: {ex}")
        time.sleep(SERIES_POLL_INTERVAL_SEC)

if SERIES_POLL_ENABLED:
    threading.Thread(target=_series_poll_loop, name="series-poll", daemon=True).start()
    logging.info(f"Series polling enabled every {SERIES_POLL_INTERVAL_SEC}s "
                 f"(page={SERIES_POLL_PAGE_SIZE}, max_total={SERIES_POLL_MAX_TOTAL}, grace={SERIES_POLL_GRACE_MIN}m)")


def _sq_get(season_id: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""
            SELECT season_id, series_id, series_name, season_number, release_year, signature, updated_at, episode_count
            FROM season_quality WHERE season_id=?""", (season_id,))
        row = cur.fetchone()
        if not row:
            return None
        return {
            "season_id": row[0],
            "series_id": row[1],
            "series_name": row[2],
            "season_number": row[3],
            "release_year": row[4],
            "signature": row[5],
            "updated_at": row[6],
            "episode_count": row[7],
        }
    except Exception as ex:
        logging.warning(f"_sq_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass


def _sq_upsert(season_id: str, *, signature: str,
               episode_count: int | None,
               series_id: str | None = None,
               series_name: str | None = None,
               season_number: int | None = None,
               release_year: int | None = None):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00', 'Z')
        cur.execute("""
            INSERT INTO season_quality (season_id, series_id, series_name, season_number, release_year, signature, updated_at, episode_count)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ON CONFLICT(season_id) DO UPDATE SET
              signature=excluded.signature,
              updated_at=excluded.updated_at,
              episode_count=excluded.episode_count,
              series_id=COALESCE(excluded.series_id, season_quality.series_id),
              series_name=COALESCE(excluded.series_name, season_quality.series_name),
              season_number=COALESCE(excluded.season_number, season_quality.season_number),
              release_year=COALESCE(excluded.release_year, season_quality.release_year)
        """, (season_id, series_id, series_name, season_number, release_year, signature, nowz, episode_count))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sq_upsert failed: {ex}")
    finally:
        try: conn.close()
        except: pass


def _sp_get(season_id: str) -> dict | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("""
            SELECT season_id, series_id, series_name, season_number, release_year,
                   present, total, last_notified_present, updated_at
            FROM season_progress WHERE season_id=?""", (season_id,))
        row = cur.fetchone()
        if not row:
            return None
        return {
            "season_id": row[0], "series_id": row[1], "series_name": row[2],
            "season_number": row[3], "release_year": row[4],
            "present": row[5], "total": row[6],
            "last_notified_present": row[7], "updated_at": row[8],
        }
    except Exception as ex:
        logging.warning(f"_sp_get failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _sp_upsert(season_id: str, *, present: int, total: int,
               series_id: str | None = None, season_number: int | None = None,
               series_name: str | None = None, release_year: int | None = None,
               mark_notified: bool = False):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å —Å–µ–∑–æ–Ω–∞ –¢–û–õ–¨–ö–û –ø—Ä–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö.
    - –±–µ–∑ mark_notified: –æ–±–Ω–æ–≤–ª—è–µ–º, –µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å present/total
    - —Å mark_notified: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø–∏—à–µ–º last_notified_present=present (–µ—Å–ª–∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è)
    –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ –∏ ¬´–º–∏–≥–∞–Ω–∏–µ¬ª mtime —É —Ñ–∞–π–ª–∞ –ë–î.
    """
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        nowz = datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')

        # —á–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        cur.execute("""
            SELECT present, total, last_notified_present
            FROM season_progress WHERE season_id=?
        """, (season_id,))
        row = cur.fetchone()

        if row:
            old_present, old_total, old_last = (row[0] or 0), (row[1] or 0), (row[2] or 0)

            # —Ä–µ—à–∞–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–∏—Å–∞—Ç—å
            need_update = False
            set_last = None

            if present != old_present or total != old_total:
                need_update = True
            if mark_notified and old_last != present:
                need_update = True
                set_last = present

            if not need_update:
                # –Ω–∏—á–µ–≥–æ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ‚Äî –≤—ã—Ö–æ–¥–∏–º –±–µ–∑ –∑–∞–ø–∏—Å–∏
                return

            if mark_notified:
                cur.execute("""
                    UPDATE season_progress
                    SET present=?, total=?, last_notified_present=?, updated_at=?,
                        series_id=COALESCE(?, series_id),
                        series_name=COALESCE(?, series_name),
                        season_number=COALESCE(?, season_number),
                        release_year=COALESCE(?, release_year)
                    WHERE season_id=?
                """, (present, total, (set_last if set_last is not None else old_last), nowz,
                      series_id, series_name, season_number, release_year, season_id))
            else:
                cur.execute("""
                    UPDATE season_progress
                    SET present=?, total=?, updated_at=?,
                        series_id=COALESCE(?, series_id),
                        series_name=COALESCE(?, series_name),
                        season_number=COALESCE(?, season_number),
                        release_year=COALESCE(?, release_year)
                    WHERE season_id=?
                """, (present, total, nowz,
                      series_id, series_name, season_number, release_year, season_id))
        else:
            # –ø–µ—Ä–≤–∞—è –∑–∞–ø–∏—Å—å –ø–æ —Å–µ–∑–æ–Ω—É
            cur.execute("""
                INSERT INTO season_progress (
                    season_id, series_id, series_name, season_number, release_year,
                    present, total, last_notified_present, updated_at
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (season_id, series_id, series_name, season_number, release_year,
                  int(present), int(total),
                  int(present) if mark_notified else 0,
                  nowz))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sp_upsert failed: {ex}")
    finally:
        try: conn.close()
        except: pass

def _sp_should_notify(season_id: str, present_now: int) -> bool:
    row = _sp_get(season_id)
    if row is None:
        # –≤–ø–µ—Ä–≤—ã–µ –≤–∏–¥–∏–º —Å–µ–∑–æ–Ω: —Å–ª–∞—Ç—å —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ –∏ –µ—Å—Ç—å —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ
        return SERIES_POLL_INITIAL_ANNOUNCE and present_now > 0
    last = int(row.get("last_notified_present") or 0)
    return present_now > last

#–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–π–ª–µ—Ä–æ–≤ –∏ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
def _utcnow_iso() -> str:
    return datetime.now(timezone.utc).isoformat(timespec='seconds').replace('+00:00','Z')

def _extcache_key(kind: str, subkind: str | None, identity: str) -> str:
    # –ï–¥–∏–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–∞
    s = subkind or "-"
    return f"{kind}:{s}:{identity}".strip()

def _extcache_read(kind: str, subkind: str | None, identity: str) -> tuple[str | None, str | None]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (value, updated_at_iso) –∏–∑ external_cache –∏–ª–∏ (None, None).
    """
    if not EXTERNAL_CACHE_ENABLED:
        return (None, None)
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        ck = _extcache_key(kind, subkind, identity)
        cur.execute("SELECT value, updated_at FROM external_cache WHERE cache_key=?", (ck,))
        row = cur.fetchone()
        return (row[0], row[1]) if row else (None, None)
    except Exception as ex:
        logging.warning(f"_extcache_read fail: {ex}")
        return (None, None)
    finally:
        try: conn.close()
        except: pass

def _extcache_write(kind: str, subkind: str | None, identity: str, value: str | None):
    if not EXTERNAL_CACHE_ENABLED:
        return
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        ck = _extcache_key(kind, subkind, identity)
        cur.execute("""
            INSERT INTO external_cache (cache_key, kind, subkind, value, updated_at)
            VALUES (?, ?, ?, ?, ?)
            ON CONFLICT(cache_key) DO UPDATE SET value=excluded.value, updated_at=excluded.updated_at
        """, (ck, kind, subkind or "", value or "", _utcnow_iso()))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_extcache_write fail: {ex}")
    finally:
        try: conn.close()
        except: pass

def _is_fresh(updated_iso: str | None, ttl_days: int) -> bool:
    if not updated_iso:
        return False
    try:
        dt = datetime.fromisoformat(updated_iso.replace('Z', '+00:00'))
        return datetime.now(timezone.utc) - dt <= timedelta(days=max(ttl_days, 0))
    except Exception:
        return False

#–ü–æ–∏—Å–∫ —Ç—Ä–µ–π–ª–µ—Ä–æ–≤ –Ω–∞ tmdb
def _tmdb_pick_best_video(results: list[dict]) -> str | None:
    """
    –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Ç—Ä–µ–π–ª–µ—Ä –∏–∑ TMDB /videos.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: YouTube + type=Trailer + official=true ‚Üí YouTube + Trailer ‚Üí YouTube ‚Üí Vimeo.
    """
    if not results:
        return None

    def to_url(site: str | None, key: str | None) -> str | None:
        if not site or not key:
            return None
        s = site.lower()
        if s == "youtube":
            return f"https://www.youtube.com/watch?v={key}"
        if s == "vimeo":
            return f"https://vimeo.com/{key}"
        return None

    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    vids = []
    for v in results:
        vids.append({
            "site": (v.get("site") or v.get("Site") or "").strip(),
            "type": (v.get("type") or v.get("Type") or "").strip(),
            "official": bool(v.get("official") if v.get("official") is not None else v.get("Official")),
            "key": v.get("key") or v.get("Key"),
            "size": v.get("size") or v.get("Size") or 0,
            "published_at": v.get("published_at") or v.get("PublishedAt") or "",
        })

    # 1) YouTube + Trailer + official
    for v in vids:
        if v["site"].lower() == "youtube" and v["type"].lower() == "trailer" and v["official"]:
            u = to_url(v["site"], v["key"])
            if u: return u
    # 2) YouTube + Trailer
    for v in vids:
        if v["site"].lower() == "youtube" and v["type"].lower() == "trailer":
            u = to_url(v["site"], v["key"])
            if u: return u
    # 3) –ª—é–±–æ–π YouTube
    for v in vids:
        if v["site"].lower() == "youtube":
            u = to_url(v["site"], v["key"])
            if u: return u
    # 4) Vimeo (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    for v in vids:
        if v["site"].lower() == "vimeo":
            u = to_url(v["site"], v["key"])
            if u: return u
    return None


def _tmdb_fetch_trailer_url(subkind: str, tmdb_id: str, season_number: int | None = None) -> str | None:
    """
    subkind: 'movie' | 'show'
    –î–ª—è —Ñ–∏–ª—å–º–æ–≤: /movie/{id}/videos
    –î–ª—è —Å–µ—Ä–∏–∞–ª–æ–≤: /tv/{id}/videos, –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–±—É–µ–º /tv/{id}/season/{n}/videos
    """
    if not TMDB_API_KEY or not tmdb_id:
        return None
    try:
        params = {
            "api_key": TMDB_API_KEY,
            "language": TMDB_LANGUAGE,
            # –≤–∫–ª—é—á–∏—Ç—å —Ä–æ–ª–∏–∫–∏ –±–µ–∑ —è–∑—ã–∫–æ–≤–æ–π –º–µ—Ç–∫–∏
            "include_video_language": f"{TMDB_LANGUAGE},null"
        }
        if subkind == "movie":
            url = f"{TMDB_BASE}/movie/{tmdb_id}/videos"
            r = requests.get(url, params=params, timeout=10)
            r.raise_for_status()
            data = r.json() or {}
            return _tmdb_pick_best_video(data.get("results") or [])
        else:
            # –ø—Ä–æ–±—É–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–µ—Ä–∏–∞–ª–∞
            url = f"{TMDB_BASE}/tv/{tmdb_id}/videos"
            r = requests.get(url, params=params, timeout=10)
            r.raise_for_status()
            data = r.json() or {}
            url_pick = _tmdb_pick_best_video(data.get("results") or [])
            if url_pick:
                return url_pick
            # –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ ‚Äî —É—Ä–æ–≤–µ–Ω—å —Å–µ–∑–æ–Ω–∞
            if season_number is not None:
                url = f"{TMDB_BASE}/tv/{tmdb_id}/season/{int(season_number)}/videos"
                r = requests.get(url, params=params, timeout=10)
                r.raise_for_status()
                data = r.json() or {}
                return _tmdb_pick_best_video(data.get("results") or [])
            return None
    except Exception as ex:
        logging.warning(f"TMDB trailer fetch failed ({subkind}:{tmdb_id} s{season_number}): {ex}")
        return None

def safe_get_trailer_prefer_tmdb(
    title: str,
    *,
    year: int | None = None,
    subkind: str,                 # 'movie' | 'show'
    tmdb_id: str | None = None,
    season_number: int | None = None,
    context: str = ""
) -> str | None:
    """
    1) –ß–∏—Ç–∞–µ–º –∫—ç—à external_cache('trailer', subkind, identity) ‚Äî identity=tmdb_id –∏–ª–∏ title+year.
    2) –ï—Å–ª–∏ –∫—ç—à —Å–≤–µ–∂–∏–π ‚Äî –æ—Ç–¥–∞—ë–º.
    3) –ò–Ω–∞—á–µ –ø—Ä–æ–±—É–µ–º TMDB ‚Üí –µ—Å–ª–∏ –Ω–∞—à–ª–∏ ‚Äî –ø–∏—à–µ–º –≤ –∫—ç—à –∏ –æ—Ç–¥–∞—ë–º.
    4) –ò–Ω–∞—á–µ fallback: YouTube-–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ safe_get_trailer(query, ...), —Ç–æ–∂–µ –∫–ª–∞–¥—ë–º –≤ –∫—ç—à.
    """
    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º identity –∏ query –¥–ª—è –∫—ç—à–∞/—Ñ–æ–ª–ª–±—ç–∫–∞
    identity = (tmdb_id or "").strip() or f"{title.strip()} ({year})".strip()
    cached_val, cached_at = _extcache_read("trailer", subkind, identity)
    if _is_fresh(cached_at, TRAILER_CACHE_TTL_DAYS) and cached_val:
        return cached_val

    # 1) TMDB
    url_tmdb = None
    try:
        url_tmdb = _tmdb_fetch_trailer_url(subkind, tmdb_id, season_number) if tmdb_id else None
    except Exception as ex:
        logging.warning(f"safe_get_trailer_prefer_tmdb: TMDB branch failed: {ex}")

    if url_tmdb:
        _extcache_write("trailer", subkind, identity, url_tmdb)
        return url_tmdb

    # 2) Fallback: YouTube –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é + –≥–æ–¥—É
    q_year = f" {year}" if year else ""
    query = f"{title} Trailer{q_year}".strip()
    url_yt = safe_get_trailer(query, context=context, subkind=subkind, tmdb_id=tmdb_id)
    if url_yt:
        _extcache_write("trailer", subkind, identity, url_yt)
        return url_yt

    # 3) –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏: –≤–µ—Ä–Ω—ë–º —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ, –µ—Å–ª–∏ –±—ã–ª–æ
    return cached_val or None

#–ü–æ–ª—É—á–µ–Ω–∏–µ –∑–≤—É–∫–æ–≤—ã—Ö –¥–æ—Ä–æ–∂–µ–∫ –¥–ª—è —Å–µ—Ä–∏–∞–ª–æ–≤
def _label_audio_stream(stream: dict) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫—É—é¬ª –ø–æ–¥–ø–∏—Å—å –¥–æ—Ä–æ–∂–∫–∏ –∫–∞–∫ –≤ —Ñ–∏–ª—å–º–∞—Ö:
    DisplayTitle/Title -> –∏–Ω–∞—á–µ LANG CODEC Ch Layout (–Ω–∞–ø—Ä–∏–º–µ—Ä: ENG AC3 6ch 5.1)
    """
    label = stream.get("DisplayTitle") or stream.get("Title")
    if label:
        return str(label)
    lang = stream.get("Language")
    codec = stream.get("Codec")
    ch = stream.get("Channels")
    layout = stream.get("ChannelLayout")
    parts = []
    if lang:   parts.append(str(lang).upper())
    if codec:  parts.append(str(codec).upper())
    if ch:     parts.append(f"{ch}ch")
    if layout: parts.append(str(layout))
    return " ".join(parts) or "Audio"

def _collect_season_audio_labels(season_id: str) -> list[str]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫ –∏–∑ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —ç–ø–∏–∑–æ–¥–æ–≤ —Å–µ–∑–æ–Ω–∞.
    –ë–µ—Ä—ë–º –Ω–µ –±–æ–ª–µ–µ SEASON_AUDIO_SCAN_LIMIT —ç–ø–∏–∑–æ–¥–æ–≤ –∏ –Ω–µ –±–æ–ª–µ–µ SEASON_AUDIO_TRACKS_MAX —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ—Ä–æ–∂–µ–∫.
    """
    labels_seen = []
    label_set = set()

    # –∑–∞–ø—Ä–æ—Å–∏–º —ç–ø–∏–∑–æ–¥—ã —Å–µ–∑–æ–Ω–∞ —Å MediaSources (–∫–∞–∫ —É —Ç–µ–±—è —É–∂–µ –¥–µ–ª–∞–µ—Ç—Å—è)
    eps = _season_fetch_episodes(season_id)  # –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å Items —Å MediaSources/LocationType/Path
    # —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ (–µ—Å—Ç—å —Ñ–∞–π–ª)
    present_eps = [ep for ep in eps if _episode_has_file(ep)]

    # –æ–≥—Ä–∞–Ω–∏—á–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞, —á—Ç–æ–±—ã –Ω–µ –≥—Ä—É–∑–∏—Ç—å –ª–∏—à–Ω–µ–µ
    for ep in present_eps[:max(SEASON_AUDIO_SCAN_LIMIT, 1)]:
        sources = ep.get("MediaSources") or []
        if not sources:
            continue
        # –≤–æ–∑—å–º—ë–º –ø–µ—Ä–≤—É—é ¬´–æ—Å–Ω–æ–≤–Ω—É—é¬ª –¥–æ—Ä–æ–∂–∫—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        src = sources[0]
        for s in (src.get("MediaStreams") or []):
            if s.get("Type") != "Audio":
                continue
            lbl = _label_audio_stream(s)
            if lbl not in label_set:
                label_set.add(lbl)
                labels_seen.append(lbl)
                if len(labels_seen) >= SEASON_AUDIO_TRACKS_MAX:
                    return labels_seen
    return labels_seen

def _season_fetch_episodes(season_id: str, *, max_items: int | None = None) -> list[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —ç–ø–∏–∑–æ–¥–æ–≤ —Å–µ–∑–æ–Ω–∞ —Å –Ω—É–∂–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞—É–¥–∏–æ:
    - –ë–µ—Ä—ë–º –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —ç–ø–∏–∑–æ–¥—ã (IsMissing=false, LocationTypes=FileSystem)
    - –¢—è–Ω–µ–º –ø–æ–ª—è MediaSources/LocationType/Path/IndexNumber/Name
    - –ü–∞–≥–∏–Ω–∞—Ü–∏—è –¥–æ max_items (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é SEASON_AUDIO_SCAN_LIMIT –∏–ª–∏ 50)
    """
    try:
        per_page = 200
        # –æ–≥—Ä–∞–Ω–∏—á–∏–º –æ–±—ä—ë–º: –Ω–∞–º –¥–ª—è —Å–ø–∏—Å–∫–∞ –¥–æ—Ä–æ–∂–µ–∫ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç—å —Å–µ–∑–æ–Ω–∞
        default_scan_limit = 50
        try:
            default_scan_limit = max(int(globals().get("SEASON_AUDIO_SCAN_LIMIT", 50)), 1)
        except Exception:
            pass
        cap = int(max_items) if isinstance(max_items, int) and max_items > 0 else default_scan_limit

        all_eps: list[dict] = []
        start = 0
        while True:
            # –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –±–æ–ª—å—à–µ, —á–µ–º –æ—Å—Ç–∞–ª–æ—Å—å –¥–æ cap
            limit = per_page if (len(all_eps) + per_page) <= cap else (cap - len(all_eps))
            if limit <= 0:
                break

            params = {
                "api_key": JELLYFIN_API_KEY,
                "ParentId": season_id,
                "IncludeItemTypes": "Episode",
                "Recursive": "false",
                # –∫–ª—é—á–µ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã: —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
                "IsMissing": "false",
                "LocationTypes": "FileSystem",
                # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —ç–ø–∏–∑–æ–¥–∞
                "SortBy": "IndexNumber,DateCreated",
                "SortOrder": "Ascending",
                "StartIndex": str(start),
                "Limit": str(limit),
                # –ø–æ–ª—è, –Ω—É–∂–Ω—ã–µ –¥–ª—è –∞—É–¥–∏–æ-–∞–Ω–∞–ª–∏—Ç–∏–∫–∏
                "Fields": "MediaSources,LocationType,Path,IndexNumber,Name"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=12)
            r.raise_for_status()
            data = r.json() or {}
            items = data.get("Items") or []
            if not items:
                break

            all_eps.extend(items)
            start += len(items)
            if len(items) < limit:
                break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

        return all_eps
    except requests.HTTPError as ex:
        status = getattr(getattr(ex, "response", None), "status_code", None)
        if status in (400, 404):
            return []  # —Å–µ–∑–æ–Ω —É–¥–∞–ª—ë–Ω ‚Äî –º–æ–ª—á–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ
        logging.warning(f"_season_fetch_episodes failed (season {season_id}): {ex}")
        return []
    except Exception as ex:
        logging.warning(f"_season_fetch_episodes failed (season {season_id}): {ex}")
        return []


def _episode_has_file(ep: dict) -> bool:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —É —ç–ø–∏–∑–æ–¥–∞ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª.
    –ü—Ä–æ–≤–µ—Ä—è–µ–º:
      - LocationType == FileSystem/File (–Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
      - –∏–ª–∏ –∑–∞–¥–∞–Ω Path
      - –∏–ª–∏ –µ—Å—Ç—å MediaSources (–Ω–µ –ø—É—Å—Ç–æ) —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ —Ñ–∞–π–ª–∞
    """
    try:
        lt = (ep.get("LocationType") or "").strip().lower()
        if lt in ("filesystem", "file"):
            return True

        if ep.get("Path"):
            return True

        ms = ep.get("MediaSources") or []
        if ms:
            for src in ms:
                # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
                src_lt = (src.get("LocationType") or "").strip().lower()
                if src_lt in ("filesystem", "file"):
                    return True
                if src.get("Path"):
                    return True
                # –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞/—Ä–∞–∑–º–µ—Ä–∞ —á–∞—Å—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ñ–∞–π–ª–µ
                if src.get("Container") or src.get("Size"):
                    return True
        return False
    except Exception:
        return False

def _plural_episodes(n: int, lang: str) -> str:
    lang = (lang or "").lower()
    if lang.startswith("ru"):
        n10, n100 = n % 10, n % 100
        if n10 == 1 and n100 != 11:
            return "—ç–ø–∏–∑–æ–¥"
        if 2 <= n10 <= 4 and not (12 <= n100 <= 14):
            return "—ç–ø–∏–∑–æ–¥–∞"
        return "—ç–ø–∏–∑–æ–¥–æ–≤"
    return "episode" if n == 1 else "episodes"

def _collect_season_audio_label_counts(season_id: str) -> tuple[OrderedDict[str, int], int]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (OrderedDict[display_label -> count], present_episodes_count).
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –º–µ—Ç–∫–∏ –¥–æ—Ä–æ–∂–µ–∫ —Å —É—á—ë—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (_normalize_audio_label),
    —á—Ç–æ–±—ã 'HDRezka' –∏ 'HDrezka' —Å—á–∏—Ç–∞–ª–∏—Å—å –æ–¥–Ω–æ–π –¥–æ—Ä–æ–∂–∫–æ–π.
    """
    try:
        eps = _season_fetch_episodes(season_id)
        present_eps = [ep for ep in eps if _episode_has_file(ep)]
        scan_limit = max(int(globals().get("SEASON_AUDIO_SCAN_LIMIT", 50)), 1)

        # norm_label -> [display_label (–ø–µ—Ä–≤–∞—è –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω–∞—è), count]
        groups: dict[str, list] = {}

        for ep in present_eps[:scan_limit]:
            sources = ep.get("MediaSources") or []
            if not sources:
                continue
            src = sources[0]
            for s in (src.get("MediaStreams") or []):
                if s.get("Type") != "Audio":
                    continue
                raw_label = _label_audio_stream(s)
                norm = _normalize_audio_label(raw_label)
                if norm not in groups:
                    # —Å–æ—Ö—Ä–∞–Ω–∏–º —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—É—é –º–µ—Ç–∫—É ¬´–∫–∞–∫ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞—Å—å –≤–ø–µ—Ä–≤—ã–µ¬ª
                    groups[norm] = [raw_label.strip(), 1]
                else:
                    groups[norm][1] += 1

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—á—ë—Ç—á–∏–∫–∞, –∑–∞—Ç–µ–º –ø–æ –º–µ—Ç–∫–µ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π)
        sorted_items = sorted(groups.items(), key=lambda kv: (-kv[1][1], kv[0]))
        ordered = OrderedDict((disp, cnt) for (_norm, (disp, cnt)) in sorted_items)
        return ordered, len(present_eps)
    except Exception as ex:
        logging.warning(f"_collect_season_audio_label_counts failed for {season_id}: {ex}")
        return OrderedDict(), 0

def build_audio_tracks_block_for_season(season_id: str) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫ –¥–ª—è —Å–µ–∑–æ–Ω–∞ –≤ –≤–∏–¥–µ:
      *Audio tracks* (N)
      - RUS AC3 5.1 √ó 5 —ç–ø–∏–∑–æ–¥–æ–≤
      - ENG EAC3 6ch √ó 3 —ç–ø–∏–∑–æ–¥–∞
      ...
    """
    try:
        labels_counts, present_cnt = _collect_season_audio_label_counts(season_id)
        if not labels_counts:
            return ""

        lang = os.environ.get("LANGUAGE", "en")
        # –∑–∞–≥–æ–ª–æ–≤–æ–∫ (fallback, –µ—Å–ª–∏ –Ω–µ—Ç –∫–ª—é—á–∞ –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–∏)
        header = (MESSAGES.get(LANG, {}) or {}).get("audio_tracks_header") or \
                 ( "–ê—É–¥–∏–æ-–¥–æ—Ä–æ–∂–∫–∏" if lang.lower().startswith("ru") else "Audio tracks" )

        max_labels = max(int(globals().get("SEASON_AUDIO_TRACKS_MAX", 12)), 1)
        lines = [f"\n\n*{header}* ({min(len(labels_counts), max_labels)})"]

        i = 0
        for label, count in labels_counts.items():
            if i >= max_labels:
                break
            lines.append(f"- {label} √ó {count} {_plural_episodes(count, lang)}")
            i += 1

        return "\n".join(lines)
    except Exception as ex:
        logging.warning(f"Season audio block build failed for {season_id}: {ex}")
        return ""

def _normalize_audio_label(label: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –º–µ—Ç–∫—É –∫ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–º—É –≤–∏–¥—É –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
    - casefold (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
    - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω–Ω—ã—Ö —Ç–∏—Ä–µ –∫ '-'
    - –µ–¥–∏–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–µ—Ñ–∏—Å–∞ –∏ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫–∏
    """
    s = (label or "").strip()
    s = re.sub(r"[‚Äì‚Äî‚àí]", "-", s)              # –≤—Å–µ —Ç–∏—Ä–µ -> '-'
    s = re.sub(r"\s*-\s*", " - ", s)          # –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥ –¥–µ—Ñ–∏—Å–∞
    s = re.sub(r"\s+", " ", s)                # —Å—Ö–ª–æ–ø–Ω—É—Ç—å –ø—Ä–æ–±–µ–ª—ã
    return s.casefold()                        # —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ

#–ö–æ–Ω—Ç—Ä–æ–ª—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–¥–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è)
def _db_get_created_at_iso() -> str | None:
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("SELECT value FROM app_meta WHERE key='db_created_at'")
        row = cur.fetchone()
        return row[0] if row else None
    except Exception as ex:
        logging.warning(f"db_created_at read failed: {ex}")
        return None
    finally:
        try: conn.close()
        except: pass

def _parse_iso_dt(s: str | None):
    if not s:
        return None
    try:
        return datetime.fromisoformat(s.replace('Z', '+00:00'))
    except Exception:
        return None

def _sp_delete(season_id: str):
    try:
        conn = sqlite3.connect(QUALITY_DB_FILE)
        cur = conn.cursor()
        cur.execute("DELETE FROM season_progress WHERE season_id=?", (season_id,))
        conn.commit()
    except Exception as ex:
        logging.warning(f"_sp_delete failed for {season_id}: {ex}")
    finally:
        try: conn.close()
        except: pass

#–£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–µ–∑–æ–Ω–æ–≤
def _episode_media_quality_signature_from_ep(ep: dict) -> str:
    """
    –°—Ç—Ä–æ–∏—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä—É –∫–∞—á–µ—Å—Ç–≤–∞ —ç–ø–∏–∑–æ–¥–∞ –ø–æ –ø–µ—Ä–≤–æ–º—É MediaSource (–±–µ–∑ —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤).
    """
    try:
        sources = ep.get("MediaSources") or []
        if not sources:
            return ""
        src = sources[0]
        streams = src.get("MediaStreams") or []

        v = next((s for s in streams if s.get("Type")=="Video"), None)
        a = next((s for s in streams if s.get("Type")=="Audio"), None)

        q = {}
        # –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä/—Ä–∞–∑–º–µ—Ä/–±–∏—Ç—Ä–µ–π—Ç
        q["container"] = (src.get("Container") or "").lower()
        try: q["size_bytes"] = int(src.get("Size") or 0)
        except Exception: q["size_bytes"] = 0
        try: q["video_bitrate_kbps"] = int((src.get("Bitrate") or 0)) // 1000
        except Exception: q["video_bitrate_kbps"] = None

        if v:
            q["video_codec"] = (v.get("Codec") or "").lower()
            q["width"]  = v.get("Width") or v.get("PixelWidth")
            q["height"] = v.get("Height") or v.get("PixelHeight")
            q["bit_depth"] = v.get("BitDepth")
            # fps
            fps = v.get("RealFrameRate") or v.get("AverageFrameRate") or v.get("FrameRate")
            try: q["fps"] = float(fps) if fps is not None else None
            except Exception: q["fps"] = None
            # –ø—Ä–æ—Ñ–∏–ª–∏ HDR/DV
            q["image_profiles"] = _detect_image_profiles_from_fields(v)

        if a:
            q["audio_codec"] = (a.get("Codec") or "").lower()
            try: q["audio_channels"] = int(a.get("Channels") or 0)
            except Exception: q["audio_channels"] = None
            try: q["audio_bitrate_kbps"] = int((a.get("BitRate") or 0)) // 1000
            except Exception: q["audio_bitrate_kbps"] = None

        sig = _quality_signature(q)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
        return sig or ""
    except Exception as ex:
        logging.debug(f"episode quality signature failed: {ex}")
        return ""

def _season_quality_signature(season_id: str, *, scan_limit: int | None = None) -> str:
    """
    –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ —Å–µ–∑–æ–Ω–∞ = sha1 –æ—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–∏–≥–Ω–∞—Ç—É—Ä —ç–ø–∏–∑–æ–¥–æ–≤ (—Å —Ñ–∞–π–ª–∞–º–∏).
    """
    eps = _season_fetch_episodes(season_id)
    present_eps = [ep for ep in eps if _episode_has_file(ep)]
    lim = max(int(globals().get("SEASON_QUALITY_SIG_LIMIT", 80)), 1)
    if scan_limit is not None:
        lim = max(int(scan_limit), 1)

    sigs = []
    for ep in present_eps[:lim]:
        s = _episode_media_quality_signature_from_ep(ep)
        if s:
            sigs.append(s)

    if not sigs:
        return ""

    sigs.sort()
    joined = "||".join(sigs).encode("utf-8", errors="ignore")
    return hashlib.sha1(joined).hexdigest()


def _season_quality_snapshot(season_id: str, *, scan_limit: int | None = None) -> tuple[str, int]:
    sig = _season_quality_signature(season_id, scan_limit=scan_limit)
    eps = _season_fetch_episodes(season_id)
    present = len([ep for ep in eps if _episode_has_file(ep)])
    return (sig, present)

def _notify_season_quality_updated(season_id: str):
    # –¥–µ—Ç–∞–ª–∏ —Å–µ–∑–æ–Ω–∞/—Å–µ—Ä–∏–∞–ª–∞
    season_details = get_item_details(season_id)
    s_item = (season_details.get("Items") or [{}])[0]
    series_id = s_item.get("SeriesId")
    season_name = s_item.get("Name") or "Season"
    release_year = s_item.get("ProductionYear")

    series_details = get_item_details(series_id) if series_id else {"Items":[{}]}
    series_item = (series_details.get("Items") or [{}])[0]
    series_name = series_item.get("Name") or ""
    overview = s_item.get("Overview") or series_item.get("Overview") or ""

    series_name_cleaned = series_name.replace(f" ({release_year})","").strip()

    # —Ä–µ–π—Ç–∏–Ω–≥–∏ + —Ç—Ä–µ–π–ª–µ—Ä
    tmdb_id = jellyfin_get_tmdb_id(series_id) if 'jellyfin_get_tmdb_id' in globals() else None
    trailer_url = safe_get_trailer_prefer_tmdb(f"{series_name_cleaned} Trailer {release_year}",
                                               subkind="show", tmdb_id=tmdb_id, context="")

    msg = f"*{t('quality_updated')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n*{season_name}*"
    if overview:
        msg += f"\n\n{overview}"
    if tmdb_id:
        ratings_text = safe_fetch_mdblist_ratings("show", tmdb_id)
        if ratings_text:
            msg += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"
    if trailer_url:
        msg += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

    if INCLUDE_AUDIO_TRACKS:
        tracks_block = build_audio_tracks_block_for_season(season_id)
        if tracks_block:
            msg += tracks_block

    # –ø–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–æ—Å—Ç–µ—Ä —Å–µ—Ä–∏–∞–ª–∞
    if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
        send_notification(season_id, msg)
    else:
        send_notification(series_id, msg)
        logging.warning(f"(EpQuality poll) season image missing; used series image for {series_name_cleaned} {season_name}")

def _maybe_notify_season_quality_change(season_id: str) -> bool:
    # –¢–µ–∫—É—â–∏–π —Å–Ω–∏–º–æ–∫
    new_sig, new_count = _season_quality_snapshot(season_id)
    if not new_sig:
        return False  # –∂–¥—ë–º, –∫–æ–≥–¥–∞ Jellyfin –æ—Ç–¥–∞—Å—Ç MediaSources/—Ñ–∞–π–ª—ã

    row = _sq_get(season_id)
    if row is None:
        # Baseline: —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É –∏ count, –±–µ–∑ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        try:
            sd = get_item_details(season_id)
            s_item = (sd.get("Items") or [{}])[0]
            _sq_upsert(
                season_id,
                signature=new_sig,
                episode_count=new_count,
                series_id=s_item.get("SeriesId"),
                series_name=None,
                season_number=int(s_item.get("IndexNumber")) if s_item.get("IndexNumber") is not None else None,
                release_year=s_item.get("ProductionYear"),
            )
        except Exception:
            _sq_upsert(season_id, signature=new_sig, episode_count=new_count)
        return False

    old_sig = row.get("signature") or ""
    old_count = row.get("episode_count")
    # 1) –ï—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å —á–∏—Å–ª–æ —ç–ø–∏–∑–æ–¥–æ–≤ –≤ —Å–µ–∑–æ–Ω–µ ‚Äî –æ–±–Ω–æ–≤–ª—è–µ–º baseline –∏ –≤—ã—Ö–æ–¥–∏–º –ë–ï–ó —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
    if (old_count is None) or (old_count != new_count):
        _sq_upsert(season_id, signature=new_sig, episode_count=new_count)
        logging.info(f"(EpQuality) suppressed due to episode_count change: {old_count} -> {new_count} for season {season_id}")
        return False

    # 2) –ï—Å–ª–∏ —Å–∏–≥–Ω–∞—Ç—É—Ä–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å ‚Äî –≤—ã—Ö–æ–¥–∏–º
    if old_sig == new_sig:
        return False

    # 3) –ß–∏—Å—Ç–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–º —á–∏—Å–ª–µ —ç–ø–∏–∑–æ–¥–æ–≤ ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
    _notify_season_quality_updated(season_id)
    _sq_upsert(season_id, signature=new_sig, episode_count=new_count)
    return True

_last_epq_since = datetime.now(timezone.utc)

def poll_episode_quality_once():
    """
    –ò—â–µ–º —ç–ø–∏–∑–æ–¥—ã –ø–æ DateModified (—Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è), —Å–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–µ–∑–æ–Ω—ã,
    –∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–∑–æ–Ω–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.
    –ù–æ–≤—ã–µ (–æ—á–µ–Ω—å —Å–≤–µ–∂–∏–µ) —ç–ø–∏–∑–æ–¥—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ‚Äî –∏—Ö –∞–Ω–æ–Ω—Å–∏—Ä—É–µ—Ç –≤–µ–±—Ö—É–∫/—Å–µ—Ä–∏–π–Ω—ã–π –ø–æ–ª–ª–µ—Ä.
    """
    page_size = EP_QUALITY_POLL_PAGE_SIZE
    max_total = EP_QUALITY_POLL_MAX_TOTAL or 0
    start = 0
    fetched = 0
    now_utc = datetime.now(timezone.utc)
    processed_seasons: set[str] = set()
    triggered = 0

    while True:
        current_limit = page_size if (not max_total or (max_total - fetched) >= page_size) else (max_total - fetched)
        if current_limit <= 0:
            break
        try:
            params = {
                "api_key": JELLYFIN_API_KEY,
                "IncludeItemTypes": "Episode",
                "Recursive": "true",
                "SortBy": "DateModified,DateCreated",
                "SortOrder": "Descending",
                "Limit": str(current_limit),
                "StartIndex": str(start),
                "Fields": "ParentId,DateCreated"
            }
            url = f"{JELLYFIN_BASE_URL}/emby/Items"
            r = requests.get(url, params=params, timeout=20)
            r.raise_for_status()
            payload = r.json() or {}
            items = payload.get("Items") or []
        except Exception as ex:
            logging.warning(f"EpQuality poll: failed page start={start}: {ex}")
            break

        if not items:
            break

        for it in items:
            season_id = it.get("ParentId") or it.get("SeasonId")
            if not season_id or season_id in processed_seasons:
                continue

            # –≥—Ä–µ–π—Å –¥–ª—è ¬´—Å–æ–≤—Å–µ–º –Ω–æ–≤—ã—Ö¬ª —ç–ø–∏–∑–æ–¥–æ–≤
            created_iso = it.get("DateCreated")
            created_dt = _parse_iso_utc(created_iso)
            if created_dt and (now_utc - created_dt) < timedelta(minutes=SERIES_POLL_GRACE_MIN):
                continue

            try:
                if _maybe_notify_season_quality_change(season_id):
                    triggered += 1
                processed_seasons.add(season_id)
            except Exception as ex:
                logging.warning(f"EpQuality poll: season {season_id} failed: {ex}")

        n = len(items)
        fetched += n
        start += n
        if n < current_limit:
            break  # –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞

    global _last_epq_since
#    logging.info(f"(EpQuality poll) processed={len(processed_seasons)}, triggered={triggered}, since={_last_epq_since.isoformat()}")
    _last_epq_since = now_utc

def _ep_quality_poll_loop():
    while True:
        try:
            poll_episode_quality_once()
        except Exception as ex:
            logging.warning(f"EpQuality poll loop error: {ex}")
        time.sleep(EP_QUALITY_POLL_INTERVAL_SEC)

if EP_QUALITY_POLL_ENABLED:
    threading.Thread(target=_ep_quality_poll_loop, name="ep-quality-poll", daemon=True).start()
    logging.info(f"Episode/Season quality polling enabled every {EP_QUALITY_POLL_INTERVAL_SEC}s "
                 f"(page={EP_QUALITY_POLL_PAGE_SIZE}, max_total={EP_QUALITY_POLL_MAX_TOTAL}, grace={SERIES_POLL_GRACE_MIN}m)")


@app.route("/webhook", methods=["POST"])
def announce_new_releases_from_jellyfin():
    try:
        payload = json.loads(request.data)
        item_type = payload.get("ItemType")
        tmdb_id = payload.get("Provider_tmdb")
        item_name = payload.get("Name")
        release_year = payload.get("Year")
        series_name = payload.get("SeriesName")
        season_epi = payload.get("EpisodeNumber00")
        season_num = payload.get("SeasonNumber00")

        if item_type == "Movie":
            movie_id = payload.get("ItemId")
            overview = payload.get("Overview")
            runtime = payload.get("RunTime")

            movie_name = item_name
            movie_name_cleaned = movie_name.replace(f" ({release_year})", "").strip()

            tmdb_id_payload = payload.get("Provider_tmdb") or payload.get("TmdbId")
            imdb_id_payload = payload.get("Provider_imdb") or payload.get("ImdbId")

            # --- –ù–û–í–û–ï: –µ—Å–ª–∏ –Ω–µ–¥–∞–≤–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏ quality-update –ø–æ —Å–∫–∞–Ω–µ—Ä—É/–≥–≤–∞—Ä–¥—É ‚Äî –≥–ª—É—à–∏–º –≤–µ–±—Ö—É–∫
            logical_key = _movie_logical_key(tmdb_id=tmdb_id_payload, imdb_id=imdb_id_payload,
                                             name=movie_name_cleaned, year=release_year)
            if was_quality_update_recent(logical_key):
                logging.info(
                    f"(Webhook/Movie) Suppressed 'new movie' due to recent quality update (logical_key={logical_key})")
                return "Suppressed: recent quality update"

            # 1) –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º –∞–ø–≥—Ä–µ–π–¥ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äî —ç—Ç–æ –¥–æ–ª–∂–Ω–æ —Å—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ–∏–ª—å–º —É–∂–µ ¬´–±—ã–ª –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω¬ª
            if maybe_notify_movie_quality_change(
                    item_id=movie_id,
                    movie_name_cleaned=movie_name_cleaned,
                    release_year=release_year,
                    tmdb_id=tmdb_id_payload,
                    imdb_id=imdb_id_payload,
                    overview=overview,
                    runtime=runtime
            ):
                return "Movie quality update sent"

            # 2) –ò–Ω–∞—á–µ ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–æ–≤–æ–º —Ñ–∏–ª—å–º–µ (–∫–∞–∫ –±—ã–ª–æ)
            if not item_already_notified(item_type, item_name, release_year):
                trailer_url = safe_get_trailer_prefer_tmdb(f"{movie_name_cleaned} Trailer {release_year}",
                                context="webhook", subkind="movie", tmdb_id=tmdb_id)

                notification_message = (
                    f"*{t('new_movie_title')}*\n\n*{movie_name_cleaned}* *({release_year})*\n\n{overview}\n\n"
                    f"*{t('new_runtime')}*\n{runtime}"
                )

                if tmdb_id:
                    mdblist_type = item_type.lower()
                    ratings_text = safe_fetch_mdblist_ratings(mdblist_type, tmdb_id)
                    if ratings_text:
                        notification_message += f"\n\n*{t('new_ratings_movie')}*\n{ratings_text}"

                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # --- Quality changes –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –æ –ù–û–í–û–ú —Ñ–∏–ª—å–º–µ ---
                try:
                    # —Ç–µ–∫—É—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
                    new_q = _get_item_media_info_movie(movie_id)

                    # –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å—Ç–∞—Ä—ã–π —Å–ª–µ–ø–æ–∫ –ø–æ –ª–æ–≥–∏—á–µ—Å–∫–æ–º—É –∫–ª—é—á—É (–µ—Å–ª–∏ —Ñ–∏–ª—å–º –∫–æ–≥–¥–∞-—Ç–æ –±—ã–ª)
                    logical_key = _movie_logical_key(
                        tmdb_id=tmdb_id_payload,
                        imdb_id=imdb_id_payload,
                        name=movie_name_cleaned,
                        year=release_year
                    )
                    old_q = None
                    try:
                        conn = sqlite3.connect(QUALITY_DB_FILE)
                        cur = conn.cursor()
                        cur.execute("""SELECT video_codec,
                                              video_bitrate,
                                              width,
                                              height,
                                              fps,
                                              bit_depth,
                                              dynamic_range,
                                              image_profiles,
                                              audio_codec,
                                              audio_bitrate,
                                              audio_channels,
                                              container,
                                              size_bytes,
                                              duration_sec
                                       FROM content_quality
                                       WHERE logical_key = ?""", (logical_key,))
                        row = cur.fetchone()
                        if row:
                            old_q = {
                                "video_codec": row[0], "video_bitrate": row[1], "width": row[2], "height": row[3],
                                "fps": row[4], "bit_depth": row[5], "dynamic_range": row[6],
                                "image_profiles": ([p.strip() for p in row[7].split(",")] if row[7] else None),
                                "audio_codec": row[8], "audio_bitrate": row[9], "audio_channels": row[10],
                                "container": row[11], "size_bytes": row[12], "duration_sec": row[13],
                            }
                    except Exception as ex:
                        logging.warning(f"Quality (new movie) old snapshot read failed: {ex}")
                    finally:
                        try:
                            conn.close()
                        except Exception:
                            pass

                    # –°—Ñ–æ—Ä–º–∏—Ä—É–µ–º –±–ª–æ–∫:
                    delta_block = build_quality_changes_block(old_q,
                                                              new_q) if old_q else build_initial_quality_changes_block(
                        new_q)
                    if not delta_block:
                        # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π: –µ—Å–ª–∏ –ø–æ—á–µ–º—É-—Ç–æ –±–ª–æ–∫ –ø—É—Å—Ç, –ø–æ–∫–∞–∂–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–π
                        delta_block = build_initial_quality_changes_block(new_q)
                    notification_message += delta_block

                    # (–ø–æ –∂–µ–ª–∞–Ω–∏—é) —Å–ø–∏—Å–æ–∫ –∞—É–¥–∏–æ-–¥–æ—Ä–æ–∂–µ–∫, –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à—ë–Ω —Ñ–ª–∞–≥–æ–º
                    if INCLUDE_AUDIO_TRACKS:
                        tracks_block = build_audio_tracks_block(new_q)
                        if tracks_block:
                            notification_message += tracks_block

                except Exception as ex:
                    logging.warning(f"Quality (new movie) block build failed: {ex}")
                # --- /Quality changes ---

                send_notification(movie_id, notification_message)
                mark_item_as_notified(item_type, item_name, release_year)
                logging.info(f"(Movie) {movie_name} {release_year} notification was sent.")
                return "Movie notification was sent"

        if item_type == "Season":
            # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∫–ª—é—á –¥–ª—è –∞–Ω—Ç–∏—Å–ø–∞–º–∞
            season = item_name  # –Ω–∞–ø—Ä–∏–º–µ—Ä, "–°–µ–∑–æ–Ω 1"
            series_title_for_key = (series_name or "").strip()
            key_name = f"{series_title_for_key} {season}".strip()

            if not item_already_notified(item_type, key_name, release_year):
                season_id = payload.get("ItemId")
                season = item_name
                season_details = get_item_details(season_id)
                series_id = season_details["Items"][0].get("SeriesId")
                series_details = get_item_details(series_id)
                # Remove release_year from series_name if present
                series_name_cleaned = series_name.replace(f" ({release_year})", "").strip()

                # Get TMDb ID via external API
                tmdb_id = jellyfin_get_tmdb_id(series_id)
                trailer_url = safe_get_trailer_prefer_tmdb(f"{series_name_cleaned} Trailer {release_year}",
                                subkind="show", tmdb_id=tmdb_id, context="")

                # **–ù–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏**: –ø–æ–ª—É—á–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∞
                ratings_text = safe_fetch_mdblist_ratings("show", tmdb_id)
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–π—Ç–∏–Ω–≥–∏ ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –Ω–∏—Ö
                ratings_section = f"{ratings_text}\n\n" if ratings_text else ""

                # Get series overview if season overview is empty
                overview_to_use = payload.get("Overview") if payload.get("Overview") else series_details["Items"][0].get(
                    "Overview")

                # —Å—á–∏—Ç–∞–µ–º ¬´—Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å / —Å–∫–æ–ª—å–∫–æ –≤—Å–µ–≥–æ¬ª –ø–æ —Å–µ–∑–æ–Ω—É (–∏—Å–ø–æ–ª—å–∑—É–π —Ç–≤–æ–π resilient-—Ö–µ–ª–ø–µ—Ä)
                present, total = jellyfin_get_season_counts_resilient(season_id)

                if total >= present and total > 0:
                    episodes_segment = f"\n\n{t('season_added_progress').format(added=present, total=total)}"
                elif present > 0:
                    episodes_segment = f"\n\n{t('season_added_count_only').format(added=present)}"
                else:
                    episodes_segment = ""

                notification_message = (
                    f"*{t('new_season_title')}*\n\n*{series_name_cleaned}* *({release_year})*\n\n"
                    f"*{season}*{episodes_segment}\n\n{overview_to_use}")

                if ratings_text:
                    notification_message += f"\n\n*{t('new_ratings_show')}*\n{ratings_text}"

                if trailer_url:
                    notification_message += f"\n\n[üé•]({trailer_url})[{t('new_trailer')}]({trailer_url})"

                # –ü—Ä–æ–≤–µ—Ä–∏–º, –µ—Å—Ç—å –ª–∏ –ø–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞ ‚Äî –µ—Å–ª–∏ –Ω–µ—Ç, —à–ª—ë–º —Å –ø–æ—Å—Ç–µ—Ä–æ–º —Å–µ—Ä–∏–∞–ª–∞
                if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                    send_notification(season_id, notification_message)
                else:
                    send_notification(series_id, notification_message)
                    logging.warning(
                        f"{series_name_cleaned} {season} image does not exist, falling back to series image")

                mark_item_as_notified(item_type, key_name, release_year)
                logging.info(f"(Season) {series_name_cleaned} {season} notification was sent")
                return "Season notification was sent"

        if item_type == "Episode":
            if not item_already_notified(item_type, item_name, release_year):
                item_id = payload.get("ItemId")
                file_details = get_item_details(item_id)
                season_id = file_details["Items"][0].get("SeasonId")
                episode_premiere_date = file_details["Items"][0].get("PremiereDate", "0000-00-00T").split("T")[0]
                season_details = get_item_details(season_id)
                series_id = season_details["Items"][0].get("SeriesId")
                season_date_created = season_details["Items"][0].get("DateCreated", "0000-00-00T").split("T")[0]
                epi_name = item_name
                overview = payload.get("Overview")

#                if not DEBUG_DISABLE_DATE_CHECKS:
                if not is_not_within_last_x_days(season_date_created, SEASON_ADDED_WITHIN_X_DAYS):
                    logging.info(f"(Episode) {series_name} Season {season_num} "
                                 f"was added within the last {SEASON_ADDED_WITHIN_X_DAYS} "
                                 f"days. Not sending notification.")
                    return (f"Season was added within the last {SEASON_ADDED_WITHIN_X_DAYS} "
                            f"days. Not sending notification.")

                if episode_premiere_date and is_within_last_x_days(episode_premiere_date,
                                                                   EPISODE_PREMIERED_WITHIN_X_DAYS):

                    notification_message = (
                        f"*{t('new_episode_title')}*\n\n*{t('new_release_date')}*: {episode_premiere_date}\n\n*{t('new_series')}*: {series_name} *S*"
                        f"{season_num}*E*{season_epi}\n*{t('new_episode_t')}*: {epi_name}\n\n{overview}\n\n"
                    )
                    # –ü–æ—Å—Ç–µ—Ä —Å–µ–∑–æ–Ω–∞ –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å ‚Äî –ø—Ä–æ–≤–µ—Ä–∏–º –∑–∞—Ä–∞–Ω–µ–µ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–π–¥—ë–º –Ω–∞ –ø–æ—Å—Ç–µ—Ä —Å–µ—Ä–∏–∞–ª–∞
                    if _fetch_jellyfin_image_with_retries(season_id, attempts=1, timeout=3):
                        send_notification(season_id, notification_message)
                    else:
                        send_notification(series_id, notification_message)
                        logging.warning(
                            f"(Episode) {series_name} season image does not exist, falling back to series image")

                    mark_item_as_notified(item_type, item_name, release_year)
                    logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} notification sent!")
                    return "Notification sent!"

                else:
                    logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} "
                                 f"was premiered more than {EPISODE_PREMIERED_WITHIN_X_DAYS} "
                                 f"days ago. Not sending notification.")
                    return (f"Episode was added more than {EPISODE_PREMIERED_WITHIN_X_DAYS} "
                            f"days ago. Not sending notification.")

        if item_type == "MusicAlbum":
            # —á–∏—Ç–∞–µ–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è/–∞–ª—å–±–æ–º –∑–∞—Ä–∞–Ω–µ–µ, —á—Ç–æ–±—ã —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á
            album_name = payload.get("Name")
            artist = payload.get("Artist")
            key_name = f"{artist} ‚Äì {album_name}".strip()

            if not item_already_notified(item_type, key_name, release_year):
                album_id = payload.get("ItemId")
                album_name = payload.get("Name")
                artist = payload.get("Artist")
                year = payload.get("Year")
                overview = payload.get("Overview")
                runtime = payload.get("RunTime")
                musicbrainzalbum_id = payload.get("Provider_musicbrainzalbum")

                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ MusicBrainz, –µ—Å–ª–∏ –µ—Å—Ç—å ID
                mb_link = f"https://musicbrainz.org/release/{musicbrainzalbum_id}" if musicbrainzalbum_id else ""

                # –®–∞–±–ª–æ–Ω —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
                notification_message = (
                    f"*{t('new_album_title')}*\n\n"
                    f"*{artist}*\n\n"
                    f"*{album_name} ({year})*\n\n"
                    f"{overview and overview + '\n\n' or ''}"
                    f"*{t('new_runtime')}*\n{runtime}\n\n"
                    f"{f'[MusicBrainz]({mb_link})' if mb_link else ''}\n"
                )

                send_notification(album_id, notification_message)
                mark_item_as_notified(item_type, key_name, release_year)
                logging.info(f"(Album) {artist} ‚Äì {album_name} ({year}) notification sent.")
                return "Album notification was sent to telegram"

        if item_type == "Movie":
            logging.info(f"(Movie) {item_name} Notification Was Already Sent")
        elif item_type == "Season":
            logging.info(f"(Season) {series_name} {item_name} Notification Was Already Sent")
        elif item_type == "Episode":
            logging.info(f"(Episode) {series_name} S{season_num}E{season_epi} Notification Was Already Sent")
        else:
            logging.error('Item type not supported')
        return "Item type not supported."

    # Handle specific HTTP errors
    except HTTPError as http_err:
        logging.error(f"HTTP error occurred: {http_err}")
        return str(http_err)

    # Handle generic exceptions
    except Exception as e:
        logging.error(f"Error: {str(e)}")
        return f"Error: {str(e)}"


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
